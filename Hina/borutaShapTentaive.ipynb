{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from BorutaShap import BorutaShap\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BorutaShap_FS_ten (X, y,method_option) :\n",
    "    #modelshap = RandomForestClassifier(n_jobs=-1,n_estimators=100, class_weight='balanced_subsample', max_depth=5, random_state=100)\n",
    "    modelshap = RandomForestClassifier(n_jobs=-1,n_estimators=100, max_depth=5, random_state=100)\n",
    "\n",
    "    # define model for resp. classifier\n",
    "    modelshap.fit(X,y)\n",
    "    feature_names = np.array(X.columns)\n",
    "    # define Boruta Sahp feature selection method\n",
    "    feature_selector = BorutaShap(model=modelshap,\n",
    "                              importance_measure=method_option,\n",
    "                              classification=True)  # find all relevant features\n",
    "    feature_selector.fit(X,y,n_trials=100,sample = False, verbose = True,random_state=100)  \n",
    "    #feature_selector.plot(which_features='accepted',figsize=(20,10))\n",
    "    tentative=retransformed_train.loc[:,feature_selector_test.tentative]\n",
    "    selected=feature_selector_test.Subset()\n",
    "    selten=pd.concat([selected,tentative],axis=1)\n",
    "    # call transform() on X to filter it down to selected features\n",
    "    return  selten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_method_t=['shap','gini']\n",
    "list_borshap_t = []\n",
    "#order=0\n",
    "\n",
    "for m in list_method_t:\n",
    "    Output_t = BorutaShap_FS_ten(retransformed_train,y_train,m)\n",
    "    list_borshap_t.append(Output_t)\n",
    "    \n",
    "for r in range(len(list_borshap_t)):\n",
    "    print(list_borshap_t[r])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boruta Py with rfpimp and percentile threshold =80 for shadow comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Boruta_FS_MDA (X, y) :\n",
    "    feature_names_rfpimp = np.array(X.columns)\n",
    "\n",
    "    # define random forest classifier\n",
    "    model_rfpimp = RandomForestClassifier(n_jobs=-1, class_weight='balanced_subsample', max_depth=5,oob_score=True, random_state=100)\n",
    "    model_rfpimp.fit(X, y)\n",
    "    # define Boruta feature selection method\n",
    "    \n",
    "    feature_selector_rfpimp = BorutaPy(model_rfpimp, n_estimators='auto', verbose=2, random_state=100, max_iter=140, perc=80)\n",
    "\n",
    "    # find all relevant features\n",
    "    feature_selector_rfpimp.fit(X.to_numpy(),y)\n",
    "\n",
    "    # check selected features\n",
    "    feature_selector_rfpimp.support_\n",
    "\n",
    "    # check ranking of features\n",
    "    feature_ranking_rfpimp=feature_selector_rfpimp.ranking_\n",
    "\n",
    "    # zip feature names, ranks, and decisions \n",
    "    feature_ranks_rfpimp = list(zip(feature_names_rfpimp, \n",
    "                             feature_selector_rfpimp.ranking_, \n",
    "                             feature_selector_rfpimp.support_))\n",
    "\n",
    "    # print the results\n",
    "    for feat in feature_ranks_rfpimp:\n",
    "        print('Feature: {:<30} Rank: {},  Keep: {}'.format(feat[0], feat[1], feat[2]))\n",
    "        \n",
    "    final_features_rfpimp = list()\n",
    "    indexes_rfpimp = np.where(feature_selector_rfpimp.ranking_ <= 1)\n",
    "    for x in np.nditer(indexes_rfpimp):\n",
    "        final_features_rfpimp.append(feature_names_rfpimp[x])\n",
    "    print(final_features_rfpimp)\n",
    "    \n",
    " # call transform() on X to filter it down to selected features\n",
    "    return pd.DataFrame(X.filter(final_features_rfpimp)) , final_features_rfpimp, feature_ranking_rfpimp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mds , final_features_mds, feature_ranking_mda = Boruta_FS_MDA(retransformed_train,y_train)# 140 iteration , per=80 , rank=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mds_dup=remove_duplicated_columns(X_train_mds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mds_cor=remove_collinear_features(X_train_mds,0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFE function to return unscaled features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFE function with random forest\n",
    "\n",
    "def RFE_FS (X, y,classify) :\n",
    "    feature_names = np.array(X.columns)\n",
    "    if classify == 'RF':\n",
    "    # define random forest classifier\n",
    "        model = RandomForestClassifier(n_jobs=-1, class_weight='balanced_subsample', max_depth=5, random_state=100)\n",
    "        #model.fit(X, y)\n",
    "        #rfe = RFE(estimator = model,n_features_to_select = 15)\n",
    "    if classify== 'SVM':\n",
    "        model = SVC(kernel='linear',C=5)\n",
    "        #model.fit(X, y)\n",
    "        #rfe = RFECV(estimator = model,scoring='accuracy')\n",
    "    # find all relevant features\n",
    "    model.fit(X, y)\n",
    "    rfe = RFE(estimator = model,n_features_to_select = 15)\n",
    "    rfe.fit(X,y)\n",
    "\n",
    "    # check selected features\n",
    "    rfe.support_\n",
    "\n",
    "    # check ranking of features\n",
    "    rfe.ranking_\n",
    "\n",
    "    # zip feature names, ranks, and decisions \n",
    "    feature_ranks = list(zip(feature_names, \n",
    "                             rfe.ranking_, \n",
    "                             rfe.support_))\n",
    "\n",
    "    # print the results\n",
    "    for feat in feature_ranks:\n",
    "        print('Feature: {:<30} Rank: {},  Keep: {}'.format(feat[0], feat[1], feat[2]))\n",
    "        \n",
    "    final_features_rfe = list()\n",
    "    indexes = np.where(rfe.ranking_ <= 1)\n",
    "    for x in np.nditer(indexes):\n",
    "        final_features_rfe.append(feature_names[x])\n",
    "    print(final_features_rfe)\n",
    "    \n",
    "    # unscale the data before return\n",
    "    ff_rfe_scaled=pd.DataFrame(X.filter(final_features_rfe))\n",
    "    ff_rfe_unscaled=pd.DataFrame(scaler.inverse_transform(X), columns=X.columns)\n",
    "\n",
    " # call transform() on X to filter it down to selected features\n",
    "    return  ff_rfe_unscaled, final_features_rfe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08c0539bf10c75c5b2836a432ee34201d271197da8458066aa86299ab8bcd438"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

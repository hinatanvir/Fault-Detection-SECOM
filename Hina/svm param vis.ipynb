{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READ ME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook is implemeted in a repository in github with input and output folders.\n",
    "#### It has 2 parts:\n",
    "##### > Part 1: Pre-defined funtions for each technique.\n",
    "##### > Part 2: Execution of model pipelines, here users can modify which combination of techniques they want to run. The scores will be printed as a csv in output folders. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1: FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from boruta import BorutaPy\n",
    "from BorutaShap import BorutaShap\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, f1_score, precision_score, recall_score, roc_auc_score, log_loss, cohen_kappa_score,fbeta_score, make_scorer,matthews_corrcoef\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical \n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function is to read, transform and join 2 data frame\n",
    "\n",
    "def read_features():\n",
    "    path = '../secom.data'\n",
    "    df = pd.read_csv(path, delimiter=' ', header=None, na_values=['NaN'])\n",
    "    df.columns = ['feature_'+str(x+1) for x in range(len(df.columns))]\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_target():\n",
    "    path = '../secom_labels.data'\n",
    "    df = pd.read_csv(path, delimiter=' ', header=None, na_values=['NaN'])\n",
    "    df.columns = ['status','timestamp']\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'],dayfirst=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove duplicated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the duplicated features (columns)\n",
    "def remove_duplicated_columns(df):\n",
    "    list_duplicate = []\n",
    "    to_remove = []\n",
    "    for i in range(0, len(df.columns)):\n",
    "        l = []\n",
    "        for j in range(i+1,len(df.columns)):\n",
    "            if df.iloc[:,i].equals(df.iloc[:,j]) == True:\n",
    "                if j not in list_duplicate:\n",
    "                    l.append(j)\n",
    "                    to_remove.append('feature_'+str(j+1))\n",
    "                list_duplicate.append(i)\n",
    "                list_duplicate.append(j)\n",
    "\n",
    "    return df.drop(columns=to_remove, axis = 1)\n",
    "\n",
    "# X = remove_duplicated_columns(X)\n",
    "# X.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove columns with Constant volatility (std=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_constant_volatility(df):\n",
    "    df_EDA= df.describe().T\n",
    "    df_EDA= df_EDA[df_EDA[\"std\"] == 0]\n",
    "    df = df.drop(axis=1, columns=df_EDA.index)\n",
    "    return df\n",
    "\n",
    "# X = remove_constant_volatility(X)\n",
    "# X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove columns with high %Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_cols_with_high_pct_null(df, null_threshold):\n",
    "    list_column_with_pct_null = pd.concat([df.isnull().sum(), df.isnull().sum()/df.shape[0]],axis=1).rename(columns={0:'Missing_Records', 1:'Percentage (%)'})\n",
    "    list_column_with_pct_null= list_column_with_pct_null[list_column_with_pct_null[\"Percentage (%)\"] >= null_threshold]\n",
    "    df = df.drop(axis=1, columns=list_column_with_pct_null.index)\n",
    "    return df\n",
    "\n",
    "# X = remove_cols_with_high_pct_null(X, 0.8)\n",
    "# X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how = ['NaN', '3s' ,'nothing']\n",
    "def replace_outlier(df, how):\n",
    "    for col in df:\n",
    "        ll_col = df[col].mean() - 3 * df[col].std()\n",
    "        ul_col = df[col].mean() + 3 * df[col].std()\n",
    "        if how == 'NaN':\n",
    "            df[col] = np.where(df[col]>ul_col,np.NaN,np.where(df[col]<ll_col,np.NaN,df[col]))\n",
    "        elif how == '3s':\n",
    "            df[col] = np.where(df[col]>ul_col,ul_col,np.where(df[col]<ll_col,ll_col,df[col]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing value Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#which_weights = ['distance','uniform']\n",
    "\n",
    "def impute_null_with_knn(X_train, X_test, which_weights):\n",
    "    #First scale the data \n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = pd.DataFrame(scaler.fit_transform(X_train), columns= X_train.columns)\n",
    "    X_test = pd.DataFrame(scaler.transform(X_test), columns= X_test.columns)\n",
    "\n",
    "    knn = KNNImputer(n_neighbors=5, weights=which_weights) #check this neighbors = 5\n",
    "\n",
    "    X_train = pd.DataFrame(knn.fit_transform(X_train), columns=X_train.columns)\n",
    "    X_test = pd.DataFrame(knn.transform(X_test), columns=X_test.columns)\n",
    "    \n",
    "    X_train = pd.DataFrame(scaler.inverse_transform(X_train), columns= X_train.columns)\n",
    "    X_test = pd.DataFrame(scaler.inverse_transform(X_test), columns= X_test.columns)\n",
    "    return X_train, X_test\n",
    "\n",
    "#X_train = impute_null_with_knn(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_null_with_mice(X_train, X_test): \n",
    "    imp = IterativeImputer(max_iter=5, verbose=0, imputation_order='roman', random_state=0)\n",
    "    X_train = pd.DataFrame(imp.fit_transform(X_train), columns=X_train.columns)\n",
    "    X_test = pd.DataFrame(imp.transform(X_test), columns=X_test.columns)\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is BorutaShap with TENTATIVE features\n",
    "\n",
    "#list_method=['shap','gini']\n",
    "\n",
    "def BorutaShap_FS (X, y,method_option) :\n",
    "    #modelshap = RandomForestClassifier(n_jobs=-1,n_estimators=100, class_weight='balanced_subsample', max_depth=5, random_state=100)\n",
    "    modelshap = RandomForestClassifier(n_jobs=-1,n_estimators=100, max_depth=5, random_state=100)\n",
    "\n",
    "    # define model for resp. classifier\n",
    "    modelshap.fit(X,y)\n",
    "    feature_names = np.array(X.columns)\n",
    "    # define Boruta Sahp feature selection method\n",
    "    feature_selector = BorutaShap(model=modelshap,\n",
    "                              importance_measure=method_option,\n",
    "                              classification=True)  # find all relevant features\n",
    "    feature_selector.fit(X,y,n_trials=100,sample = False, verbose = False,random_state=100)  \n",
    "    #feature_selector.plot(which_features='accepted',figsize=(20,10))\n",
    "    tentative=X.loc[:,feature_selector.tentative]\n",
    "    selected=feature_selector.Subset()\n",
    "    selten=pd.concat([selected,tentative],axis=1)\n",
    "    # call transform() on X to filter it down to selected features\n",
    "    return  selten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFE\n",
    "\n",
    "#classifier = ['RF', 'SVM']\n",
    "\n",
    "def RFE_FS (X, y,classify) :\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled= pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "    feature_names = np.array(X_scaled.columns)\n",
    "    if classify == 'RF':\n",
    "    # define random forest classifier\n",
    "        model = RandomForestClassifier(n_jobs=-1, class_weight='balanced_subsample', max_depth=5, random_state=100)\n",
    "       \n",
    "    if classify== 'SVM':\n",
    "        model = SVC(kernel='linear',C=5)\n",
    "        #rfe = RFECV(estimator = model,scoring='accuracy')\n",
    "    # find all relevant features\n",
    "    model.fit(X_scaled, y)\n",
    "    rfe = RFE(estimator = model,n_features_to_select = 30)\n",
    "    rfe.fit(X_scaled,y)\n",
    "\n",
    "     # zip feature names, ranks, and decisions \n",
    "    feature_ranks = list(zip(feature_names, \n",
    "                             rfe.ranking_, \n",
    "                             rfe.support_))\n",
    "\n",
    "    final_features_rfe = list()\n",
    "    indexes = np.where(rfe.ranking_ <= 2)\n",
    "    for x in np.nditer(indexes):\n",
    "        final_features_rfe.append(feature_names[x])\n",
    "    \n",
    "    \n",
    "    # unscale the data before return\n",
    "    X_unscaled=pd.DataFrame(scaler.inverse_transform(X_scaled), columns=X_scaled.columns)\n",
    "    ff_rfe=pd.DataFrame(X_unscaled.filter(final_features_rfe))\n",
    "    \n",
    "\n",
    " # call transform() on X to filter it down to selected features\n",
    "    return  ff_rfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boruta function with random forest\n",
    "\n",
    "def BorutaPy_FS (X, y) :\n",
    "    feature_names = np.array(X.columns)\n",
    "\n",
    "    # define random forest classifier\n",
    "    model = RandomForestClassifier(n_jobs=-1, class_weight='balanced_subsample', max_depth=5, random_state=100)\n",
    "    model.fit(X, y)\n",
    "    # define Boruta feature selection method\n",
    "    \n",
    "    feature_selector = BorutaPy(model, n_estimators='auto', verbose=0, random_state=100, max_iter=140)\n",
    "\n",
    "    # find all relevant features\n",
    "    feature_selector.fit(X.to_numpy(),y)\n",
    "\n",
    "    # check selected features\n",
    "    ##--feature_selector.support_\n",
    "\n",
    "    # check ranking of features\n",
    "    ##--feature_ranking=feature_selector.ranking_\n",
    "\n",
    "    # zip feature names, ranks, and decisions \n",
    "    # feature_ranks = list(zip(feature_names, \n",
    "    #                          feature_selector.ranking_, \n",
    "    #                          feature_selector.support_))\n",
    "\n",
    "    # print the results\n",
    "    ##--for feat in feature_ranks:\n",
    "    ##--    print('Feature: {:<30} Rank: {},  Keep: {}'.format(feat[0], feat[1], feat[2]))\n",
    "        \n",
    "    final_features = list()\n",
    "    indexes = np.where(feature_selector.ranking_ <= 2) #change to 2\n",
    "    for x in np.nditer(indexes):\n",
    "        final_features.append(feature_names[x])\n",
    "    ##--print(final_features)\n",
    "    \n",
    " # call transform() on X to filter it down to selected features\n",
    "    return pd.DataFrame(X.filter(final_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multicolinearity treatement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the highly collinear features from data\n",
    "def remove_collinear_features(x, threshold):\n",
    "    '''\n",
    "    Objective:\n",
    "        Remove collinear features in a dataframe with a correlation coefficient\n",
    "        greater than the threshold. Removing collinear features can help a model \n",
    "        to generalize and improves the interpretability of the model.\n",
    "\n",
    "    Inputs: \n",
    "        x: features dataframe\n",
    "        threshold: features with correlations greater than this value are removed\n",
    "\n",
    "    Output: \n",
    "        dataframe that contains only the non-highly-collinear features\n",
    "    '''\n",
    "\n",
    "    # Calculate the correlation matrix\n",
    "    corr_matrix = x.corr()\n",
    "    iters = range(len(corr_matrix.columns) - 1)\n",
    "    drop_cols = []\n",
    "\n",
    "    # Iterate through the correlation matrix and compare correlations\n",
    "    for i in iters:\n",
    "        for j in range(i+1):\n",
    "            item = corr_matrix.iloc[j:(j+1), (i+1):(i+2)]\n",
    "            col = item.columns\n",
    "            row = item.index\n",
    "            val = abs(item.values)\n",
    "\n",
    "            # If correlation exceeds the threshold\n",
    "            if val >= threshold:\n",
    "                #Print the correlated features and the correlation value\n",
    "                #print(col.values[0], \"|\", row.values[0], \"|\", round(val[0][0], 2))\n",
    "                drop_cols.append(col.values[0])\n",
    "\n",
    "    # Drop one of each pair of correlated columns\n",
    "    drops = set(drop_cols)\n",
    "    x = x.drop(columns=drops)\n",
    "\n",
    "    return x\n",
    "\n",
    "#remove_collinear_features(X, 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(X_train, y_train, sampler):\n",
    "    \n",
    "    #SMOTE\n",
    "    if sampler == 'SMOTE':\n",
    "        sampler = SMOTE(random_state=100)    \n",
    "    \n",
    "    #ROSE\n",
    "    if sampler == 'ROSE':\n",
    "        sampler = RandomOverSampler(random_state=100, shrinkage=1)\n",
    "\n",
    "    #ADASYN\n",
    "    if sampler == 'ADASYN':\n",
    "        sampler = ADASYN(random_state=100)\n",
    "    \n",
    "\n",
    "    #SMOTTEENN\n",
    "    if sampler == 'SMOTEENN' :\n",
    "        sampler = SMOTEENN(random_state=100)\n",
    "        \n",
    "        \n",
    "    #Random under Sampling\n",
    "    if sampler == \"randomunder\":\n",
    "        sampler = RandomUnderSampler(random_state=100)\n",
    "\n",
    "    X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)\n",
    "    #counter = Counter(y_resampled)\n",
    "    #print(counter)\n",
    "    \n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "# X_train, y_train = sampling(X_train, y_train,'SMOTE')\n",
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with 3s, knn,BoS__shap, SMOTEENN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:54<00:00,  1.83it/s]\n"
     ]
    }
   ],
   "source": [
    "X = read_features()\n",
    "y = read_target().iloc[:,0]\n",
    "\n",
    "result = []\n",
    "\n",
    "#step 1:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1, stratify=y)\n",
    "\n",
    "# # step 2:\n",
    "X_train = remove_duplicated_columns(X_train)\n",
    "# #step 3:\n",
    "X_train = remove_constant_volatility(X_train)\n",
    "# #step 4:\n",
    "X_train = remove_cols_with_high_pct_null(X_train, 0.8) #this can be in the loop too, may be later\n",
    "# #step 5: remove the same columns from step 2-4 TRAIN_TEST split\n",
    "X_test = X_test.loc[:,X_train.columns]\n",
    "\n",
    "fast_track_cols = X_test.columns\n",
    "\n",
    "X_train = X_train.loc[:, fast_track_cols]\n",
    "X_test = X_test.loc[:, fast_track_cols]\n",
    "\n",
    "X_train_temp = X_train\n",
    "X_test_temp = X_test\n",
    "y_train_temp = y_train\n",
    "y_test_temp = y_test\n",
    "X_train_temp = replace_outlier(X_train_temp, '3s')\n",
    "X_test_temp = replace_outlier(X_test_temp, '3s')\n",
    "X_train_temp, X_test_temp = impute_null_with_knn(X_train_temp, X_test_temp, 'distance')\n",
    "X_train_temp = BorutaShap_FS(X_train_temp, y_train_temp, 'shap')\n",
    "X_test_temp = X_test_temp.loc[:,X_train_temp.columns]\n",
    "X_train_temp, y_train_temp = sampling(X_train_temp, y_train_temp, 'SMOTEENN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Model grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = [\n",
    "    {\"kernel\": [\"rbf\"], \"gamma\": [0.00, 1e-3, 0.1,10 ], \"C\": [1, 100, 1000,0.01]},\n",
    "    {\"kernel\": [\"linear\"], \"C\": [0.01,1, 100, 1000,10000]},\n",
    "    {\"kernel\": [\"poly\"], \"gamma\": [1e-4, 1e-3,0.1,10], \"C\": [1, 100, 1000,0.01], \"degree\" : [3,5,6]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_rbf= [{\"gamma\": [1e-4, 1e-3, 0.1,10 ]},\"C\": [1, 100, 1000,0.01]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_scorer(clf, X, y):\n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    return {'tn': cm[0, 0], 'fp': cm[0, 1],\n",
    "            'fn': cm[1, 0], 'tp': cm[1, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer={#'cf_scorer': make_scorer(confusion_matrix_scorer),\n",
    "        'rec' : 'recall',\n",
    "        'pre': 'precision',\n",
    "        'f1' : 'f1',\n",
    "        'fbeta' : make_scorer(fbeta_score, beta=3),\n",
    "        'acc' : 'accuracy',\n",
    "        'roc' :'roc_auc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_tune=grid = GridSearchCV(SVC(), param_grid=tuned_parameters, cv=cv, scoring= ['recall','accuracy','roc_auc'],verbose=4,refit='roc_auc')\n",
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "#grid_tune1 = GridSearchCV(SVC(), param_grid=tuned_parameters, cv=cv, scoring='accuracy' ,refit='recall',verbose=4)\n",
    "grid = GridSearchCV(SVC(), param_grid=tuned_parameters, cv=cv, scoring=scorer ,refit='fbeta',verbose=4)\n",
    "#grid = GridSearchCV(SVC(), param_grid=param_test, cv=cv, scoring=scorer ,refit='roc',verbose=4,error_score=\"raise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 68 candidates, totalling 340 fits\n",
      "[CV 1/5] END C=1, gamma=0.0001, kernel=rbf; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.846) total time=   0.0s\n",
      "[CV 2/5] END C=1, gamma=0.0001, kernel=rbf; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.836) total time=   0.0s\n",
      "[CV 3/5] END C=1, gamma=0.0001, kernel=rbf; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.843) total time=   0.0s\n",
      "[CV 4/5] END C=1, gamma=0.0001, kernel=rbf; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.864) total time=   0.0s\n",
      "[CV 5/5] END C=1, gamma=0.0001, kernel=rbf; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.875) total time=   0.0s\n",
      "[CV 1/5] END C=1, gamma=0.001, kernel=rbf; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.846) total time=   0.0s\n",
      "[CV 2/5] END C=1, gamma=0.001, kernel=rbf; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.834) total time=   0.0s\n",
      "[CV 3/5] END C=1, gamma=0.001, kernel=rbf; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.841) total time=   0.0s\n",
      "[CV 4/5] END C=1, gamma=0.001, kernel=rbf; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.862) total time=   0.0s\n",
      "[CV 5/5] END C=1, gamma=0.001, kernel=rbf; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.873) total time=   0.0s\n",
      "[CV 1/5] END C=1, gamma=0.1, kernel=rbf; acc: (test=0.794) f1: (test=0.821) fbeta: (test=0.819) pre: (test=0.823) rec: (test=0.819) roc: (test=0.858) total time=   0.0s\n",
      "[CV 2/5] END C=1, gamma=0.1, kernel=rbf; acc: (test=0.769) f1: (test=0.799) fbeta: (test=0.799) pre: (test=0.799) rec: (test=0.799) roc: (test=0.848) total time=   0.0s\n",
      "[CV 3/5] END C=1, gamma=0.1, kernel=rbf; acc: (test=0.780) f1: (test=0.807) fbeta: (test=0.801) pre: (test=0.815) rec: (test=0.799) roc: (test=0.860) total time=   0.0s\n",
      "[CV 4/5] END C=1, gamma=0.1, kernel=rbf; acc: (test=0.823) f1: (test=0.845) fbeta: (test=0.844) pre: (test=0.847) rec: (test=0.843) roc: (test=0.876) total time=   0.0s\n",
      "[CV 5/5] END C=1, gamma=0.1, kernel=rbf; acc: (test=0.820) f1: (test=0.844) fbeta: (test=0.847) pre: (test=0.840) rec: (test=0.848) roc: (test=0.889) total time=   0.0s\n",
      "[CV 1/5] END C=1, gamma=10, kernel=rbf; acc: (test=0.977) f1: (test=0.981) fbeta: (test=0.988) pre: (test=0.971) rec: (test=0.990) roc: (test=0.997) total time=   0.0s\n",
      "[CV 2/5] END C=1, gamma=10, kernel=rbf; acc: (test=0.977) f1: (test=0.981) fbeta: (test=0.992) pre: (test=0.967) rec: (test=0.995) roc: (test=0.998) total time=   0.0s\n",
      "[CV 3/5] END C=1, gamma=10, kernel=rbf; acc: (test=0.975) f1: (test=0.978) fbeta: (test=0.988) pre: (test=0.967) rec: (test=0.990) roc: (test=0.998) total time=   0.0s\n",
      "[CV 4/5] END C=1, gamma=10, kernel=rbf; acc: (test=0.972) f1: (test=0.976) fbeta: (test=0.991) pre: (test=0.958) rec: (test=0.995) roc: (test=0.993) total time=   0.0s\n",
      "[CV 5/5] END C=1, gamma=10, kernel=rbf; acc: (test=0.975) f1: (test=0.978) fbeta: (test=0.996) pre: (test=0.958) rec: (test=1.000) roc: (test=0.998) total time=   0.0s\n",
      "[CV 1/5] END C=100, gamma=0.0001, kernel=rbf; acc: (test=0.639) f1: (test=0.757) fbeta: (test=0.922) pre: (test=0.618) rec: (test=0.975) roc: (test=0.846) total time=   0.0s\n",
      "[CV 2/5] END C=100, gamma=0.0001, kernel=rbf; acc: (test=0.662) f1: (test=0.768) fbeta: (test=0.926) pre: (test=0.634) rec: (test=0.975) roc: (test=0.835) total time=   0.0s\n",
      "[CV 3/5] END C=100, gamma=0.0001, kernel=rbf; acc: (test=0.645) f1: (test=0.763) fbeta: (test=0.938) pre: (test=0.619) rec: (test=0.995) roc: (test=0.841) total time=   0.0s\n",
      "[CV 4/5] END C=100, gamma=0.0001, kernel=rbf; acc: (test=0.642) f1: (test=0.758) fbeta: (test=0.923) pre: (test=0.620) rec: (test=0.975) roc: (test=0.862) total time=   0.0s\n",
      "[CV 5/5] END C=100, gamma=0.0001, kernel=rbf; acc: (test=0.631) f1: (test=0.754) fbeta: (test=0.928) pre: (test=0.611) rec: (test=0.985) roc: (test=0.873) total time=   0.0s\n",
      "[CV 1/5] END C=100, gamma=0.001, kernel=rbf; acc: (test=0.792) f1: (test=0.818) fbeta: (test=0.815) pre: (test=0.822) rec: (test=0.814) roc: (test=0.854) total time=   0.0s\n",
      "[CV 2/5] END C=100, gamma=0.001, kernel=rbf; acc: (test=0.766) f1: (test=0.795) fbeta: (test=0.790) pre: (test=0.801) rec: (test=0.789) roc: (test=0.840) total time=   0.0s\n",
      "[CV 3/5] END C=100, gamma=0.001, kernel=rbf; acc: (test=0.775) f1: (test=0.803) fbeta: (test=0.800) pre: (test=0.807) rec: (test=0.799) roc: (test=0.855) total time=   0.0s\n",
      "[CV 4/5] END C=100, gamma=0.001, kernel=rbf; acc: (test=0.814) f1: (test=0.836) fbeta: (test=0.826) pre: (test=0.848) rec: (test=0.824) roc: (test=0.872) total time=   0.0s\n",
      "[CV 5/5] END C=100, gamma=0.001, kernel=rbf; acc: (test=0.814) f1: (test=0.838) fbeta: (test=0.838) pre: (test=0.838) rec: (test=0.838) roc: (test=0.882) total time=   0.0s\n",
      "[CV 1/5] END C=100, gamma=0.1, kernel=rbf; acc: (test=0.842) f1: (test=0.863) fbeta: (test=0.867) pre: (test=0.859) rec: (test=0.868) roc: (test=0.922) total time=   0.0s\n",
      "[CV 2/5] END C=100, gamma=0.1, kernel=rbf; acc: (test=0.859) f1: (test=0.882) fbeta: (test=0.910) pre: (test=0.850) rec: (test=0.917) roc: (test=0.918) total time=   0.0s\n",
      "[CV 3/5] END C=100, gamma=0.1, kernel=rbf; acc: (test=0.873) f1: (test=0.891) fbeta: (test=0.900) pre: (test=0.880) rec: (test=0.902) roc: (test=0.933) total time=   0.0s\n",
      "[CV 4/5] END C=100, gamma=0.1, kernel=rbf; acc: (test=0.882) f1: (test=0.900) fbeta: (test=0.921) pre: (test=0.875) rec: (test=0.926) roc: (test=0.940) total time=   0.0s\n",
      "[CV 5/5] END C=100, gamma=0.1, kernel=rbf; acc: (test=0.873) f1: (test=0.892) fbeta: (test=0.908) pre: (test=0.873) rec: (test=0.912) roc: (test=0.940) total time=   0.0s\n",
      "[CV 1/5] END C=100, gamma=10, kernel=rbf; acc: (test=0.969) f1: (test=0.973) fbeta: (test=0.987) pre: (test=0.957) rec: (test=0.990) roc: (test=0.998) total time=   0.0s\n",
      "[CV 2/5] END C=100, gamma=10, kernel=rbf; acc: (test=0.972) f1: (test=0.976) fbeta: (test=0.987) pre: (test=0.962) rec: (test=0.990) roc: (test=0.999) total time=   0.0s\n",
      "[CV 3/5] END C=100, gamma=10, kernel=rbf; acc: (test=0.980) f1: (test=0.983) fbeta: (test=0.985) pre: (test=0.980) rec: (test=0.985) roc: (test=0.998) total time=   0.0s\n",
      "[CV 4/5] END C=100, gamma=10, kernel=rbf; acc: (test=0.980) f1: (test=0.983) fbeta: (test=0.997) pre: (test=0.967) rec: (test=1.000) roc: (test=0.995) total time=   0.0s\n",
      "[CV 5/5] END C=100, gamma=10, kernel=rbf; acc: (test=0.983) f1: (test=0.985) fbeta: (test=0.993) pre: (test=0.976) rec: (test=0.995) roc: (test=0.999) total time=   0.0s\n",
      "[CV 1/5] END C=1000, gamma=0.0001, kernel=rbf; acc: (test=0.792) f1: (test=0.818) fbeta: (test=0.815) pre: (test=0.822) rec: (test=0.814) roc: (test=0.854) total time=   0.0s\n",
      "[CV 2/5] END C=1000, gamma=0.0001, kernel=rbf; acc: (test=0.766) f1: (test=0.795) fbeta: (test=0.790) pre: (test=0.801) rec: (test=0.789) roc: (test=0.840) total time=   0.0s\n",
      "[CV 3/5] END C=1000, gamma=0.0001, kernel=rbf; acc: (test=0.775) f1: (test=0.803) fbeta: (test=0.800) pre: (test=0.807) rec: (test=0.799) roc: (test=0.855) total time=   0.0s\n",
      "[CV 4/5] END C=1000, gamma=0.0001, kernel=rbf; acc: (test=0.814) f1: (test=0.836) fbeta: (test=0.826) pre: (test=0.848) rec: (test=0.824) roc: (test=0.872) total time=   0.0s\n",
      "[CV 5/5] END C=1000, gamma=0.0001, kernel=rbf; acc: (test=0.814) f1: (test=0.838) fbeta: (test=0.838) pre: (test=0.838) rec: (test=0.838) roc: (test=0.882) total time=   0.0s\n",
      "[CV 1/5] END C=1000, gamma=0.001, kernel=rbf; acc: (test=0.800) f1: (test=0.823) fbeta: (test=0.812) pre: (test=0.838) rec: (test=0.809) roc: (test=0.860) total time=   0.0s\n",
      "[CV 2/5] END C=1000, gamma=0.001, kernel=rbf; acc: (test=0.761) f1: (test=0.789) fbeta: (test=0.781) pre: (test=0.799) rec: (test=0.779) roc: (test=0.847) total time=   0.0s\n",
      "[CV 3/5] END C=1000, gamma=0.001, kernel=rbf; acc: (test=0.789) f1: (test=0.811) fbeta: (test=0.793) pre: (test=0.834) rec: (test=0.789) roc: (test=0.863) total time=   0.0s\n",
      "[CV 4/5] END C=1000, gamma=0.001, kernel=rbf; acc: (test=0.814) f1: (test=0.834) fbeta: (test=0.818) pre: (test=0.856) rec: (test=0.814) roc: (test=0.878) total time=   0.0s\n",
      "[CV 5/5] END C=1000, gamma=0.001, kernel=rbf; acc: (test=0.803) f1: (test=0.825) fbeta: (test=0.812) pre: (test=0.842) rec: (test=0.809) roc: (test=0.885) total time=   0.0s\n",
      "[CV 1/5] END C=1000, gamma=0.1, kernel=rbf; acc: (test=0.873) f1: (test=0.891) fbeta: (test=0.900) pre: (test=0.880) rec: (test=0.902) roc: (test=0.936) total time=   0.0s\n",
      "[CV 2/5] END C=1000, gamma=0.1, kernel=rbf; acc: (test=0.876) f1: (test=0.898) fbeta: (test=0.940) pre: (test=0.851) rec: (test=0.951) roc: (test=0.936) total time=   0.0s\n",
      "[CV 3/5] END C=1000, gamma=0.1, kernel=rbf; acc: (test=0.893) f1: (test=0.909) fbeta: (test=0.927) pre: (test=0.888) rec: (test=0.931) roc: (test=0.945) total time=   0.1s\n",
      "[CV 4/5] END C=1000, gamma=0.1, kernel=rbf; acc: (test=0.904) f1: (test=0.921) fbeta: (test=0.960) pre: (test=0.876) rec: (test=0.971) roc: (test=0.953) total time=   0.0s\n",
      "[CV 5/5] END C=1000, gamma=0.1, kernel=rbf; acc: (test=0.901) f1: (test=0.918) fbeta: (test=0.956) pre: (test=0.876) rec: (test=0.966) roc: (test=0.963) total time=   0.0s\n",
      "[CV 1/5] END C=1000, gamma=10, kernel=rbf; acc: (test=0.969) f1: (test=0.973) fbeta: (test=0.987) pre: (test=0.957) rec: (test=0.990) roc: (test=0.998) total time=   0.0s\n",
      "[CV 2/5] END C=1000, gamma=10, kernel=rbf; acc: (test=0.972) f1: (test=0.976) fbeta: (test=0.987) pre: (test=0.962) rec: (test=0.990) roc: (test=0.999) total time=   0.0s\n",
      "[CV 3/5] END C=1000, gamma=10, kernel=rbf; acc: (test=0.980) f1: (test=0.983) fbeta: (test=0.985) pre: (test=0.980) rec: (test=0.985) roc: (test=0.998) total time=   0.0s\n",
      "[CV 4/5] END C=1000, gamma=10, kernel=rbf; acc: (test=0.980) f1: (test=0.983) fbeta: (test=0.997) pre: (test=0.967) rec: (test=1.000) roc: (test=0.995) total time=   0.0s\n",
      "[CV 5/5] END C=1000, gamma=10, kernel=rbf; acc: (test=0.983) f1: (test=0.985) fbeta: (test=0.993) pre: (test=0.976) rec: (test=0.995) roc: (test=0.999) total time=   0.0s\n",
      "[CV 1/5] END C=0.01, gamma=0.0001, kernel=rbf; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.850) total time=   0.0s\n",
      "[CV 2/5] END C=0.01, gamma=0.0001, kernel=rbf; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.838) total time=   0.0s\n",
      "[CV 3/5] END C=0.01, gamma=0.0001, kernel=rbf; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.846) total time=   0.0s\n",
      "[CV 4/5] END C=0.01, gamma=0.0001, kernel=rbf; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.866) total time=   0.0s\n",
      "[CV 5/5] END C=0.01, gamma=0.0001, kernel=rbf; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.877) total time=   0.0s\n",
      "[CV 1/5] END C=0.01, gamma=0.001, kernel=rbf; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.850) total time=   0.0s\n",
      "[CV 2/5] END C=0.01, gamma=0.001, kernel=rbf; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.838) total time=   0.0s\n",
      "[CV 3/5] END C=0.01, gamma=0.001, kernel=rbf; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.845) total time=   0.0s\n",
      "[CV 4/5] END C=0.01, gamma=0.001, kernel=rbf; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.866) total time=   0.0s\n",
      "[CV 5/5] END C=0.01, gamma=0.001, kernel=rbf; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.876) total time=   0.0s\n",
      "[CV 1/5] END C=0.01, gamma=0.1, kernel=rbf; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.848) total time=   0.0s\n",
      "[CV 2/5] END C=0.01, gamma=0.1, kernel=rbf; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.835) total time=   0.0s\n",
      "[CV 3/5] END C=0.01, gamma=0.1, kernel=rbf; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.842) total time=   0.0s\n",
      "[CV 4/5] END C=0.01, gamma=0.1, kernel=rbf; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.865) total time=   0.0s\n",
      "[CV 5/5] END C=0.01, gamma=0.1, kernel=rbf; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.873) total time=   0.0s\n",
      "[CV 1/5] END C=0.01, gamma=10, kernel=rbf; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.963) total time=   0.0s\n",
      "[CV 2/5] END C=0.01, gamma=10, kernel=rbf; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.950) total time=   0.0s\n",
      "[CV 3/5] END C=0.01, gamma=10, kernel=rbf; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.966) total time=   0.0s\n",
      "[CV 4/5] END C=0.01, gamma=10, kernel=rbf; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.968) total time=   0.0s\n",
      "[CV 5/5] END C=0.01, gamma=10, kernel=rbf; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.961) total time=   0.0s\n",
      "[CV 1/5] END C=1, kernel=linear; acc: (test=0.794) f1: (test=0.820) fbeta: (test=0.815) pre: (test=0.826) rec: (test=0.814) roc: (test=0.859) total time=   0.0s\n",
      "[CV 2/5] END C=1, kernel=linear; acc: (test=0.763) f1: (test=0.792) fbeta: (test=0.786) pre: (test=0.800) rec: (test=0.784) roc: (test=0.846) total time=   0.0s\n",
      "[CV 3/5] END C=1, kernel=linear; acc: (test=0.786) f1: (test=0.809) fbeta: (test=0.793) pre: (test=0.830) rec: (test=0.789) roc: (test=0.860) total time=   0.0s\n",
      "[CV 4/5] END C=1, kernel=linear; acc: (test=0.811) f1: (test=0.831) fbeta: (test=0.813) pre: (test=0.855) rec: (test=0.809) roc: (test=0.875) total time=   0.0s\n",
      "[CV 5/5] END C=1, kernel=linear; acc: (test=0.800) f1: (test=0.822) fbeta: (test=0.807) pre: (test=0.841) rec: (test=0.804) roc: (test=0.884) total time=   0.0s\n",
      "[CV 1/5] END C=100, kernel=linear; acc: (test=0.789) f1: (test=0.812) fbeta: (test=0.798) pre: (test=0.831) rec: (test=0.794) roc: (test=0.868) total time=   0.0s\n",
      "[CV 2/5] END C=100, kernel=linear; acc: (test=0.786) f1: (test=0.814) fbeta: (test=0.814) pre: (test=0.814) rec: (test=0.814) roc: (test=0.860) total time=   0.0s\n",
      "[CV 3/5] END C=100, kernel=linear; acc: (test=0.792) f1: (test=0.811) fbeta: (test=0.786) pre: (test=0.846) rec: (test=0.779) roc: (test=0.872) total time=   0.0s\n",
      "[CV 4/5] END C=100, kernel=linear; acc: (test=0.817) f1: (test=0.839) fbeta: (test=0.830) pre: (test=0.849) rec: (test=0.828) roc: (test=0.884) total time=   0.0s\n",
      "[CV 5/5] END C=100, kernel=linear; acc: (test=0.820) f1: (test=0.840) fbeta: (test=0.827) pre: (test=0.857) rec: (test=0.824) roc: (test=0.891) total time=   0.0s\n",
      "[CV 1/5] END C=1000, kernel=linear; acc: (test=0.789) f1: (test=0.812) fbeta: (test=0.798) pre: (test=0.831) rec: (test=0.794) roc: (test=0.870) total time=   0.4s\n",
      "[CV 2/5] END C=1000, kernel=linear; acc: (test=0.780) f1: (test=0.811) fbeta: (test=0.817) pre: (test=0.803) rec: (test=0.819) roc: (test=0.860) total time=   0.4s\n",
      "[CV 3/5] END C=1000, kernel=linear; acc: (test=0.789) f1: (test=0.808) fbeta: (test=0.781) pre: (test=0.845) rec: (test=0.775) roc: (test=0.876) total time=   0.3s\n",
      "[CV 4/5] END C=1000, kernel=linear; acc: (test=0.814) f1: (test=0.834) fbeta: (test=0.818) pre: (test=0.856) rec: (test=0.814) roc: (test=0.885) total time=   0.4s\n",
      "[CV 5/5] END C=1000, kernel=linear; acc: (test=0.820) f1: (test=0.838) fbeta: (test=0.819) pre: (test=0.865) rec: (test=0.814) roc: (test=0.895) total time=   0.5s\n",
      "[CV 1/5] END C=0.01, kernel=linear; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.846) total time=   0.0s\n",
      "[CV 2/5] END C=0.01, kernel=linear; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.835) total time=   0.0s\n",
      "[CV 3/5] END C=0.01, kernel=linear; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.841) total time=   0.0s\n",
      "[CV 4/5] END C=0.01, kernel=linear; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.862) total time=   0.0s\n",
      "[CV 5/5] END C=0.01, kernel=linear; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.873) total time=   0.0s\n",
      "[CV 1/5] END C=1, degree=3, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.852) total time=   0.0s\n",
      "[CV 2/5] END C=1, degree=3, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.831) total time=   0.0s\n",
      "[CV 3/5] END C=1, degree=3, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.838) total time=   0.0s\n",
      "[CV 4/5] END C=1, degree=3, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.860) total time=   0.0s\n",
      "[CV 5/5] END C=1, degree=3, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.865) total time=   0.0s\n",
      "[CV 1/5] END C=1, degree=3, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.852) total time=   0.0s\n",
      "[CV 2/5] END C=1, degree=3, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.831) total time=   0.0s\n",
      "[CV 3/5] END C=1, degree=3, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.838) total time=   0.0s\n",
      "[CV 4/5] END C=1, degree=3, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.860) total time=   0.0s\n",
      "[CV 5/5] END C=1, degree=3, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.866) total time=   0.0s\n",
      "[CV 1/5] END C=1, degree=3, gamma=0.1, kernel=poly; acc: (test=0.744) f1: (test=0.749) fbeta: (test=0.682) pre: (test=0.855) rec: (test=0.667) roc: (test=0.852) total time=   0.0s\n",
      "[CV 2/5] END C=1, degree=3, gamma=0.1, kernel=poly; acc: (test=0.758) f1: (test=0.772) fbeta: (test=0.726) pre: (test=0.839) rec: (test=0.716) roc: (test=0.832) total time=   0.0s\n",
      "[CV 3/5] END C=1, degree=3, gamma=0.1, kernel=poly; acc: (test=0.721) f1: (test=0.726) fbeta: (test=0.657) pre: (test=0.834) rec: (test=0.642) roc: (test=0.839) total time=   0.0s\n",
      "[CV 4/5] END C=1, degree=3, gamma=0.1, kernel=poly; acc: (test=0.763) f1: (test=0.775) fbeta: (test=0.723) pre: (test=0.853) rec: (test=0.711) roc: (test=0.862) total time=   0.0s\n",
      "[CV 5/5] END C=1, degree=3, gamma=0.1, kernel=poly; acc: (test=0.749) f1: (test=0.753) fbeta: (test=0.682) pre: (test=0.866) rec: (test=0.667) roc: (test=0.868) total time=   0.0s\n",
      "[CV 1/5] END C=1, degree=3, gamma=10, kernel=poly; acc: (test=0.930) f1: (test=0.941) fbeta: (test=0.972) pre: (test=0.905) rec: (test=0.980) roc: (test=0.966) total time=   1.0s\n",
      "[CV 2/5] END C=1, degree=3, gamma=10, kernel=poly; acc: (test=0.949) f1: (test=0.957) fbeta: (test=0.980) pre: (test=0.931) rec: (test=0.985) roc: (test=0.970) total time=   0.6s\n",
      "[CV 3/5] END C=1, degree=3, gamma=10, kernel=poly; acc: (test=0.946) f1: (test=0.955) fbeta: (test=0.975) pre: (test=0.930) rec: (test=0.980) roc: (test=0.975) total time=   0.5s\n",
      "[CV 4/5] END C=1, degree=3, gamma=10, kernel=poly; acc: (test=0.946) f1: (test=0.955) fbeta: (test=0.987) pre: (test=0.919) rec: (test=0.995) roc: (test=0.978) total time=   0.5s\n",
      "[CV 5/5] END C=1, degree=3, gamma=10, kernel=poly; acc: (test=0.935) f1: (test=0.946) fbeta: (test=0.981) pre: (test=0.906) rec: (test=0.990) roc: (test=0.950) total time=   0.7s\n",
      "[CV 1/5] END C=1, degree=5, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.795) total time=   0.0s\n",
      "[CV 2/5] END C=1, degree=5, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.758) total time=   0.0s\n",
      "[CV 3/5] END C=1, degree=5, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.776) total time=   0.0s\n",
      "[CV 4/5] END C=1, degree=5, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.807) total time=   0.0s\n",
      "[CV 5/5] END C=1, degree=5, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.805) total time=   0.0s\n",
      "[CV 1/5] END C=1, degree=5, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.849) total time=   0.0s\n",
      "[CV 2/5] END C=1, degree=5, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.824) total time=   0.0s\n",
      "[CV 3/5] END C=1, degree=5, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.826) total time=   0.0s\n",
      "[CV 4/5] END C=1, degree=5, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.852) total time=   0.0s\n",
      "[CV 5/5] END C=1, degree=5, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.856) total time=   0.0s\n",
      "[CV 1/5] END C=1, degree=5, gamma=0.1, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.850) total time=   0.0s\n",
      "[CV 2/5] END C=1, degree=5, gamma=0.1, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.824) total time=   0.0s\n",
      "[CV 3/5] END C=1, degree=5, gamma=0.1, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.824) total time=   0.0s\n",
      "[CV 4/5] END C=1, degree=5, gamma=0.1, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.851) total time=   0.0s\n",
      "[CV 5/5] END C=1, degree=5, gamma=0.1, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.855) total time=   0.0s\n",
      "[CV 1/5] END C=1, degree=5, gamma=10, kernel=poly; acc: (test=0.930) f1: (test=0.941) fbeta: (test=0.964) pre: (test=0.912) rec: (test=0.971) roc: (test=0.961) total time=   0.1s\n",
      "[CV 2/5] END C=1, degree=5, gamma=10, kernel=poly; acc: (test=0.952) f1: (test=0.959) fbeta: (test=0.972) pre: (test=0.943) rec: (test=0.975) roc: (test=0.965) total time=   0.1s\n",
      "[CV 3/5] END C=1, degree=5, gamma=10, kernel=poly; acc: (test=0.952) f1: (test=0.959) fbeta: (test=0.968) pre: (test=0.947) rec: (test=0.971) roc: (test=0.967) total time=   0.2s\n",
      "[CV 4/5] END C=1, degree=5, gamma=10, kernel=poly; acc: (test=0.941) f1: (test=0.950) fbeta: (test=0.978) pre: (test=0.918) rec: (test=0.985) roc: (test=0.974) total time=   0.1s\n",
      "[CV 5/5] END C=1, degree=5, gamma=10, kernel=poly; acc: (test=0.932) f1: (test=0.943) fbeta: (test=0.973) pre: (test=0.909) rec: (test=0.980) roc: (test=0.959) total time=   0.2s\n",
      "[CV 1/5] END C=1, degree=6, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.500) total time=   0.0s\n",
      "[CV 2/5] END C=1, degree=6, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.500) total time=   0.0s\n",
      "[CV 3/5] END C=1, degree=6, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.500) total time=   0.0s\n",
      "[CV 4/5] END C=1, degree=6, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.500) total time=   0.0s\n",
      "[CV 5/5] END C=1, degree=6, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.500) total time=   0.0s\n",
      "[CV 1/5] END C=1, degree=6, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.849) total time=   0.0s\n",
      "[CV 2/5] END C=1, degree=6, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.821) total time=   0.0s\n",
      "[CV 3/5] END C=1, degree=6, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.822) total time=   0.0s\n",
      "[CV 4/5] END C=1, degree=6, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.849) total time=   0.0s\n",
      "[CV 5/5] END C=1, degree=6, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.853) total time=   0.0s\n",
      "[CV 1/5] END C=1, degree=6, gamma=0.1, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.849) total time=   0.0s\n",
      "[CV 2/5] END C=1, degree=6, gamma=0.1, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.821) total time=   0.0s\n",
      "[CV 3/5] END C=1, degree=6, gamma=0.1, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.821) total time=   0.0s\n",
      "[CV 4/5] END C=1, degree=6, gamma=0.1, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.850) total time=   0.0s\n",
      "[CV 5/5] END C=1, degree=6, gamma=0.1, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.853) total time=   0.0s\n",
      "[CV 1/5] END C=1, degree=6, gamma=10, kernel=poly; acc: (test=0.918) f1: (test=0.931) fbeta: (test=0.955) pre: (test=0.903) rec: (test=0.961) roc: (test=0.961) total time=   0.1s\n",
      "[CV 2/5] END C=1, degree=6, gamma=10, kernel=poly; acc: (test=0.949) f1: (test=0.957) fbeta: (test=0.976) pre: (test=0.935) rec: (test=0.980) roc: (test=0.962) total time=   0.1s\n",
      "[CV 3/5] END C=1, degree=6, gamma=10, kernel=poly; acc: (test=0.946) f1: (test=0.954) fbeta: (test=0.963) pre: (test=0.943) rec: (test=0.966) roc: (test=0.965) total time=   0.1s\n",
      "[CV 4/5] END C=1, degree=6, gamma=10, kernel=poly; acc: (test=0.938) f1: (test=0.948) fbeta: (test=0.978) pre: (test=0.914) rec: (test=0.985) roc: (test=0.976) total time=   0.1s\n",
      "[CV 5/5] END C=1, degree=6, gamma=10, kernel=poly; acc: (test=0.935) f1: (test=0.946) fbeta: (test=0.973) pre: (test=0.913) rec: (test=0.980) roc: (test=0.956) total time=   0.2s\n",
      "[CV 1/5] END C=100, degree=3, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.852) total time=   0.0s\n",
      "[CV 2/5] END C=100, degree=3, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.831) total time=   0.0s\n",
      "[CV 3/5] END C=100, degree=3, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.838) total time=   0.0s\n",
      "[CV 4/5] END C=100, degree=3, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.860) total time=   0.0s\n",
      "[CV 5/5] END C=100, degree=3, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.866) total time=   0.0s\n",
      "[CV 1/5] END C=100, degree=3, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.852) total time=   0.0s\n",
      "[CV 2/5] END C=100, degree=3, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.831) total time=   0.0s\n",
      "[CV 3/5] END C=100, degree=3, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.838) total time=   0.0s\n",
      "[CV 4/5] END C=100, degree=3, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.860) total time=   0.0s\n",
      "[CV 5/5] END C=100, degree=3, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.866) total time=   0.0s\n",
      "[CV 1/5] END C=100, degree=3, gamma=0.1, kernel=poly; acc: (test=0.837) f1: (test=0.854) fbeta: (test=0.833) pre: (test=0.880) rec: (test=0.828) roc: (test=0.901) total time=   0.0s\n",
      "[CV 2/5] END C=100, degree=3, gamma=0.1, kernel=poly; acc: (test=0.808) f1: (test=0.832) fbeta: (test=0.825) pre: (test=0.840) rec: (test=0.824) roc: (test=0.898) total time=   0.0s\n",
      "[CV 3/5] END C=100, degree=3, gamma=0.1, kernel=poly; acc: (test=0.814) f1: (test=0.832) fbeta: (test=0.805) pre: (test=0.867) rec: (test=0.799) roc: (test=0.910) total time=   0.0s\n",
      "[CV 4/5] END C=100, degree=3, gamma=0.1, kernel=poly; acc: (test=0.856) f1: (test=0.875) fbeta: (test=0.873) pre: (test=0.877) rec: (test=0.873) roc: (test=0.922) total time=   0.0s\n",
      "[CV 5/5] END C=100, degree=3, gamma=0.1, kernel=poly; acc: (test=0.859) f1: (test=0.875) fbeta: (test=0.861) pre: (test=0.893) rec: (test=0.858) roc: (test=0.923) total time=   0.0s\n",
      "[CV 1/5] END C=100, degree=3, gamma=10, kernel=poly; acc: (test=0.924) f1: (test=0.937) fbeta: (test=0.971) pre: (test=0.897) rec: (test=0.980) roc: (test=0.970) total time=   0.9s\n",
      "[CV 2/5] END C=100, degree=3, gamma=10, kernel=poly; acc: (test=0.955) f1: (test=0.962) fbeta: (test=0.980) pre: (test=0.939) rec: (test=0.985) roc: (test=0.971) total time=   0.6s\n",
      "[CV 3/5] END C=100, degree=3, gamma=10, kernel=poly; acc: (test=0.944) f1: (test=0.952) fbeta: (test=0.975) pre: (test=0.926) rec: (test=0.980) roc: (test=0.975) total time=   0.6s\n",
      "[CV 4/5] END C=100, degree=3, gamma=10, kernel=poly; acc: (test=0.941) f1: (test=0.950) fbeta: (test=0.978) pre: (test=0.918) rec: (test=0.985) roc: (test=0.977) total time=   0.8s\n",
      "[CV 5/5] END C=100, degree=3, gamma=10, kernel=poly; acc: (test=0.944) f1: (test=0.953) fbeta: (test=0.982) pre: (test=0.918) rec: (test=0.990) roc: (test=0.952) total time=   0.7s\n",
      "[CV 1/5] END C=100, degree=5, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.849) total time=   0.0s\n",
      "[CV 2/5] END C=100, degree=5, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.823) total time=   0.0s\n",
      "[CV 3/5] END C=100, degree=5, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.825) total time=   0.0s\n",
      "[CV 4/5] END C=100, degree=5, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.851) total time=   0.0s\n",
      "[CV 5/5] END C=100, degree=5, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.856) total time=   0.0s\n",
      "[CV 1/5] END C=100, degree=5, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.849) total time=   0.0s\n",
      "[CV 2/5] END C=100, degree=5, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.824) total time=   0.0s\n",
      "[CV 3/5] END C=100, degree=5, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.826) total time=   0.0s\n",
      "[CV 4/5] END C=100, degree=5, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.852) total time=   0.0s\n",
      "[CV 5/5] END C=100, degree=5, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.856) total time=   0.0s\n",
      "[CV 1/5] END C=100, degree=5, gamma=0.1, kernel=poly; acc: (test=0.777) f1: (test=0.788) fbeta: (test=0.733) pre: (test=0.870) rec: (test=0.721) roc: (test=0.872) total time=   0.0s\n",
      "[CV 2/5] END C=100, degree=5, gamma=0.1, kernel=poly; acc: (test=0.792) f1: (test=0.804) fbeta: (test=0.756) pre: (test=0.874) rec: (test=0.745) roc: (test=0.865) total time=   0.0s\n",
      "[CV 3/5] END C=100, degree=5, gamma=0.1, kernel=poly; acc: (test=0.763) f1: (test=0.774) fbeta: (test=0.719) pre: (test=0.857) rec: (test=0.706) roc: (test=0.875) total time=   0.0s\n",
      "[CV 4/5] END C=100, degree=5, gamma=0.1, kernel=poly; acc: (test=0.800) f1: (test=0.810) fbeta: (test=0.753) pre: (test=0.893) rec: (test=0.740) roc: (test=0.899) total time=   0.0s\n",
      "[CV 5/5] END C=100, degree=5, gamma=0.1, kernel=poly; acc: (test=0.806) f1: (test=0.812) fbeta: (test=0.745) pre: (test=0.914) rec: (test=0.730) roc: (test=0.901) total time=   0.0s\n",
      "[CV 1/5] END C=100, degree=5, gamma=10, kernel=poly; acc: (test=0.930) f1: (test=0.941) fbeta: (test=0.964) pre: (test=0.912) rec: (test=0.971) roc: (test=0.961) total time=   0.1s\n",
      "[CV 2/5] END C=100, degree=5, gamma=10, kernel=poly; acc: (test=0.952) f1: (test=0.959) fbeta: (test=0.972) pre: (test=0.943) rec: (test=0.975) roc: (test=0.965) total time=   0.1s\n",
      "[CV 3/5] END C=100, degree=5, gamma=10, kernel=poly; acc: (test=0.952) f1: (test=0.959) fbeta: (test=0.968) pre: (test=0.947) rec: (test=0.971) roc: (test=0.967) total time=   0.2s\n",
      "[CV 4/5] END C=100, degree=5, gamma=10, kernel=poly; acc: (test=0.941) f1: (test=0.950) fbeta: (test=0.978) pre: (test=0.918) rec: (test=0.985) roc: (test=0.974) total time=   0.2s\n",
      "[CV 5/5] END C=100, degree=5, gamma=10, kernel=poly; acc: (test=0.932) f1: (test=0.943) fbeta: (test=0.973) pre: (test=0.909) rec: (test=0.980) roc: (test=0.959) total time=   0.2s\n",
      "[CV 1/5] END C=100, degree=6, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.500) total time=   0.0s\n",
      "[CV 2/5] END C=100, degree=6, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.500) total time=   0.0s\n",
      "[CV 3/5] END C=100, degree=6, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.500) total time=   0.0s\n",
      "[CV 4/5] END C=100, degree=6, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.500) total time=   0.0s\n",
      "[CV 5/5] END C=100, degree=6, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.500) total time=   0.0s\n",
      "[CV 1/5] END C=100, degree=6, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.849) total time=   0.0s\n",
      "[CV 2/5] END C=100, degree=6, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.822) total time=   0.0s\n",
      "[CV 3/5] END C=100, degree=6, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.822) total time=   0.0s\n",
      "[CV 4/5] END C=100, degree=6, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.848) total time=   0.0s\n",
      "[CV 5/5] END C=100, degree=6, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.852) total time=   0.0s\n",
      "[CV 1/5] END C=100, degree=6, gamma=0.1, kernel=poly; acc: (test=0.749) f1: (test=0.751) fbeta: (test=0.674) pre: (test=0.876) rec: (test=0.657) roc: (test=0.861) total time=   0.0s\n",
      "[CV 2/5] END C=100, degree=6, gamma=0.1, kernel=poly; acc: (test=0.766) f1: (test=0.771) fbeta: (test=0.702) pre: (test=0.881) rec: (test=0.686) roc: (test=0.849) total time=   0.0s\n",
      "[CV 3/5] END C=100, degree=6, gamma=0.1, kernel=poly; acc: (test=0.741) f1: (test=0.736) fbeta: (test=0.646) pre: (test=0.889) rec: (test=0.627) roc: (test=0.857) total time=   0.0s\n",
      "[CV 4/5] END C=100, degree=6, gamma=0.1, kernel=poly; acc: (test=0.777) f1: (test=0.779) fbeta: (test=0.699) pre: (test=0.908) rec: (test=0.681) roc: (test=0.884) total time=   0.0s\n",
      "[CV 5/5] END C=100, degree=6, gamma=0.1, kernel=poly; acc: (test=0.758) f1: (test=0.751) fbeta: (test=0.657) pre: (test=0.915) rec: (test=0.637) roc: (test=0.886) total time=   0.0s\n",
      "[CV 1/5] END C=100, degree=6, gamma=10, kernel=poly; acc: (test=0.918) f1: (test=0.931) fbeta: (test=0.955) pre: (test=0.903) rec: (test=0.961) roc: (test=0.961) total time=   0.1s\n",
      "[CV 2/5] END C=100, degree=6, gamma=10, kernel=poly; acc: (test=0.949) f1: (test=0.957) fbeta: (test=0.976) pre: (test=0.935) rec: (test=0.980) roc: (test=0.962) total time=   0.1s\n",
      "[CV 3/5] END C=100, degree=6, gamma=10, kernel=poly; acc: (test=0.946) f1: (test=0.954) fbeta: (test=0.963) pre: (test=0.943) rec: (test=0.966) roc: (test=0.965) total time=   0.2s\n",
      "[CV 4/5] END C=100, degree=6, gamma=10, kernel=poly; acc: (test=0.938) f1: (test=0.948) fbeta: (test=0.978) pre: (test=0.914) rec: (test=0.985) roc: (test=0.976) total time=   0.1s\n",
      "[CV 5/5] END C=100, degree=6, gamma=10, kernel=poly; acc: (test=0.935) f1: (test=0.946) fbeta: (test=0.973) pre: (test=0.913) rec: (test=0.980) roc: (test=0.956) total time=   0.2s\n",
      "[CV 1/5] END C=1000, degree=3, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.852) total time=   0.0s\n",
      "[CV 2/5] END C=1000, degree=3, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.831) total time=   0.0s\n",
      "[CV 3/5] END C=1000, degree=3, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.838) total time=   0.0s\n",
      "[CV 4/5] END C=1000, degree=3, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.860) total time=   0.0s\n",
      "[CV 5/5] END C=1000, degree=3, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.866) total time=   0.0s\n",
      "[CV 1/5] END C=1000, degree=3, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.853) total time=   0.0s\n",
      "[CV 2/5] END C=1000, degree=3, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.831) total time=   0.0s\n",
      "[CV 3/5] END C=1000, degree=3, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.838) total time=   0.0s\n",
      "[CV 4/5] END C=1000, degree=3, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.860) total time=   0.0s\n",
      "[CV 5/5] END C=1000, degree=3, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.866) total time=   0.0s\n",
      "[CV 1/5] END C=1000, degree=3, gamma=0.1, kernel=poly; acc: (test=0.856) f1: (test=0.874) fbeta: (test=0.869) pre: (test=0.881) rec: (test=0.868) roc: (test=0.933) total time=   0.0s\n",
      "[CV 2/5] END C=1000, degree=3, gamma=0.1, kernel=poly; acc: (test=0.862) f1: (test=0.882) fbeta: (test=0.898) pre: (test=0.864) rec: (test=0.902) roc: (test=0.931) total time=   0.0s\n",
      "[CV 3/5] END C=1000, degree=3, gamma=0.1, kernel=poly; acc: (test=0.879) f1: (test=0.895) fbeta: (test=0.897) pre: (test=0.893) rec: (test=0.897) roc: (test=0.943) total time=   0.0s\n",
      "[CV 4/5] END C=1000, degree=3, gamma=0.1, kernel=poly; acc: (test=0.890) f1: (test=0.908) fbeta: (test=0.938) pre: (test=0.873) rec: (test=0.946) roc: (test=0.946) total time=   0.0s\n",
      "[CV 5/5] END C=1000, degree=3, gamma=0.1, kernel=poly; acc: (test=0.910) f1: (test=0.923) fbeta: (test=0.937) pre: (test=0.906) rec: (test=0.941) roc: (test=0.953) total time=   0.0s\n",
      "[CV 1/5] END C=1000, degree=3, gamma=10, kernel=poly; acc: (test=0.924) f1: (test=0.937) fbeta: (test=0.971) pre: (test=0.897) rec: (test=0.980) roc: (test=0.970) total time=   0.9s\n",
      "[CV 2/5] END C=1000, degree=3, gamma=10, kernel=poly; acc: (test=0.955) f1: (test=0.962) fbeta: (test=0.980) pre: (test=0.939) rec: (test=0.985) roc: (test=0.971) total time=   0.7s\n",
      "[CV 3/5] END C=1000, degree=3, gamma=10, kernel=poly; acc: (test=0.944) f1: (test=0.952) fbeta: (test=0.975) pre: (test=0.926) rec: (test=0.980) roc: (test=0.975) total time=   0.6s\n",
      "[CV 4/5] END C=1000, degree=3, gamma=10, kernel=poly; acc: (test=0.941) f1: (test=0.950) fbeta: (test=0.978) pre: (test=0.918) rec: (test=0.985) roc: (test=0.977) total time=   0.8s\n",
      "[CV 5/5] END C=1000, degree=3, gamma=10, kernel=poly; acc: (test=0.944) f1: (test=0.953) fbeta: (test=0.982) pre: (test=0.918) rec: (test=0.990) roc: (test=0.952) total time=   0.8s\n",
      "[CV 1/5] END C=1000, degree=5, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.849) total time=   0.0s\n",
      "[CV 2/5] END C=1000, degree=5, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.824) total time=   0.0s\n",
      "[CV 3/5] END C=1000, degree=5, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.826) total time=   0.0s\n",
      "[CV 4/5] END C=1000, degree=5, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.852) total time=   0.0s\n",
      "[CV 5/5] END C=1000, degree=5, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.856) total time=   0.0s\n",
      "[CV 1/5] END C=1000, degree=5, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.849) total time=   0.0s\n",
      "[CV 2/5] END C=1000, degree=5, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.824) total time=   0.0s\n",
      "[CV 3/5] END C=1000, degree=5, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.826) total time=   0.0s\n",
      "[CV 4/5] END C=1000, degree=5, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.852) total time=   0.0s\n",
      "[CV 5/5] END C=1000, degree=5, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.856) total time=   0.0s\n",
      "[CV 1/5] END C=1000, degree=5, gamma=0.1, kernel=poly; acc: (test=0.842) f1: (test=0.859) fbeta: (test=0.838) pre: (test=0.885) rec: (test=0.833) roc: (test=0.914) total time=   0.0s\n",
      "[CV 2/5] END C=1000, degree=5, gamma=0.1, kernel=poly; acc: (test=0.820) f1: (test=0.843) fbeta: (test=0.843) pre: (test=0.843) rec: (test=0.843) roc: (test=0.908) total time=   0.0s\n",
      "[CV 3/5] END C=1000, degree=5, gamma=0.1, kernel=poly; acc: (test=0.834) f1: (test=0.849) fbeta: (test=0.821) pre: (test=0.888) rec: (test=0.814) roc: (test=0.921) total time=   0.0s\n",
      "[CV 4/5] END C=1000, degree=5, gamma=0.1, kernel=poly; acc: (test=0.865) f1: (test=0.882) fbeta: (test=0.878) pre: (test=0.886) rec: (test=0.877) roc: (test=0.938) total time=   0.0s\n",
      "[CV 5/5] END C=1000, degree=5, gamma=0.1, kernel=poly; acc: (test=0.859) f1: (test=0.876) fbeta: (test=0.869) pre: (test=0.885) rec: (test=0.868) roc: (test=0.935) total time=   0.0s\n",
      "[CV 1/5] END C=1000, degree=5, gamma=10, kernel=poly; acc: (test=0.930) f1: (test=0.941) fbeta: (test=0.964) pre: (test=0.912) rec: (test=0.971) roc: (test=0.961) total time=   0.1s\n",
      "[CV 2/5] END C=1000, degree=5, gamma=10, kernel=poly; acc: (test=0.952) f1: (test=0.959) fbeta: (test=0.972) pre: (test=0.943) rec: (test=0.975) roc: (test=0.965) total time=   0.1s\n",
      "[CV 3/5] END C=1000, degree=5, gamma=10, kernel=poly; acc: (test=0.952) f1: (test=0.959) fbeta: (test=0.968) pre: (test=0.947) rec: (test=0.971) roc: (test=0.967) total time=   0.2s\n",
      "[CV 4/5] END C=1000, degree=5, gamma=10, kernel=poly; acc: (test=0.941) f1: (test=0.950) fbeta: (test=0.978) pre: (test=0.918) rec: (test=0.985) roc: (test=0.974) total time=   0.2s\n",
      "[CV 5/5] END C=1000, degree=5, gamma=10, kernel=poly; acc: (test=0.932) f1: (test=0.943) fbeta: (test=0.973) pre: (test=0.909) rec: (test=0.980) roc: (test=0.959) total time=   0.2s\n",
      "[CV 1/5] END C=1000, degree=6, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.656) total time=   0.0s\n",
      "[CV 2/5] END C=1000, degree=6, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.651) total time=   0.0s\n",
      "[CV 3/5] END C=1000, degree=6, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.647) total time=   0.0s\n",
      "[CV 4/5] END C=1000, degree=6, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.666) total time=   0.0s\n",
      "[CV 5/5] END C=1000, degree=6, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.658) total time=   0.0s\n",
      "[CV 1/5] END C=1000, degree=6, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.849) total time=   0.0s\n",
      "[CV 2/5] END C=1000, degree=6, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.822) total time=   0.0s\n",
      "[CV 3/5] END C=1000, degree=6, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.822) total time=   0.0s\n",
      "[CV 4/5] END C=1000, degree=6, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.848) total time=   0.0s\n",
      "[CV 5/5] END C=1000, degree=6, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.852) total time=   0.0s\n",
      "[CV 1/5] END C=1000, degree=6, gamma=0.1, kernel=poly; acc: (test=0.803) f1: (test=0.817) fbeta: (test=0.775) pre: (test=0.876) rec: (test=0.765) roc: (test=0.896) total time=   0.0s\n",
      "[CV 2/5] END C=1000, degree=6, gamma=0.1, kernel=poly; acc: (test=0.808) f1: (test=0.822) fbeta: (test=0.780) pre: (test=0.882) rec: (test=0.770) roc: (test=0.891) total time=   0.0s\n",
      "[CV 3/5] END C=1000, degree=6, gamma=0.1, kernel=poly; acc: (test=0.792) f1: (test=0.802) fbeta: (test=0.748) pre: (test=0.882) rec: (test=0.735) roc: (test=0.905) total time=   0.0s\n",
      "[CV 4/5] END C=1000, degree=6, gamma=0.1, kernel=poly; acc: (test=0.828) f1: (test=0.838) fbeta: (test=0.786) pre: (test=0.913) rec: (test=0.775) roc: (test=0.925) total time=   0.0s\n",
      "[CV 5/5] END C=1000, degree=6, gamma=0.1, kernel=poly; acc: (test=0.825) f1: (test=0.834) fbeta: (test=0.778) pre: (test=0.918) rec: (test=0.765) roc: (test=0.921) total time=   0.0s\n",
      "[CV 1/5] END C=1000, degree=6, gamma=10, kernel=poly; acc: (test=0.918) f1: (test=0.931) fbeta: (test=0.955) pre: (test=0.903) rec: (test=0.961) roc: (test=0.961) total time=   0.1s\n",
      "[CV 2/5] END C=1000, degree=6, gamma=10, kernel=poly; acc: (test=0.949) f1: (test=0.957) fbeta: (test=0.976) pre: (test=0.935) rec: (test=0.980) roc: (test=0.962) total time=   0.1s\n",
      "[CV 3/5] END C=1000, degree=6, gamma=10, kernel=poly; acc: (test=0.946) f1: (test=0.954) fbeta: (test=0.963) pre: (test=0.943) rec: (test=0.966) roc: (test=0.965) total time=   0.2s\n",
      "[CV 4/5] END C=1000, degree=6, gamma=10, kernel=poly; acc: (test=0.938) f1: (test=0.948) fbeta: (test=0.978) pre: (test=0.914) rec: (test=0.985) roc: (test=0.976) total time=   0.1s\n",
      "[CV 5/5] END C=1000, degree=6, gamma=10, kernel=poly; acc: (test=0.935) f1: (test=0.946) fbeta: (test=0.973) pre: (test=0.913) rec: (test=0.980) roc: (test=0.956) total time=   0.2s\n",
      "[CV 1/5] END C=0.01, degree=3, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.852) total time=   0.0s\n",
      "[CV 2/5] END C=0.01, degree=3, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.831) total time=   0.0s\n",
      "[CV 3/5] END C=0.01, degree=3, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.838) total time=   0.0s\n",
      "[CV 4/5] END C=0.01, degree=3, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.860) total time=   0.0s\n",
      "[CV 5/5] END C=0.01, degree=3, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.866) total time=   0.0s\n",
      "[CV 1/5] END C=0.01, degree=3, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.852) total time=   0.0s\n",
      "[CV 2/5] END C=0.01, degree=3, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.831) total time=   0.0s\n",
      "[CV 3/5] END C=0.01, degree=3, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.838) total time=   0.0s\n",
      "[CV 4/5] END C=0.01, degree=3, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.860) total time=   0.0s\n",
      "[CV 5/5] END C=0.01, degree=3, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.866) total time=   0.0s\n",
      "[CV 1/5] END C=0.01, degree=3, gamma=0.1, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.852) total time=   0.0s\n",
      "[CV 2/5] END C=0.01, degree=3, gamma=0.1, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.830) total time=   0.0s\n",
      "[CV 3/5] END C=0.01, degree=3, gamma=0.1, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.836) total time=   0.0s\n",
      "[CV 4/5] END C=0.01, degree=3, gamma=0.1, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.861) total time=   0.0s\n",
      "[CV 5/5] END C=0.01, degree=3, gamma=0.1, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.865) total time=   0.0s\n",
      "[CV 1/5] END C=0.01, degree=3, gamma=10, kernel=poly; acc: (test=0.887) f1: (test=0.905) fbeta: (test=0.930) pre: (test=0.876) rec: (test=0.936) roc: (test=0.946) total time=   0.0s\n",
      "[CV 2/5] END C=0.01, degree=3, gamma=10, kernel=poly; acc: (test=0.910) f1: (test=0.927) fbeta: (test=0.977) pre: (test=0.871) rec: (test=0.990) roc: (test=0.943) total time=   0.0s\n",
      "[CV 3/5] END C=0.01, degree=3, gamma=10, kernel=poly; acc: (test=0.921) f1: (test=0.935) fbeta: (test=0.971) pre: (test=0.893) rec: (test=0.980) roc: (test=0.960) total time=   0.0s\n",
      "[CV 4/5] END C=0.01, degree=3, gamma=10, kernel=poly; acc: (test=0.901) f1: (test=0.920) fbeta: (test=0.971) pre: (test=0.863) rec: (test=0.985) roc: (test=0.966) total time=   0.0s\n",
      "[CV 5/5] END C=0.01, degree=3, gamma=10, kernel=poly; acc: (test=0.918) f1: (test=0.932) fbeta: (test=0.970) pre: (test=0.889) rec: (test=0.980) roc: (test=0.969) total time=   0.0s\n",
      "[CV 1/5] END C=0.01, degree=5, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.500) total time=   0.0s\n",
      "[CV 2/5] END C=0.01, degree=5, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.500) total time=   0.0s\n",
      "[CV 3/5] END C=0.01, degree=5, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.500) total time=   0.0s\n",
      "[CV 4/5] END C=0.01, degree=5, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.500) total time=   0.0s\n",
      "[CV 5/5] END C=0.01, degree=5, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.500) total time=   0.0s\n",
      "[CV 1/5] END C=0.01, degree=5, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.849) total time=   0.0s\n",
      "[CV 2/5] END C=0.01, degree=5, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.824) total time=   0.0s\n",
      "[CV 3/5] END C=0.01, degree=5, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.826) total time=   0.0s\n",
      "[CV 4/5] END C=0.01, degree=5, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.852) total time=   0.0s\n",
      "[CV 5/5] END C=0.01, degree=5, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.856) total time=   0.0s\n",
      "[CV 1/5] END C=0.01, degree=5, gamma=0.1, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.850) total time=   0.0s\n",
      "[CV 2/5] END C=0.01, degree=5, gamma=0.1, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.825) total time=   0.0s\n",
      "[CV 3/5] END C=0.01, degree=5, gamma=0.1, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.826) total time=   0.0s\n",
      "[CV 4/5] END C=0.01, degree=5, gamma=0.1, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.853) total time=   0.0s\n",
      "[CV 5/5] END C=0.01, degree=5, gamma=0.1, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.857) total time=   0.0s\n",
      "[CV 1/5] END C=0.01, degree=5, gamma=10, kernel=poly; acc: (test=0.930) f1: (test=0.941) fbeta: (test=0.964) pre: (test=0.912) rec: (test=0.971) roc: (test=0.961) total time=   0.2s\n",
      "[CV 2/5] END C=0.01, degree=5, gamma=10, kernel=poly; acc: (test=0.952) f1: (test=0.959) fbeta: (test=0.972) pre: (test=0.943) rec: (test=0.975) roc: (test=0.965) total time=   0.2s\n",
      "[CV 3/5] END C=0.01, degree=5, gamma=10, kernel=poly; acc: (test=0.952) f1: (test=0.959) fbeta: (test=0.968) pre: (test=0.947) rec: (test=0.971) roc: (test=0.967) total time=   0.3s\n",
      "[CV 4/5] END C=0.01, degree=5, gamma=10, kernel=poly; acc: (test=0.941) f1: (test=0.950) fbeta: (test=0.978) pre: (test=0.918) rec: (test=0.985) roc: (test=0.974) total time=   0.1s\n",
      "[CV 5/5] END C=0.01, degree=5, gamma=10, kernel=poly; acc: (test=0.932) f1: (test=0.943) fbeta: (test=0.973) pre: (test=0.909) rec: (test=0.980) roc: (test=0.959) total time=   0.3s\n",
      "[CV 1/5] END C=0.01, degree=6, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.500) total time=   0.0s\n",
      "[CV 2/5] END C=0.01, degree=6, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.500) total time=   0.0s\n",
      "[CV 3/5] END C=0.01, degree=6, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.500) total time=   0.0s\n",
      "[CV 4/5] END C=0.01, degree=6, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.500) total time=   0.0s\n",
      "[CV 5/5] END C=0.01, degree=6, gamma=0.0001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.500) total time=   0.0s\n",
      "[CV 1/5] END C=0.01, degree=6, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.821) total time=   0.0s\n",
      "[CV 2/5] END C=0.01, degree=6, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.802) total time=   0.0s\n",
      "[CV 3/5] END C=0.01, degree=6, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.805) total time=   0.0s\n",
      "[CV 4/5] END C=0.01, degree=6, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.829) total time=   0.0s\n",
      "[CV 5/5] END C=0.01, degree=6, gamma=0.001, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.833) total time=   0.0s\n",
      "[CV 1/5] END C=0.01, degree=6, gamma=0.1, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.849) total time=   0.0s\n",
      "[CV 2/5] END C=0.01, degree=6, gamma=0.1, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.822) total time=   0.0s\n",
      "[CV 3/5] END C=0.01, degree=6, gamma=0.1, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.823) total time=   0.0s\n",
      "[CV 4/5] END C=0.01, degree=6, gamma=0.1, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.849) total time=   0.0s\n",
      "[CV 5/5] END C=0.01, degree=6, gamma=0.1, kernel=poly; acc: (test=0.575) f1: (test=0.730) fbeta: (test=0.931) pre: (test=0.575) rec: (test=1.000) roc: (test=0.853) total time=   0.0s\n",
      "[CV 1/5] END C=0.01, degree=6, gamma=10, kernel=poly; acc: (test=0.918) f1: (test=0.931) fbeta: (test=0.955) pre: (test=0.903) rec: (test=0.961) roc: (test=0.961) total time=   0.1s\n",
      "[CV 2/5] END C=0.01, degree=6, gamma=10, kernel=poly; acc: (test=0.949) f1: (test=0.957) fbeta: (test=0.976) pre: (test=0.935) rec: (test=0.980) roc: (test=0.962) total time=   0.1s\n",
      "[CV 3/5] END C=0.01, degree=6, gamma=10, kernel=poly; acc: (test=0.946) f1: (test=0.954) fbeta: (test=0.963) pre: (test=0.943) rec: (test=0.966) roc: (test=0.965) total time=   0.2s\n",
      "[CV 4/5] END C=0.01, degree=6, gamma=10, kernel=poly; acc: (test=0.938) f1: (test=0.948) fbeta: (test=0.978) pre: (test=0.914) rec: (test=0.985) roc: (test=0.976) total time=   0.1s\n",
      "[CV 5/5] END C=0.01, degree=6, gamma=10, kernel=poly; acc: (test=0.935) f1: (test=0.946) fbeta: (test=0.973) pre: (test=0.913) rec: (test=0.980) roc: (test=0.956) total time=   0.2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedShuffleSplit(n_splits=5, random_state=42, test_size=0.2,\n",
       "            train_size=None),\n",
       "             estimator=SVC(),\n",
       "             param_grid=[{&#x27;C&#x27;: [1, 100, 1000, 0.01],\n",
       "                          &#x27;gamma&#x27;: [0.0001, 0.001, 0.1, 10],\n",
       "                          &#x27;kernel&#x27;: [&#x27;rbf&#x27;]},\n",
       "                         {&#x27;C&#x27;: [1, 100, 1000, 0.01], &#x27;kernel&#x27;: [&#x27;linear&#x27;]},\n",
       "                         {&#x27;C&#x27;: [1, 100, 1000, 0.01], &#x27;degree&#x27;: [3, 5, 6],\n",
       "                          &#x27;gamma&#x27;: [0.0001, 0.001, 0.1, 10],\n",
       "                          &#x27;kernel&#x27;: [&#x27;poly&#x27;]}],\n",
       "             refit=&#x27;fbeta&#x27;,\n",
       "             scoring={&#x27;acc&#x27;: &#x27;accuracy&#x27;, &#x27;f1&#x27;: &#x27;f1&#x27;,\n",
       "                      &#x27;fbeta&#x27;: make_scorer(fbeta_score, beta=3),\n",
       "                      &#x27;pre&#x27;: &#x27;precision&#x27;, &#x27;rec&#x27;: &#x27;recall&#x27;, &#x27;roc&#x27;: &#x27;roc_auc&#x27;},\n",
       "             verbose=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedShuffleSplit(n_splits=5, random_state=42, test_size=0.2,\n",
       "            train_size=None),\n",
       "             estimator=SVC(),\n",
       "             param_grid=[{&#x27;C&#x27;: [1, 100, 1000, 0.01],\n",
       "                          &#x27;gamma&#x27;: [0.0001, 0.001, 0.1, 10],\n",
       "                          &#x27;kernel&#x27;: [&#x27;rbf&#x27;]},\n",
       "                         {&#x27;C&#x27;: [1, 100, 1000, 0.01], &#x27;kernel&#x27;: [&#x27;linear&#x27;]},\n",
       "                         {&#x27;C&#x27;: [1, 100, 1000, 0.01], &#x27;degree&#x27;: [3, 5, 6],\n",
       "                          &#x27;gamma&#x27;: [0.0001, 0.001, 0.1, 10],\n",
       "                          &#x27;kernel&#x27;: [&#x27;poly&#x27;]}],\n",
       "             refit=&#x27;fbeta&#x27;,\n",
       "             scoring={&#x27;acc&#x27;: &#x27;accuracy&#x27;, &#x27;f1&#x27;: &#x27;f1&#x27;,\n",
       "                      &#x27;fbeta&#x27;: make_scorer(fbeta_score, beta=3),\n",
       "                      &#x27;pre&#x27;: &#x27;precision&#x27;, &#x27;rec&#x27;: &#x27;recall&#x27;, &#x27;roc&#x27;: &#x27;roc_auc&#x27;},\n",
       "             verbose=4)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(n_splits=5, random_state=42, test_size=0.2,\n",
       "            train_size=None),\n",
       "             estimator=SVC(),\n",
       "             param_grid=[{'C': [1, 100, 1000, 0.01],\n",
       "                          'gamma': [0.0001, 0.001, 0.1, 10],\n",
       "                          'kernel': ['rbf']},\n",
       "                         {'C': [1, 100, 1000, 0.01], 'kernel': ['linear']},\n",
       "                         {'C': [1, 100, 1000, 0.01], 'degree': [3, 5, 6],\n",
       "                          'gamma': [0.0001, 0.001, 0.1, 10],\n",
       "                          'kernel': ['poly']}],\n",
       "             refit='fbeta',\n",
       "             scoring={'acc': 'accuracy', 'f1': 'f1',\n",
       "                      'fbeta': make_scorer(fbeta_score, beta=3),\n",
       "                      'pre': 'precision', 'rec': 'recall', 'roc': 'roc_auc'},\n",
       "             verbose=4)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grid_tune.fit(X_train_temp_scaled, y_train_temp)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_temp_scaled= pd.DataFrame(scaler.fit_transform(X_train_temp), columns=X_train_temp.columns)\n",
    "grid.fit(X_train_temp_scaled, y_train_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1, gamma=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, gamma=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=1, gamma=10)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_index_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean_fit_time                                      0.048542\n",
       "std_fit_time                                       0.004444\n",
       "mean_score_time                                    0.051838\n",
       "std_score_time                                     0.009952\n",
       "param_C                                                   1\n",
       "param_gamma                                              10\n",
       "param_kernel                                            rbf\n",
       "param_degree                                            NaN\n",
       "params               {'C': 1, 'gamma': 10, 'kernel': 'rbf'}\n",
       "split0_test_rec                                    0.990196\n",
       "split1_test_rec                                    0.995098\n",
       "split2_test_rec                                    0.990196\n",
       "split3_test_rec                                    0.995098\n",
       "split4_test_rec                                         1.0\n",
       "mean_test_rec                                      0.994118\n",
       "std_test_rec                                       0.003668\n",
       "rank_test_rec                                            37\n",
       "split0_test_pre                                    0.971154\n",
       "split1_test_pre                                    0.966667\n",
       "split2_test_pre                                    0.966507\n",
       "split3_test_pre                                    0.957547\n",
       "split4_test_pre                                    0.957746\n",
       "mean_test_pre                                      0.963924\n",
       "std_test_pre                                       0.005391\n",
       "rank_test_pre                                             3\n",
       "split0_test_f1                                     0.980583\n",
       "split1_test_f1                                     0.980676\n",
       "split2_test_f1                                     0.978208\n",
       "split3_test_f1                                     0.975962\n",
       "split4_test_f1                                     0.978417\n",
       "mean_test_f1                                       0.978769\n",
       "std_test_f1                                        0.001746\n",
       "rank_test_f1                                              3\n",
       "split0_test_fbeta                                  0.988258\n",
       "split1_test_fbeta                                   0.99218\n",
       "split2_test_fbeta                                  0.987775\n",
       "split3_test_fbeta                                  0.991211\n",
       "split4_test_fbeta                                  0.995608\n",
       "mean_test_fbeta                                    0.991006\n",
       "std_test_fbeta                                     0.002849\n",
       "rank_test_fbeta                                           1\n",
       "split0_test_acc                                    0.977465\n",
       "split1_test_acc                                    0.977465\n",
       "split2_test_acc                                    0.974648\n",
       "split3_test_acc                                    0.971831\n",
       "split4_test_acc                                    0.974648\n",
       "mean_test_acc                                      0.975211\n",
       "std_test_acc                                       0.002108\n",
       "rank_test_acc                                             3\n",
       "split0_test_roc                                    0.996559\n",
       "split1_test_roc                                    0.998312\n",
       "split2_test_roc                                     0.99789\n",
       "split3_test_roc                                    0.993183\n",
       "split4_test_roc                                     0.99815\n",
       "mean_test_roc                                      0.996819\n",
       "std_test_roc                                        0.00192\n",
       "rank_test_roc                                             3\n",
       "Name: 3, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd.DataFrame.from_dict(grid.cv_results_).iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(grid_tune.cv_results_).iloc[11,:]\n",
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise svm hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'C': 1, 'gamma': 10, 'kernel': 'rbf'} with a score of 0.99\n"
     ]
    }
   ],
   "source": [
    "#\"gamma\": [1e-4, 1e-3, 0.1,10 ], \"C\": [1, 100, 1000,0.01]\n",
    "C_range=[1, 100, 1000,0.01]\n",
    "gamma_range=[1e-4, 1e-3, 0.1,10 ]\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "grid_vis = GridSearchCV(SVC(), param_grid=param_grid, cv=cv)\n",
    "grid_vis.fit(X_train_temp_scaled, y_train_temp)\n",
    "\n",
    "print(\n",
    "    \"The best parameters are %s with a score of %0.2f\"\n",
    "    % (grid.best_params_, grid.best_score_)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(grid_vis.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores = grid_vis.cv_results_[\"mean_test_score\"].reshape(len(C_range), len(gamma_range))\n",
    "scores = grid.cv_results_[\"mean_test_score\"].reshape(len(C_range), len(gamma_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdoAAAGsCAYAAAB6n2ZzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAnmElEQVR4nO3dfZhdZX3v//fHIPIoDyL8lKCgDSraYjXic9VSNNTSqK0eUEGRNqVKT9tftaWen0dbay97PLbVIzRyjhGwCqWXUmKNgMeqqEVNUCCA0KaIEEPFiBXkOeH7+2OvqTubyWSSmTV7zcr7dV3rmtn3fa+97tmE+c73e6+HVBWSJKkdDxv3BCRJ6jMDrSRJLTLQSpLUIgOtJEktMtBKktQiA60kSS0y0KrXklSSn2m+X57kHdMZuwPHeV2SS3d0npL6K15Hqy5Lcgnw9ar67yPtS4EPAwuratMU+xewqKrWTeNY0xqb5FDgO8DDpzq2JIEZrbrvbODEJBlpPxH4uIGuXUl2GfccpPnOQKuu+wdgf+CFEw1J9gN+BTg3yVFJLk/yH0luTfKhJLtO9kZJzk7yZ0Ov39bssyHJm0bGvjzJt5LckeSWJO8a6r6s+fofSX6S5LlJ3pjkK0P7Py/J6iQ/br4+b6jvi0neneSrSe5McmmSA7Yy5/2S/GOSHyT5UfP9wqH+/ZN8tPkZfpTkH4b6lia5svkZ/i3Jkqb9piS/NDTuXUn+tvn+0KaEfkqSm4F/atr/Psm/Nz/PZUmeOrT/7knen+S7Tf9XmrbPJPmdkZ/n6iSvmOxnlfrKQKtOq6p7gAuAk4aaXwNcX1VXAZuB3wcOAJ4LHA28eVvv2wSdtwLHAIuAXxoZcldzzH2BlwO/PRQgfqH5um9V7VVVl4+89/7AZ4APAo8C/hL4TJJHDQ17LXAycCCwazOXyTwM+CjweOBxwD3Ah4b6PwbsATy1ea+/auZwFHAu8LbmZ/gF4KatHGMyLwKeArysef1ZBp/TgcA3gY8Pjf2fwDOB5zH4o+gPgQeBc4DXTwxKciRwMLBqO+YhzXsGWs0H5wCvTrJ78/qkpo2quqKqvlZVm6rqJgbrti+axnu+BvhoVV1TVXcB7xrurKovVtXaqnqwqq4Gzpvm+8IgMP9rVX2smdd5wPXAcUNjPlpV/zL0h8TTJ3ujqvphVX2yqu6uqjuB90zMI8ljgGOBU6vqR1X1QFV9qdn1FGBFVX2u+Rm+V1XXT3P+AO+qqrua+VFVK6rqzqq6j8FndWSSfZI8DHgT8LvNMTZX1T834y4CFiVZ1LznicDfVdX92zEPad4z0KrzquorwA+ApUmeADwL+ARAksObcuq/J7kD+HMG2e22PBa4Zej1d4c7kzw7yReaku2PgVOn+b4T7/3dkbbvMsjmJvz70Pd3A3tN9kZJ9kjy4aYseweDsvW+SRYAhwC3V9WPJtn1EODfpjnfyfznZ5NkQZL3NuXnO/hpZnxAs+022bGaYHsB8PomIJ/AIAOXdioGWs0X5zLIZE8ELq2q7zftf8MgW1xUVY8E3g6Mnjg1mVsZBKMJjxvp/wSwEjikqvYBlg+977ZO1d/AoNQ77HHA96Yxr1F/ADwJeHbz802UrcMgGO6fZN9J9rsFeOJW3vMuBuXmCf/PJGOGf8bXAksZlNf3AQ4dmsNG4N4pjnUO8DoGJf27R8vs0s7AQKv54lwGv+h/k6Zs3NgbuAP4SZInA789zfe7AHhjkiOS7AG8c6R/bwbZ4r3Neudrh/p+wGAN8glbee9VwOFJXptklyT/BTgC+Mdpzm10HvcwOPFq/+F5VtWtDNZOz2xOmnp4kolA/BHg5CRHJ3lYkoObzwfgSuD4Zvxi4NenMYf7gB8yCNB/PjSHB4EVwF8meWyT/T43ySOa/ssZfFbvx2xWOykDreaFZv31n4E9GWSaE97KIAjeCfxv4O+m+X6fBf6awVm165qvw94M/GmSO4H/ziAwT+x7N4O10q9mcLbzc0be+4cMzor+AwbB6Q+BX6mqjdOZ24i/BnZnkDl+Dbh4pP9E4AEGWf1twO81c/gGg5Ot/gr4MfAlfpplv4NBBvoj4E9oyvBTOJdB6ft7wHXNPIa9FVgLrAZuB/6CLX+3nAv8LPC32ziO1EvesEJSq5KcBCyrqheMey7SOJjRSmpNU5Z/M3DWuOcijYuBVlIrkryMwXr299l2eVrqLUvHkiS1yIxWkqQW9faG4UnKvyI0n/z8Y8Y9g5567DPGPYNeuumm77Jx48bpXLO+XZYsWVIbN+7ICfo/dcUVV1xSVUtmaUoz1ttA+zAGt6uR5os1vzHuGfTUn3593DPopcWLn93K+27cuJE1a9bM6D229pCOceltoJUkzUcF9OvplwZaSVLHGGglSWpJ/zJazxeSJKlFZrSSpA7pX0ZroJUkdYiBVpKkFvUv0LpGK0lSi8xoJUkd0r+M1kArSeoYA60kSS0pYPO4JzGrXKOVJKlFZrSSpA5xjVaSpBYZaCVJalm/Aq1rtJIktciMVpLUIZaOJUlqUf8CraVjSdJOJ8mSJDckWZfk9En690tyYZKrk3wjydOG+m5KsjbJlUnWbOtYZrSSpA5pP6NNsgA4AzgGWA+sTrKyqq4bGvZ24MqqemWSJzfjjx7qf0lVbZzO8cxoJUkdMhFoZ7Jt01HAuqq6saruB84Hlo6MOQL4PEBVXQ8cmuSgHfmJDLSSpI6ZcaA9IMmaoW3ZyAEOBm4Zer2+aRt2FfAqgCRHAY8HFjZ9BVya5IpJ3vshLB1LkvpmY1UtnqI/k7TVyOv3Ah9IciWwFvgWP02Xn19VG5IcCHwuyfVVddnWDmaglSR1yJycdbweOGTo9UJgwxazqLoDOBkgSYDvNBtVtaH5eluSCxmUorcaaC0dS5I6ZE7WaFcDi5IclmRX4Hhg5fCAJPs2fQC/AVxWVXck2TPJ3s2YPYGXAtdMdTAzWklSh7Sf0VbVpiSnAZcAC4AVVXVtklOb/uXAU4Bzk2wGrgNOaXY/CLhwkOSyC/CJqrp4quMZaCVJO52qWgWsGmlbPvT95cCiSfa7EThye45loJUkdUj/7gxloJUkdYyBVpKklvQvo/WsY0mSWmRGK0nqkP5ltAZaSVKHFLB53JOYVQZaSVKH9C+jdY1WkqQWmdFKkjqmXxmtgVaS1CH9Kx0baCVJHdK/QDsv1miTrEhyW5Ipn5AgSVLXzItAC5wNLBn3JCRJbZuTx+TNqXlROq6qy5IcOu55SJLa1r/S8bwItNOVZBmwDCBjnoskaUcZaDurqs4CzgJYkNSYpyNJUr8CrSRpvrN0LElSi/oXaOfFWcdJzgMuB56UZH2SU8Y9J0mSpmNeZLRVdcK45yBJmgv9y2jnRaCVJO0sDLSSJLWsX4F2XqzRSpI0X5nRSpI6xNKxJEktMtBKktSi/gVa12glSWqRGa0kqWM2j3sCs8pAK0nqkP6Vjg20kqQO6V+gdY1WkqQWmdFKkjqkfxmtgVaS1CEGWkmSWtS/QOsarSRpp5NkSZIbkqxLcvok/fsluTDJ1Um+keRp0913lIFWktQxm2a4TS3JAuAM4FjgCOCEJEeMDHs7cGVV/RxwEvCB7dh3CwZaSVKHTJSO2wu0wFHAuqq6saruB84Hlo6MOQL4PEBVXQ8cmuSgae67BQOtJKlDZiXQHpBkzdC2bOQgBwO3DL1e37QNuwp4FUCSo4DHAwunue8WPBlKktQ3G6tq8RT9maStRl6/F/hAkiuBtcC3GETx6ey7BQOtJKlD5uSs4/XAIUOvFwIbtphF1R3AyQBJAnyn2fbY1r6jLB1LkjpkTtZoVwOLkhyWZFfgeGDl8IAk+zZ9AL8BXNYE323uO8qMVpLUMe1mtFW1KclpwCXAAmBFVV2b5NSmfznwFODcJJuB64BTptp3quMZaCVJO52qWgWsGmlbPvT95cCi6e47FQOtJKlD+ndnKAOtJKlD+hdoPRlKkqQWmdFKkjqkfxmtgVaS1CEGWkmSWrZ53BOYVa7RSpLUIjNaSVKHWDqWJKlFBlpJklrUv0DrGq0kSS0yo5UkdUy/MloDrSSpQ/pXOjbQSpI6xEA7bxwE/Oa4J9FDf/K2cc+gx9467gn0VW9/zY1Zxj2BecN/gZKkDjGjlSSpXdWvWzAaaCVJ3fLguCcwu7yOVpKkFpnRSpK6o+jbw3sMtJKkDjHQSpLUMtdoJUnSdJnRSpK6w9KxJEkt61np2EArSeqOHma0rtFKktQiM1pJUrf0LKM10EqSuqPo3RqtpWNJklpkRitJ6hZLx5IktaSHZx0baCVJ3eIarSRJmi4DrSSpOyZKxzPZpiHJkiQ3JFmX5PRJ+vdJ8ukkVyW5NsnJQ303JVmb5Moka7Z1LEvHkqRuabl0nGQBcAZwDLAeWJ1kZVVdNzTsLcB1VXVckkcDNyT5eFXd3/S/pKo2Tud4BlpJUnfMzclQRwHrqupGgCTnA0uB4UBbwN5JAuwF3A5s2pGDWTqWJPXNAUnWDG3LRvoPBm4Zer2+aRv2IeApwAZgLfC7VTWRaxdwaZIrJnnvhzCjlSR1x+xktBuravEU/dnKkYe9DLgS+EXgicDnkny5qu4Anl9VG5Ic2LRfX1WXbe1gZrSSpG55cIbbtq0HDhl6vZBB5jrsZOBTNbAO+A7wZICq2tB8vQ24kEEpeqsMtJKk7pibs45XA4uSHJZkV+B4YOXImJuBowGSHAQ8CbgxyZ5J9m7a9wReClwz1cEsHUuSdipVtSnJacAlwAJgRVVdm+TUpn858G7g7CRrGZSa/6iqNiZ5AnDh4BwpdgE+UVUXT3U8A60kqVvm4BaMVbUKWDXStnzo+w0MstXR/W4EjtyeYxloJUnd0cPH5BloJUnd0rOHCngylCRJLTKjlSR1h6VjSZJa1rPSsYFWktQdPXzwu2u0kiS1yIxWktQtrtFKktSSHpaODbSSpG7pWaB1jVaSpBaZ0UqSuqOH19GOJaNNsiLJbUmuGWrbP8nnkvxr83W/ob4/TrIuyQ1JXjaOOUuS5kj7j8mbU+MqHZ8NLBlpOx34fFUtAj7fvCbJEQyeFfjUZp8zkyyYu6lKkrTjxhJoq+oy4PaR5qXAOc335wCvGGo/v6ruq6rvAOvYxtPsJUnz1ETpeCZbx3RpjfagqroVoKpuTXJg034w8LWhceubtodIsgxYBrBPixOVJLWog+XfmehSoN2aTNJWkw2sqrOAswAem0w6RpLUYT28jrZLl/d8P8ljAJqvtzXt64FDhsYtBDbM8dwkSdohXQq0K4E3NN+/AbhoqP34JI9IchiwCPjGGOYnSZoLrtHOXJLzgBcDByRZD7wTeC9wQZJTgJuBVwNU1bVJLgCuAzYBb6mqnhUWJElAL0vHYwm0VXXCVrqO3sr49wDvaW9GkqRO6GGg7VLpWJKk3pkPZx1LknYmHVxnnQkDrSSpO3pYOjbQSpK6pWcZrWu0kiS1yIxWktQdlo4lSWqZgVaSpJb44HdJkrQ9zGglSd1i6ViSpJb0sHRsoJUkdUvPMlrXaCVJapGBVpLUHRPX0c5km4YkS5LckGRdktMn6d8nyaeTXJXk2iQnT3ffUQZaSVK3tPzg9yQLgDOAY4EjgBOSHDEy7C3AdVV1JIPnp78/ya7T3HcLBlpJUnfMTUZ7FLCuqm6sqvuB84Glk8xk7yQB9gJuBzZNc98tGGglSX1zQJI1Q9uykf6DgVuGXq9v2oZ9CHgKsAFYC/xuVT04zX234FnHkqTumJ17HW+sqsVT9GcrRx72MuBK4BeBJwKfS/Llae67BTNaSVK3tLxGyyALPWTo9UIGmeuwk4FP1cA64DvAk6e57xYMtJKknc1qYFGSw5LsChwPrBwZczNwNECSg4AnATdOc98tWDqWJHXHHDwmr6o2JTkNuARYAKyoqmuTnNr0LwfeDZydZC2DcvEfVdVGgMn2nep4BlpJUrfMwS0Yq2oVsGqkbfnQ9xuAl05336kYaCVJ3dHDB7+7RitJUovMaCVJ3dKzjNZAK0nqDh+TJ0lSy3qW0bpGK0lSi8xoJUnd0cOzjg20kqRucY1WkqSW9DCjdY1WkqQWmdFKkrrF0rEkSS3pYenYQCtJ6paeBdop12iT/EyS50/S/sIkT2xvWpIk9cO2Tob6a+DOSdrvafokSZo9E7dgnMnWMdsqHR9aVVePNlbVmiSHtjOl2fHYg+BPThr3LHpowbgn0GOPPHzcM5C6oWel420F2t2m6Nt9NiciSVIfT4baVul4dZLfHG1McgpwRTtTkiSpP7aV0f4ecGGS1/HTwLoY2BV4ZYvzkiTtrDq4zjoTUwbaqvo+8LwkLwGe1jR/pqr+qfWZSZJ2Pj0sHU/rOtqq+gLwhZbnIkna2fXwwe/e61iSpBZ5ZyhJUrfsjKVjSZLmRA/XaC0dS5LUIjNaSVK39OxkKAOtJKk7elg6NtBKkrqlZ4HWNVpJklpkRitJ6o4e3rDCQCtJ6paelY4NtJKk7uhhRusarSRJLTKjlSR1S89Kx2a0kqTumLiOdibbNCRZkuSGJOuSnD5J/9uSXNls1yTZnGT/pu+mJGubvjXbOpYZrSSpW1peo02yADgDOAZYD6xOsrKqrpsYU1XvA97XjD8O+P2qun3obV5SVRunczwzWknSzuYoYF1V3VhV9wPnA0unGH8CcN6OHsxAK0nqjtkpHR+QZM3QtmzkKAcDtwy9Xt+0PUSSPYAlwCdHZnlpkismee+HsHQsSeqO2bnX8caqWjxFf7Zy5MkcB3x1pGz8/KrakORA4HNJrq+qy7Z2MDNaSVK3PDjDbdvWA4cMvV4IbNjK2OMZKRtX1Ybm623AhQxK0VtloJUk7WxWA4uSHJZkVwbBdOXooCT7AC8CLhpq2zPJ3hPfAy8FrpnqYJaOJUndMQePyauqTUlOAy4BFgArquraJKc2/cuboa8ELq2qu4Z2Pwi4MAkMYugnquriqY5noJUkdcsc3IKxqlYBq0balo+8Phs4e6TtRuDI7TmWgVaS1B09fPC7a7SSJLXIjFaS1C09y2gNtJKk7ujhY/IMtJKkbulZRusarSRJLTKjlSR1Rw/POjbQSpK6pWdrtJaOJUlqkRmtJKk7LB1LktSynpWODbSSpO7oYUbb2hptkhVJbktyzVDb/kk+l+Rfm6/7DfX9cZJ1SW5I8rKh9mcmWdv0fTDNIxMkSZoP2jwZ6mxgyUjb6cDnq2oR8PnmNUmOYPA8wKc2+5yZZEGzz98Ay4BFzTb6npKkPtk8w61jWgu0VXUZcPtI81LgnOb7c4BXDLWfX1X3VdV3gHXAUUkeAzyyqi6vqgLOHdpHktQ3E7dgnMnWMXO9RntQVd0KUFW3JjmwaT8Y+NrQuPVN2wPN96Ptk0qyjEH2y+MeOYuzliTNnQ5mpTPRletoJ1t3rSnaJ1VVZ1XV4qpa/OjdZ21ukiTtsLnOaL+f5DFNNvsY4LamfT1wyNC4hcCGpn3hJO2SpD7yrOMZWwm8ofn+DcBFQ+3HJ3lEksMYnPT0jabMfGeS5zRnG580tI8kqY9co52eJOcBLwYOSLIeeCfwXuCCJKcANwOvBqiqa5NcAFwHbALeUlUTf9P8NoMzmHcHPttskqSe6llC216graoTttJ19FbGvwd4zyTta4CnzeLUJEmaM94ZSpLUGT1cojXQSpK6pYPLrDNioJUkdUYfM9quXEcrSVIvmdFKkjrF0rEkSS3pY+nYQCtJ6ow+BlrXaCVJapEZrSSpU1yjlSSpJX0sHRtoJUmd0rdA6xqtJEktMqOVJHVG0b81WjNaSVKnbJ7hNh1JliS5Icm6JKdP0v+2JFc22zVJNifZfzr7jjLQSpJ2KkkWAGcAxwJHACckOWJ4TFW9r6qeXlVPB/4Y+FJV3T6dfUcZaCVJnTFROp7JNg1HAeuq6saquh84H1g6xfgTgPN2cF8DrSSpW2ahdHxAkjVD27KRQxwM3DL0en3T9hBJ9gCWAJ/c3n0neDKUJKkzZuk62o1VtXiK/mzl0JM5DvhqVd2+A/sCZrSSpJ3PeuCQodcLgQ1bGXs8Py0bb+++gIFWktQxc7BGuxpYlOSwJLsyCKYrRwcl2Qd4EXDR9u47zNKxJKkz5uIWjFW1KclpwCXAAmBFVV2b5NSmf3kz9JXApVV117b2nep4BlpJUmfM1b2Oq2oVsGqkbfnI67OBs6ez71QsHUuS1CIzWklSp/TtFowGWklSZ/iYPEmSWta3jNY1WkmSWmRGK0nqDEvHkiS1zEArSVJLfPC7JEnaLma0kqROsXQsSVJLPBlKkqSWuUYrSZKmzYxWktQZlo4lSWpZ30rHqapxz6EVC5LabdyTkKSeuhfYXJXZft+fSer9M3yPV8AVVbV4NuYzG1yjlSSpRZaOJUmd4hqtJEkt8RaMkiRpu5jRSpI6xdKxJEkt8TpaSZJa5hqtJEmaNjNaSVJnWDqWJKlFfby8x0ArSeqUvmW0rtFKktQiM1pJUme4RitJUstco5UkqSV9zGhdo5UkqUVmtJKkTulbRmuglSR1Rh+vo7V0LEnqlM0z3KYjyZIkNyRZl+T0rYx5cZIrk1yb5EtD7TclWdv0rdnWscxoJUk7lSQLgDOAY4D1wOokK6vquqEx+wJnAkuq6uYkB468zUuqauN0jmdGK0nqjInS8Uy2aTgKWFdVN1bV/cD5wNKRMa8FPlVVNwNU1W07+jMZaCVJnTILpeMDkqwZ2paNHOJg4Jah1+ubtmGHA/sl+WKSK5KcNNRXwKVN++h7P4SlY0lSZ8zSdbQbq2rxFP3ZyqGH7QI8Ezga2B24PMnXqupfgOdX1YamnPy5JNdX1WVbO5gZrSRpZ7MeOGTo9UJgwyRjLq6qu5q12MuAIwGqakPz9TbgQgal6K0y0EqSOmUO1mhXA4uSHJZkV+B4YOXImIuAFybZJckewLOBbyfZM8neAEn2BF4KXDPVwSwdS5I6Yy5uwVhVm5KcBlwCLABWVNW1SU5t+pdX1beTXAxczSB+/5+quibJE4ALk8Aghn6iqi6e6nipGi1L98OCpHYb9yQkqafuBTZXTbbWOSOPSeqUGb7He+CKbazRzilLx5IktcjSsSSpU/p2C0YDrSSpM3xMniRJ2i5mtJKkTrF0LElSS/pYOjbQSpI6pW+B1jVaSZJaZEYrSeqMicfk9YmBVpLUKX0rHRtoJUmd0ceToVyjlSSpRWa0kqRO6dsa7ZxltEmWJLkhybokp0/SnyQfbPqvTvKMob4VSW5LMuUz/yRJ89tE6XgmW9fMSaBNsgA4AzgWOAI4IckRI8OOBRY12zLgb4b6zgaWtD9TSdK4zcGD3+fUXGW0RwHrqurGqrofOB9YOjJmKXBuDXwN2DfJYwCq6jLg9jmaqyRJs2auAu3BwC1Dr9c3bds7ZkpJliVZk2RNPx9nL0n91sfS8VydDJVJ2kZj4XTGTKmqzgLOAliQGGslaR7qYrCcibkKtOuBQ4ZeLwQ27MAYSVKP9fHOUHNVOl4NLEpyWJJdgeOBlSNjVgInNWcfPwf4cVXdOkfzkySpFXOS0VbVpiSnAZcAC4AVVXVtklOb/uXAKuCXgXXA3cDJE/snOQ94MXBAkvXAO6vqI3Mxd0nS3Opb6ThV/VzKXJDUbuOehCT11L3A5qrJzq2Zkf2SeskM3+NCuKKqFs/KhGaBd4aSJHWGa7SSJGm7mNFKkjqlb2u0BlpJUmf0sXRsoJUkdUrfMlrXaCVJapEZrSSpMybuddwnBlpJUqf0bY3W0rEkSS0yo5UkdYalY0mSWmaglSSpJX28jtY1WknSTifJkiQ3JFmX5PStjHlxkiuTXJvkS9uz7zAzWklSp7RdOk6yADgDOAZYD6xOsrKqrhsasy9wJrCkqm5OcuB09x1lRitJ6oyJ0vFMtmk4ClhXVTdW1f3A+cDSkTGvBT5VVTcDVNVt27HvFgy0kqRO2TzDDTggyZqhbdnIIQ4Gbhl6vb5pG3Y4sF+SLya5IslJ27HvFiwdS5L6ZuM2Hvw+2QPra+T1LsAzgaOB3YHLk3xtmvs+5I0kSeqEObqOdj1wyNDrhcCGScZsrKq7gLuSXAYcOc19t2DpWJLUKXOwRrsaWJTksCS7AscDK0fGXAS8MMkuSfYAng18e5r7bsGMVpLUGXOR0VbVpiSnAZcAC4AVVXVtklOb/uVV9e0kFwNXM4jf/6eqrgGYbN+pjpeqKUvL89aCpHYb9yQkqafuBTZXTbZeOSO7J/WEGb7HdXDFNtZo55QZrSSpM7zXsSRJLevbLRgNtJKkzuhjRutZx5IktciMVpLUKZaOJUlqSR9LxwZaSVKn9C3QukYrSVKLzGglSZ0x8Zi8PjHQSpI6pW+lYwOtJKkz+ngylGu0kiS1yIxWktQprtFKktQSS8eSJGm7mNFKkjrF0vE88SBsvBu+O+55TNMBwMZxT6KH/Fzb42fbjvn0uT6+jTd9EC65a/A5zESnPsNU1bjnsNNLsqaqFo97Hn3j59oeP9t2+Ln2k2u0kiS1yEArSVKLDLTdcNa4J9BTfq7t8bNth59rD7lGK0lSi8xoJUlqkYFWkqQWGWglSWqRgXYeSOJ/J3VOkox7Dn3lZ9sv/gLvqCTPS3IiQFU9aLCduST7jHsOfZDk0UkeVlVlQJgdSZ6d5EVJngXgZ9sv/vLuoCTHAP8XWJrkzWCwnakkrwIuT/ICP8cdl+QVwN8DJyRZYECYuSTHAn8LvA74b0k+AgbbPvHyng5K8ibgIOCbwCuBq6vqzKbvYVXVt3tutyrJ44FzgHuAnwB/CXzdz3H7NJ/jKuAaYB2wFvj7qtqcJOUvk+2WZAHwceAzVfWxJI9k8Bn/e1X9ejPGz3ae8y/7DqqqFcBfA5cBnwd+NslpTd+Dzf+cmr4HgHdW1bHAGuD/A56dZIuHapg9bNMPgZOB3wY2AM8FXp1k1yb78t/ldqqqzcC3hl7fUVUvAA5K8uGmzSA7zxloOyLJc5Mck+S5AFV1T1XdA3wW+ALw1CSvSfJG4FVjnOq8kWRvgKraAHy1+f4vGPwB8w7gWc24pzd9/kKbQlX9hEF15XbgI8C/MAi2v9YMWTiuuc03SQ4fevk94I+SPG6o7ZXAo5IcMbczUxssHXdAkiXA/2KQvT4auKeqXj/UvxfwTOB/AE8GXlhVV49jrvNFkl9lsOYFg7LxtVX13aH+PwKeAdwMHAscXVXfn/OJzkMTpcwkewJvZLDM8UTgJcBTq+pH45xf1yX5FeACYGVVHd+0vZvBZ/n8qrq5aTsf+Kuq+vq45qrZYaAds+bEnHOBz1fVR5PsAXwauLuqjhsa9wfAWxkEhOvGM9v5ockWvgC8BlgMHAjsBZxZVTcMjbsU+FngpVW1dhxz7bIkTwL2Z1Buf3B4LXZ43TDJRcDPAa+oqqvGOOXOa/44+STwKeB5wCOq6oSm793ArwJnMnge6+uBX66q74xpupollo7HrDkh5yqa/xZVdXdVHQ3snuTsoaH3MvifziC7bbsBX6mqr1bVBxj8YvsB8FtJFgIkeTLwKGCJQfahmrO0LwL+jEGZ+C1JHtkE2YlLexY0wfi5wFKD7LZV1V3Am4BPMPjD+eFJzmv63gG8i8HvgsOAVxtk+8GMdkyS7NWseZHk5QzOhD2uqv6laduXwZM83uMvsO2TZFfgcuAjQ2drPxP4L8DFVfVPSR7NYFl24xin2klJHs7gcpMPVtVXk/wa8BzgPuB9VfXjkfGPrqofjGGq816SRzH4//z+qjohyVOBnwwvc2j+M6Mdg2b98CNJ/i7JLwOXAP8T+HKTIVBV/wFsBvYe20TnkSRHJXl+khdU1f3A24FnJTkeoKquAG4HJm4C8gOD7JQeCSxqvr8Q+EdgV2CizPns5t8uBtkdV1U/BH4LuDfJDQyqCJvHOyvNNgPtHGvWD/8G+CDwz8AvMAiyHwf+G3Bhkt9J8g7g6Qwuo9AUkrwMWAm8HPhYklOB6xmcXLYkyX9thn5vMDyPGM9M54eqeoBBheVVSV7YLG98BbgSeGHz+T2eoctStOOaP/iuBvYBXllV68c8Jc2yXbY9RLPsP9cPga8meQZwHIO1sLcxOAv2CQwulfj1qrpxbDPtuOa614ks679W1QVJ/h54H4N/2//A4A+V9yf5BQaX8/xqVd03pinPJ18GngSc2Jz4dBnwiSS/CTy+qi4Y7/T6I8l+wC/jSXm9ZaCde9cDP5PkzVV1ZlV9swkYrwVeVFWXjnl+80Zz1ut9Sb4N/FySVVX1rSS/x+ByqQeq6sNJjgIeB9xZVbeNccrzRlXdm+TjQAF/3Jw8dh+DM7h/POXO2i5V9aMkx1XVveOei9ph6XgOTHP98AfASeOc5zx2NYMziJ+YZJequobBGZ1/mOSZVfVAVf2bQXb7NNfD/m8G12//IoPrZF/v9cazzyDbbwbalm3n+iGuH07fxC0Tq+qzDO5h/LvA05ozuq8ALsYTS2akqu6vqi8wuPnHm6rKdVlpO3l5T0uG1g8/DKxq1g9/nsH64T802+HA+4F/46frh17KM4XJbqIw1Pc/GJylfS9wC/AHDO60c9MYpipJgIG2dc2t/vYG3ltVP0nyNAbrh+c364cPx/XDaWluovDnDLL/7zEItmdX1R1DY17C4C5FhwNneIMPSeNmoG1ZBs+a/FVgOYP77W5qbp5wAfCapsSpbdiBmyjsUlWbxjBVSdqCa7Qtcf2wFdu6icJzmrtsgZ+tpI4w0M6iJE9qHnf3cIY+26p6G7CRwR1g3p3k/wVeAfzHOOY5H03zJgqPA77ZjLdUI6kTLB3PEtcP25dkN+A3GHyGf9vcRIEkXwB+a+I+0ZLUJQbaWeD64dxp7qLzWuBXGJSP7wP+EPhFr++U1EWWjmeP64dzwJsoSJpvzGhnSZJjgN9hkMF+OckCBo9lezmD508uBb5cVbeOcZq90nzG1azXSlInGWhnieuHkqTJ+FCBWeJN2CVJkzGjnWVJdgWeT/MwZ+AD3h9WknZeBtqWuH4oSQIDrSRJrfLyHkmSWmSglSSpRQZaSZJaZKCVJKlFBlpJklpkoJUkqUUGWkmSWuQtGKUZSvIO4HXALcBG4AoGt91cxuAJTuuAE6vq7iRnA/cATwYeD5wMvAF4LvD1qnpj854/Ac4Afgn4EfB2Bk8sehzwe1W1MsmhwMeAPZupnFZV/9zyjytpO5nRSjOQZDHwa8DPA68CFjddn6qqZ1XVkcC3gVOGdtuPwSP+fh/4NPBXwFOBn03y9GbMnsAXq+qZwJ3AnwHHAK8E/rQZcxtwTFU9g8GToj7Yxs8oaWbMaKWZeQFwUVXdA5Dk003705L8GbAvsBdwydA+n66qSrIW+H5VrW32vRY4FLgSuB+4uBm/Frivqh5o9jm0aX848KEmOG8GDm/h55M0QwZaaWaylfazgVdU1VVJ3gi8eKjvvubrg0PfT7ye+H/ygfrp/VH/c1xVPZhkYszvA98HjmRQnbp3h38KSa2xdCzNzFeA45LslmQv4OVN+97ArUkezmD9tg37ALc2D644EVjQ0nEkzYAZrTQDVbU6yUrgKuC7wBoGJ0K9A/h607aWQeCdbWcCn0zyauALwF0tHEPSDPn0HmmGkuxVVT9JsgdwGbCsqr457nlJ6gYzWmnmzkpyBLAbcI5BVtIwM1pJklrkyVCSJLXIQCtJUosMtJIktchAK0lSiwy0kiS16P8Hn3l2j6RcWS0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#heatmap of the classifier’s cross-validation accuracy as a function of C and gamma\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.subplots_adjust(left=0.2, right=0.95, bottom=0.15, top=0.95)\n",
    "plt.imshow(\n",
    "    scores,\n",
    "    interpolation=\"nearest\",\n",
    "    cmap=plt.cm.hot,\n",
    "    #norm=MidpointNormalize(vmin=0.2, midpoint=0.92),\n",
    ")\n",
    "plt.xlabel(\"gamma\")\n",
    "plt.ylabel(\"C\")\n",
    "plt.colorbar()\n",
    "plt.xticks(np.arange(len(gamma_range)), gamma_range, rotation=45)\n",
    "plt.yticks(np.arange(len(C_range)), C_range)\n",
    "plt.title(\"Validation accuracy\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.574648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.627042</td>\n",
       "      <td>0.796620</td>\n",
       "      <td>0.722817</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.574648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.797183</td>\n",
       "      <td>0.859718</td>\n",
       "      <td>0.975211</td>\n",
       "      <td>0.891268</td>\n",
       "      <td>0.574648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.643380</td>\n",
       "      <td>0.791549</td>\n",
       "      <td>0.824225</td>\n",
       "      <td>0.916620</td>\n",
       "      <td>0.976901</td>\n",
       "      <td>0.899155</td>\n",
       "      <td>0.574648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.643944</td>\n",
       "      <td>0.792113</td>\n",
       "      <td>0.798310</td>\n",
       "      <td>0.865915</td>\n",
       "      <td>0.949859</td>\n",
       "      <td>0.976901</td>\n",
       "      <td>0.899155</td>\n",
       "      <td>0.574648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.643944</td>\n",
       "      <td>0.792113</td>\n",
       "      <td>0.793239</td>\n",
       "      <td>0.833803</td>\n",
       "      <td>0.889577</td>\n",
       "      <td>0.949296</td>\n",
       "      <td>0.976901</td>\n",
       "      <td>0.899155</td>\n",
       "      <td>0.574648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.643380</td>\n",
       "      <td>0.790986</td>\n",
       "      <td>0.790986</td>\n",
       "      <td>0.799437</td>\n",
       "      <td>0.865915</td>\n",
       "      <td>0.919437</td>\n",
       "      <td>0.947606</td>\n",
       "      <td>0.976901</td>\n",
       "      <td>0.899155</td>\n",
       "      <td>0.574648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.653521</td>\n",
       "      <td>0.793239</td>\n",
       "      <td>0.788169</td>\n",
       "      <td>0.797183</td>\n",
       "      <td>0.835493</td>\n",
       "      <td>0.884507</td>\n",
       "      <td>0.936338</td>\n",
       "      <td>0.947606</td>\n",
       "      <td>0.976901</td>\n",
       "      <td>0.899155</td>\n",
       "      <td>0.574648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.574648</td>\n",
       "      <td>0.701408</td>\n",
       "      <td>0.789296</td>\n",
       "      <td>0.793239</td>\n",
       "      <td>0.791549</td>\n",
       "      <td>0.804507</td>\n",
       "      <td>0.870986</td>\n",
       "      <td>0.902535</td>\n",
       "      <td>0.936901</td>\n",
       "      <td>0.947606</td>\n",
       "      <td>0.976901</td>\n",
       "      <td>0.899155</td>\n",
       "      <td>0.574648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.690141</td>\n",
       "      <td>0.609014</td>\n",
       "      <td>0.709859</td>\n",
       "      <td>0.791549</td>\n",
       "      <td>0.785915</td>\n",
       "      <td>0.811268</td>\n",
       "      <td>0.872113</td>\n",
       "      <td>0.904789</td>\n",
       "      <td>0.936901</td>\n",
       "      <td>0.947606</td>\n",
       "      <td>0.976901</td>\n",
       "      <td>0.899155</td>\n",
       "      <td>0.574648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.503099</td>\n",
       "      <td>0.576338</td>\n",
       "      <td>0.699155</td>\n",
       "      <td>0.789859</td>\n",
       "      <td>0.787606</td>\n",
       "      <td>0.803944</td>\n",
       "      <td>0.871549</td>\n",
       "      <td>0.899718</td>\n",
       "      <td>0.936901</td>\n",
       "      <td>0.947606</td>\n",
       "      <td>0.976901</td>\n",
       "      <td>0.899155</td>\n",
       "      <td>0.574648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.499155</td>\n",
       "      <td>0.577465</td>\n",
       "      <td>0.693521</td>\n",
       "      <td>0.793239</td>\n",
       "      <td>0.782535</td>\n",
       "      <td>0.807887</td>\n",
       "      <td>0.870986</td>\n",
       "      <td>0.899155</td>\n",
       "      <td>0.936901</td>\n",
       "      <td>0.947606</td>\n",
       "      <td>0.976901</td>\n",
       "      <td>0.899155</td>\n",
       "      <td>0.574648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.498592</td>\n",
       "      <td>0.577465</td>\n",
       "      <td>0.714366</td>\n",
       "      <td>0.785352</td>\n",
       "      <td>0.782535</td>\n",
       "      <td>0.802817</td>\n",
       "      <td>0.875493</td>\n",
       "      <td>0.897465</td>\n",
       "      <td>0.936901</td>\n",
       "      <td>0.947606</td>\n",
       "      <td>0.976901</td>\n",
       "      <td>0.899155</td>\n",
       "      <td>0.574648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0   0.574648  0.574648  0.574648  0.574648  0.574648  0.574648  0.574648   \n",
       "1   0.574648  0.574648  0.574648  0.574648  0.574648  0.574648  0.574648   \n",
       "2   0.574648  0.574648  0.574648  0.574648  0.574648  0.574648  0.574648   \n",
       "3   0.574648  0.574648  0.574648  0.574648  0.574648  0.574648  0.643380   \n",
       "4   0.574648  0.574648  0.574648  0.574648  0.574648  0.643944  0.792113   \n",
       "5   0.574648  0.574648  0.574648  0.574648  0.643944  0.792113  0.793239   \n",
       "6   0.574648  0.574648  0.574648  0.643380  0.790986  0.790986  0.799437   \n",
       "7   0.574648  0.574648  0.653521  0.793239  0.788169  0.797183  0.835493   \n",
       "8   0.574648  0.701408  0.789296  0.793239  0.791549  0.804507  0.870986   \n",
       "9   0.690141  0.609014  0.709859  0.791549  0.785915  0.811268  0.872113   \n",
       "10  0.503099  0.576338  0.699155  0.789859  0.787606  0.803944  0.871549   \n",
       "11  0.499155  0.577465  0.693521  0.793239  0.782535  0.807887  0.870986   \n",
       "12  0.498592  0.577465  0.714366  0.785352  0.782535  0.802817  0.875493   \n",
       "\n",
       "          7         8         9         10        11        12  \n",
       "0   0.574648  0.574648  0.574648  0.574648  0.574648  0.574648  \n",
       "1   0.574648  0.627042  0.796620  0.722817  0.574648  0.574648  \n",
       "2   0.640000  0.797183  0.859718  0.975211  0.891268  0.574648  \n",
       "3   0.791549  0.824225  0.916620  0.976901  0.899155  0.574648  \n",
       "4   0.798310  0.865915  0.949859  0.976901  0.899155  0.574648  \n",
       "5   0.833803  0.889577  0.949296  0.976901  0.899155  0.574648  \n",
       "6   0.865915  0.919437  0.947606  0.976901  0.899155  0.574648  \n",
       "7   0.884507  0.936338  0.947606  0.976901  0.899155  0.574648  \n",
       "8   0.902535  0.936901  0.947606  0.976901  0.899155  0.574648  \n",
       "9   0.904789  0.936901  0.947606  0.976901  0.899155  0.574648  \n",
       "10  0.899718  0.936901  0.947606  0.976901  0.899155  0.574648  \n",
       "11  0.899155  0.936901  0.947606  0.976901  0.899155  0.574648  \n",
       "12  0.897465  0.936901  0.947606  0.976901  0.899155  0.574648  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(scores1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MidpointNormalize(Normalize):\n",
    "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "        self.midpoint = midpoint\n",
    "        Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "    def __call__(self, value, clip=None):\n",
    "        x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]\n",
    "        return np.ma.masked_array(np.interp(value, x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.subplots_adjust(left=0.2, right=0.95, bottom=0.15, top=0.95)\n",
    "plt.imshow(\n",
    "    scores1,\n",
    "    interpolation=\"nearest\",\n",
    "    cmap=plt.cm.hot,\n",
    "    norm=MidpointNormalize(vmin=0.4,midpoint=0.85),\n",
    ")\n",
    "plt.xlabel(\"gamma\")\n",
    "plt.ylabel(\"C\")\n",
    "plt.colorbar()\n",
    "plt.xticks(np.arange(len(gamma_range)), gamma_range, rotation=45)\n",
    "plt.yticks(np.arange(len(C_range)), C_range)\n",
    "plt.title(\"Validation accuracy\")\n",
    "plt.show()\n",
    "#good model score found between the Gamma ranges of 0.01 to 10 and C values of 100 to 10^5\n",
    "# when gamma is higher , or gamma is 10 no value of C can control overfitting \n",
    "# higher values of C are not prefereable because they increase risk of overfitting and take more time to fit the model\n",
    "# that for some intermediate values of gamma we get equally performing models when C becomes very large, so smaller values of C can be used to keep model fitting time reasonable \n",
    "\n",
    "#10000,0.1\n",
    "#10000,0.01\n",
    "#100,1\n",
    "#1000,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "('params', 'rank_test_recall', 'mean_test_recall', 'std_test_recall')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hinat\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hinat\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hinat\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ('params', 'rank_test_recall', 'mean_test_recall', 'std_test_recall')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2928/1672155390.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mgrid_vis\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"params\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"_\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m ).rename_axis(\"kernel\")\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mgrid_vis\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"params\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rank_test_recall\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"mean_test_recall\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"std_test_recall\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\hinat\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3456\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3457\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3458\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3459\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hinat\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3363\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ('params', 'rank_test_recall', 'mean_test_recall', 'std_test_recall')"
     ]
    }
   ],
   "source": [
    "# see different kernel accuracy with different test scores \n",
    "grid_vis = pd.DataFrame(grid_tune.cv_results_)\n",
    "grid_vis = grid_vis.sort_values(by=[\"rank_test_recall\"]) \n",
    "grid_vis = grid_vis.set_index(\n",
    "    grid_vis[\"params\"].apply(lambda x: \"_\".join(str(val) for val in x.values()))\n",
    ").rename_axis(\"kernel\")\n",
    "grid_vis[\"params\", \"rank_test_recall\", \"mean_test_recall\", \"std_test_recall\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for |: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2928/1040301902.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_vis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mr\"split\\d*_test_recall\"\u001b[0m\u001b[1;33m|\u001b[0m\u001b[1;34m'param_kernel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel_scores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for |: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "model_scores = grid_vis.filter(regex=r\"split\\d*_test_recall\"|'param_kernel')\n",
    "model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.lineplot(\n",
    "    data=model_scores.transpose().iloc[:30],\n",
    "    #data=grid_vis,\n",
    "    dashes=False,\n",
    "    palette=\"Set1\",\n",
    "    marker=\"o\",\n",
    "    alpha=0.5,\n",
    "    ax=ax,\n",
    "    hue='kernel'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run model svm with best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_svm(X_train, y_train, X_test, y_test,ker,ga,co):\n",
    "    scaler=MinMaxScaler()\n",
    "    X_train_scaled= pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "    X_test_scaled= pd.DataFrame(scaler.fit_transform(X_test), columns=X_test.columns)\n",
    "    #model =SVC(kernel='linear',C=1000) # scoring = recall,  , accuracy, AUC ROC , refit ='auc roc' \n",
    "    #model=SVC(kernel='rbf',gamma=0.001,C=1)  # scoring = recall, precision , AUC_ROC , refit ='recall' df_svm1 [1], grid_tune1 = GridSearchCV(SVC(), param_grid=tuned_parameters, cv=cv, scoring= 'recall',verbose=4,refit='roc_auc')\n",
    "    #model= SVC(kernel='poly',C=0.1,gamma=0.1) # when param grid was used 50 combination enede up , no degree was provided\n",
    "    #model= SVC(kernel='rbf',gamma=0.001,C=1)\n",
    "    #model= SVC(kernel='rbf',gamma=10,C=1) # scorer has all parameters , rec, pre, f1, fbeta, roc , refit is fbeta\n",
    "    #after heatmap\n",
    "    #10000,0.1\n",
    "    #10000,0.01\n",
    "    #100,1\n",
    "    #1000,1\n",
    "   # model= SVC(kernel='rbf',gamma=0.01,C=10000) # scorer has all parameters , rec, pre, f1, fbeta, roc , refit is fbeta\n",
    "    # from notebook on svm \n",
    "    #model= SVC(kernel='rbf',gamma=0.0008,C=2) # scorer has all parameters , rec, pre, f1, fbeta, roc , refit is fbeta\n",
    "    if ker=='linear':\n",
    "        model= SVC(kernel='linear',C=co)\n",
    "    else:\n",
    "        model= SVC(kernel=ker,gamma=ga,C=co) \n",
    "    \n",
    "    model.fit(X_train_scaled,y_train)\n",
    "\n",
    "\n",
    "    #For TEST SPLIT\n",
    "    y_pred= model.predict(X_test_scaled)\n",
    "    cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    accuracy= accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred) ##\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    specificity = cf_matrix[1][1] / ( cf_matrix[1][1] + cf_matrix[1][0] )\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    type_1_error_FP = cf_matrix[0][1]\n",
    "    type_2_error_FN = cf_matrix[1][0]\n",
    "    log_loss_ = log_loss(y_test, y_pred)\n",
    "    cohen_kappa_score_ = cohen_kappa_score(y_test, y_pred)\n",
    "    mcc= matthews_corrcoef(y_test, y_pred)\n",
    "    #Note by default 1 is the positive label. Therefore, -1 is negative\n",
    "    #bad waffe -> 2 line of matrix -> POSITIVE -> data = -1\n",
    "\n",
    "    #For TRAIN SPLIT\n",
    "    y_pred_train= model.predict(X_train_scaled)\n",
    "    cf_matrix_train = confusion_matrix(y_train, y_pred_train)\n",
    "    accuracy_train= accuracy_score(y_train, y_pred_train)\n",
    "    f1_train = f1_score(y_train, y_pred_train) ##\n",
    "    precision_train = precision_score(y_train, y_pred_train)\n",
    "    recall_train = recall_score(y_train, y_pred_train)\n",
    "    specificity_train = cf_matrix_train[1][1] / ( cf_matrix_train[1][1] + cf_matrix_train[1][0] )\n",
    "    auc_train = roc_auc_score(y_train, y_pred_train)\n",
    "    type_1_error_FP_train = cf_matrix_train[0][1]\n",
    "    type_2_error_FN_train = cf_matrix_train[1][0]\n",
    "    mcc_train= matthews_corrcoef(y_train, y_pred_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return cf_matrix, accuracy, f1, precision, recall, mcc, type_1_error_FP, type_2_error_FN, auc,log_loss_,cohen_kappa_score_, cf_matrix_train, accuracy_train, f1_train, precision_train, recall_train, mcc_train, type_1_error_FP_train, type_2_error_FN_train, auc_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ker=['linear','rbf','poly']\n",
    "ga=[0.001,0.01,0.1,1]\n",
    "co=[0.01,1,100,1000,10000]\n",
    "svm_rkgc=[]\n",
    "i=1\n",
    "\n",
    "for kernel in ker:  \n",
    "    for gamma in ga:\n",
    "        for cost in co:\n",
    "            cf_matrix, accuracy, f1, precision, recall, mcc, type_1_error_FP, type_2_error_FN, auc, log_loss_,cohen_kappa_score_, cf_matrix_train, accuracy_train, f1_train, precision_train, recall_train, mcc_train, type_1_error_FP_train, type_2_error_FN_train, auc_train = run_model_svm(X_train_temp, y_train_temp, X_test_temp, y_test_temp,kernel,gamma,cost)\n",
    "            svm_rkgc.append((i,kernel,gamma,cost,cf_matrix, accuracy, f1, precision, recall, mcc, type_1_error_FP, type_2_error_FN, auc, log_loss_, cohen_kappa_score_, cf_matrix_train, accuracy_train, f1_train, precision_train, recall_train, mcc_train, type_1_error_FP_train, type_2_error_FN_train, auc_train))\n",
    "            print('attemp no.: ',i, 'kernel: ', kernel, 'gamma: ', gamma, 'cost: ', cost,' acc: ', accuracy,' accuracy_train: ',accuracy_train, ' f1: ', f1,' f1_train: ',f1_train, ' recall: ', recall, ' :auc ', auc, ' cfm: ', '\\n', cf_matrix, '\\n n_cols', X_train_temp.shape[1])\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. default parameters svm\n",
    "#df_svm_def = pd.DataFrame(result, columns = ['cf_matrix', 'accuracy', 'f1', 'precision', 'recall', 'sensitivity', 'type_1_error_FP', 'type_2_error_FN', 'auc', 'log_loss_','cohen_kappa_score_','cf_matrix_train', 'accuracy_train', 'f1_train', 'precision_train', 'recall_train', 'sensitivity_train', 'type_1_error_FP_train', 'type_2_error_FN_train', 'auc_train'])\n",
    "# 2. default svm and C=100\n",
    "# 3. default svm and C=10000\n",
    "# 4. default svm and C=7000\n",
    "# 5. default svm and C=1000, \n",
    "# \n",
    "#df_svm = pd.DataFrame(result, columns = ['cf_matrix', 'accuracy', 'f1', 'precision', 'recall', 'sensitivity', 'type_1_error_FP', 'type_2_error_FN', 'auc', 'log_loss_','cohen_kappa_score_','cf_matrix_train', 'accuracy_train', 'f1_train', 'precision_train', 'recall_train', 'sensitivity_train', 'type_1_error_FP_train', 'type_2_error_FN_train', 'auc_train'])\n",
    "df_sv_kgc= pd.DataFrame(svm_rkgc, columns = ['No.','kernel','gamma','cost','cf_matrix', 'accuracy', 'f1', 'precision', 'recall', 'mcc', 'type_1_error_FP', 'type_2_error_FN', 'auc', 'log_loss_','cohen_kappa_score_','cf_matrix_train', 'accuracy_train', 'f1_train', 'precision_train', 'recall_train', 'mcc_train', 'type_1_error_FP_train', 'type_2_error_FN_train', 'auc_train'])\n",
    "df_sv_kgc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sv_kgc.to_csv('csv_kgc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cf_matrix</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>type_1_error_FP</th>\n",
       "      <th>type_2_error_FN</th>\n",
       "      <th>auc</th>\n",
       "      <th>log_loss_</th>\n",
       "      <th>cohen_kappa_score_</th>\n",
       "      <th>cf_matrix_train</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>precision_train</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>sensitivity_train</th>\n",
       "      <th>type_1_error_FP_train</th>\n",
       "      <th>type_2_error_FN_train</th>\n",
       "      <th>auc_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[[96, 197], [3, 18]]</td>\n",
       "      <td>0.363057</td>\n",
       "      <td>0.152542</td>\n",
       "      <td>0.083721</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>197</td>\n",
       "      <td>3</td>\n",
       "      <td>0.592394</td>\n",
       "      <td>21.999722</td>\n",
       "      <td>0.034945</td>\n",
       "      <td>[[623, 132], [71, 947]]</td>\n",
       "      <td>0.885505</td>\n",
       "      <td>0.903195</td>\n",
       "      <td>0.877665</td>\n",
       "      <td>0.930255</td>\n",
       "      <td>0.930255</td>\n",
       "      <td>132</td>\n",
       "      <td>71</td>\n",
       "      <td>0.877710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[[0, 293], [0, 21]]</td>\n",
       "      <td>0.066879</td>\n",
       "      <td>0.125373</td>\n",
       "      <td>0.066879</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>293</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>32.229604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[[0, 755], [0, 1018]]</td>\n",
       "      <td>0.574168</td>\n",
       "      <td>0.729488</td>\n",
       "      <td>0.574168</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>755</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[[221, 72], [8, 13]]</td>\n",
       "      <td>0.745223</td>\n",
       "      <td>0.245283</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>72</td>\n",
       "      <td>8</td>\n",
       "      <td>0.686657</td>\n",
       "      <td>8.799872</td>\n",
       "      <td>0.154607</td>\n",
       "      <td>[[570, 185], [189, 829]]</td>\n",
       "      <td>0.789058</td>\n",
       "      <td>0.815945</td>\n",
       "      <td>0.817554</td>\n",
       "      <td>0.814342</td>\n",
       "      <td>0.814342</td>\n",
       "      <td>185</td>\n",
       "      <td>189</td>\n",
       "      <td>0.784654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               cf_matrix  accuracy        f1  precision    recall  \\\n",
       "12  [[96, 197], [3, 18]]  0.363057  0.152542   0.083721  0.857143   \n",
       "13   [[0, 293], [0, 21]]  0.066879  0.125373   0.066879  1.000000   \n",
       "14  [[221, 72], [8, 13]]  0.745223  0.245283   0.152941  0.619048   \n",
       "\n",
       "    sensitivity  type_1_error_FP  type_2_error_FN       auc  log_loss_  \\\n",
       "12     0.857143              197                3  0.592394  21.999722   \n",
       "13     1.000000              293                0  0.500000  32.229604   \n",
       "14     0.619048               72                8  0.686657   8.799872   \n",
       "\n",
       "    cohen_kappa_score_           cf_matrix_train  accuracy_train  f1_train  \\\n",
       "12            0.034945   [[623, 132], [71, 947]]        0.885505  0.903195   \n",
       "13            0.000000     [[0, 755], [0, 1018]]        0.574168  0.729488   \n",
       "14            0.154607  [[570, 185], [189, 829]]        0.789058  0.815945   \n",
       "\n",
       "    precision_train  recall_train  sensitivity_train  type_1_error_FP_train  \\\n",
       "12         0.877665      0.930255           0.930255                    132   \n",
       "13         0.574168      1.000000           1.000000                    755   \n",
       "14         0.817554      0.814342           0.814342                    185   \n",
       "\n",
       "    type_2_error_FN_train  auc_train  \n",
       "12                     71   0.877710  \n",
       "13                      0   0.500000  \n",
       "14                    189   0.784654  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_svm1.iloc[[12,13,14],:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2: EXECUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(466,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_track_cols = X_test.columns\n",
    "fast_track_cols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:35<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attemp no.:  1 3s & knn__distance & BoS__shap & No & SMOTEENN & RF  acc:  0.7197452229299363  accuracy_train:  0.9142695995487874  f1:  0.25423728813559326  f1_train:  0.9285042333019755  sensitivity:  0.7142857142857143  :auc  0.7172111165285228  cfm:  \n",
      " [[211  82]\n",
      " [  6  15]] \n",
      " n_cols 19\n"
     ]
    }
   ],
   "source": [
    "X = read_features()\n",
    "y = read_target().iloc[:,0]\n",
    "\n",
    "removing_coli = 'No'\n",
    "#['Yes', 'No']\n",
    "\n",
    "result = []\n",
    "i = 1\n",
    "\n",
    "\n",
    "\n",
    "#step 1:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1, stratify=y)\n",
    "#change random state??\n",
    "\n",
    "#-----------\n",
    "\n",
    "# # step 2:\n",
    "X_train = remove_duplicated_columns(X_train)\n",
    "# #step 3:\n",
    "X_train = remove_constant_volatility(X_train)\n",
    "# #step 4:\n",
    "X_train = remove_cols_with_high_pct_null(X_train, 0.8) #this can be in the loop too, may be later\n",
    "# #step 5: remove the same columns from step 2-4 TRAIN_TEST split\n",
    "X_test = X_test.loc[:,X_train.columns]\n",
    "\n",
    "#------------\n",
    "fast_track_cols = X_test.columns\n",
    "\n",
    "X_train = X_train.loc[:, fast_track_cols]\n",
    "X_test = X_test.loc[:, fast_track_cols]\n",
    "\n",
    "#------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#step 6-9\n",
    "replace_outlier_options = ['3s'] #nothing at all\n",
    "#replace_outlier_options = ['3s','NaN','nothing']\n",
    "impute_null_options = ['knn__distance']\n",
    "#impute_null_options = ['knn__distance', 'MICE', 'knn__uniform']\n",
    "FS_options = ['BoS__shap']\n",
    "#FS_options = ['BoP','BoS__shap', 'BoS__gini', 'RFE__RF', 'RFE__SVM', 'nothing]\n",
    "sampling_options = ['SMOTEENN'] #TRY OTHER SAMPLING\n",
    "#sampling_options = ['SMOTE','ROSE','ADASYN','SMOTEENN']\n",
    "model_options = ['RF']\n",
    "#model_options = ['LR', 'RF', 'NN']\n",
    "#try RF=10depth\n",
    "\n",
    "#next: TRY KNN DISTANCE\n",
    "\n",
    "for replace_with in replace_outlier_options:\n",
    "    for knn_weight in impute_null_options:\n",
    "        for classifier_model in FS_options:\n",
    "            for sampling_technique in sampling_options:\n",
    "                for Model in model_options:\n",
    "                    X_train_temp = X_train\n",
    "                    X_test_temp = X_test\n",
    "                    y_train_temp = y_train\n",
    "                    y_test_temp = y_test\n",
    "\n",
    "                    combined_technique = replace_with +' & '+ knn_weight +' & '+ classifier_model + ' & ' + removing_coli +' & '+ sampling_technique +' & '+ Model\n",
    "\n",
    "                    #step 6: oulier treatement (on both TRAIN & TEST split)\n",
    "                    if replace_with != 'nothing':\n",
    "                        X_train_temp = replace_outlier(X_train_temp, replace_with)\n",
    "                        X_test_temp = replace_outlier(X_test_temp, replace_with)\n",
    "                    \n",
    "                    #step 7: missing value imputation (on both TRAIN & TEST split)\n",
    "                    if knn_weight == 'knn__distance' or knn_weight == 'knn__uniform':\n",
    "                        X_train_temp, X_test_temp = impute_null_with_knn(X_train_temp, X_test_temp, knn_weight[-(len(knn_weight)-5):])\n",
    "                    elif knn_weight == 'MICE':\n",
    "                        X_train_temp, X_test_temp = impute_null_with_mice(X_train_temp, X_test_temp)\n",
    "\n",
    "                    #step 8: feature selection (on both TRAIN & TEST split)\n",
    "                    if classifier_model !='nothing':\n",
    "                        if classifier_model == 'BoS__shap' or classifier_model == 'BoS__gini':\n",
    "                            X_train_temp = BorutaShap_FS(X_train_temp, y_train_temp, classifier_model[-(len(classifier_model)-5):])\n",
    "                        elif classifier_model == 'RFE__RF' or classifier_model == 'RFE__SVM':\n",
    "                            X_train_temp = RFE_FS(X_train_temp, y_train_temp, classifier_model[-(len(classifier_model)-5):])\n",
    "                        elif classifier_model == 'BoP':\n",
    "                            X_train_temp = BorutaPy_FS(X_train_temp, y_train_temp)\n",
    "                    \n",
    "\n",
    "                        #step 9: remove multilinear features\n",
    "                    if removing_coli=='Yes':\n",
    "                        print('n_cols BEFORE multicolinearity treatement', X_train_temp.shape[1])\n",
    "                        X_train_temp = remove_collinear_features(X_train_temp, 0.7)\n",
    "                        print('n_cols AFTER multicolinearity treatement', X_train_temp.shape[1])\n",
    "\n",
    "                    #apply the same result for TEST\n",
    "                    X_test_temp = X_test_temp.loc[:,X_train_temp.columns]\n",
    "\n",
    "                    #print out datasets for backup\n",
    "                    #X_train_temp.to_csv('sampling_visualization/X_train_temp_BEFORESAMPLING_'+str(i)+combined_technique+'.csv')\n",
    "                    #X_test_temp.to_csv('sampling_visualization/X_test_temp_BEFORESAMPLING_'+str(i)+combined_technique+'.csv')\n",
    "                    #y_train_temp.to_csv('sampling_visualization/y_train_temp_BEFORESAMPLING_'+str(i)+combined_technique+'.csv')\n",
    "                    #y_test_temp.to_csv('sampling_visualization/y_test_temp_BEFORESAMPLING_'+str(i)+combined_technique+'.csv')\n",
    "\n",
    "                    #step 10: balancing only on TRAIN split\n",
    "                    X_train_temp, y_train_temp = sampling(X_train_temp, y_train_temp, sampling_technique)\n",
    "\n",
    "                    #print out datasets for backup\n",
    "                    #X_train_temp.to_csv('sampling_visualization/X_train_temp_AFTERSAMPLING_'+str(i)+combined_technique+'.csv')\n",
    "                    #X_test_temp.to_csv('sampling_visualization/X_test_temp_AFTERSAMPLING_'+str(i)+combined_technique+'.csv')\n",
    "                    #y_train_temp.to_csv('sampling_visualization/y_train_temp_AFTERSAMPLING_'+str(i)+combined_technique+'.csv')\n",
    "                    #y_test_temp.to_csv('sampling_visualization/y_test_temp_AFTERSAMPLING_'+str(i)+combined_technique+'.csv')\n",
    "\n",
    "\n",
    "                    #step 11: train model, predict, and print scores\n",
    "                    if Model != 'NN':\n",
    "                        try:\n",
    "                            cf_matrix, accuracy, f1, precision, recall, sensitivity, type_1_error_FP, type_2_error_FN, auc, log_loss_,cohen_kappa_score_, cf_matrix_train, accuracy_train, f1_train, precision_train, recall_train, sensitivity_train, type_1_error_FP_train, type_2_error_FN_train, auc_train = run_model(X_train_temp, y_train_temp, X_test_temp, y_test_temp, Model)\n",
    "                        except Exception:\n",
    "                            cf_matrix = accuracy = f1 = precision = recall = sensitivity = type_1_error_FP = type_2_error_FN = auc = log_loss_ =cohen_kappa_score_ = cf_matrix_train = accuracy_train = f1_train = precision_train = recall_train = sensitivity_train = type_1_error_FP_train = type_2_error_FN_train = auc_train = 0\n",
    "                    #elif Model == 'NN':\n",
    "                    #    try:\n",
    "                    #        cf_matrix, accuracy, f1, precision, recall, sensitivity, type_1_error_FP, type_2_error_FN, auc, log_loss_,cohen_kappa_score_, cf_matrix_train, accuracy_train, f1_train, precision_train, recall_train, sensitivity_train, type_1_error_FP_train, type_2_error_FN_train, auc_train = run_model_NN(X_train_temp, y_train_temp, X_test_temp, y_test_temp)\n",
    "                    #    except Exception:\n",
    "                    #        cf_matrix = accuracy = f1 = precision = recall = sensitivity = type_1_error_FP = type_2_error_FN = auc = log_loss_ =cohen_kappa_score_ = cf_matrix_train = accuracy_train = f1_train = precision_train = recall_train = sensitivity_train = type_1_error_FP_train = type_2_error_FN_train = auc_train = 0\n",
    "\n",
    "                    result.append((i, combined_technique, X_train_temp.shape[1], replace_with, knn_weight, classifier_model, removing_coli, sampling_technique, Model, X_train_temp.columns, cf_matrix, accuracy, f1, precision, recall, sensitivity, type_1_error_FP, type_2_error_FN, auc, log_loss_, cohen_kappa_score_, cf_matrix_train, accuracy_train, f1_train, precision_train, recall_train, sensitivity_train, type_1_error_FP_train, type_2_error_FN_train, auc_train))\n",
    "                    \n",
    "                    print('attemp no.: ',i, combined_technique,' acc: ', accuracy,' accuracy_train: ',accuracy_train, ' f1: ', f1,' f1_train: ',f1_train, ' sensitivity: ', sensitivity, ' :auc ', auc, ' cfm: ', '\\n', cf_matrix, '\\n n_cols', X_train_temp.shape[1])\n",
    "                    \n",
    "\n",
    "                    if i%5==0: \n",
    "                        df_result = pd.DataFrame(result, columns = ['No.','combination','n_cols','outlier_replace_with', 'imputation_knn_weight', 'FS_classifier_model', 'removing_coli','balancing_sampling_technique', 'Model','cols','cf_matrix', 'accuracy', 'f1', 'precision', 'recall', 'sensitivity', 'type_1_error_FP', 'type_2_error_FN', 'auc', 'log_loss_','cohen_kappa_score_','cf_matrix_train', 'accuracy_train', 'f1_train', 'precision_train', 'recall_train', 'sensitivity_train', 'type_1_error_FP_train', 'type_2_error_FN_train', 'auc_train'])\n",
    "                        #df_result.to_csv('tracker/result'+str(i)+'.csv')\n",
    "                    \n",
    "\n",
    "                    i+=1\n",
    "\n",
    "\n",
    "\n",
    "df_result = pd.DataFrame(result, columns = ['No.','combination','n_cols','outlier_replace_with', 'imputation_knn_weight', 'FS_classifier_model', 'removing_coli','balancing_sampling_technique', 'Model','cols','cf_matrix', 'accuracy', 'f1', 'precision', 'recall', 'sensitivity', 'type_1_error_FP', 'type_2_error_FN', 'auc', 'log_loss_','cohen_kappa_score_','cf_matrix_train', 'accuracy_train', 'f1_train', 'precision_train', 'recall_train', 'sensitivity_train', 'type_1_error_FP_train', 'type_2_error_FN_train', 'auc_train'])\n",
    "#df_result.to_csv('tracker/bm.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3pt= df_result.loc[:,['cf_matrix', 'accuracy', 'f1', 'precision', 'recall', 'sensitivity', 'type_1_error_FP', 'type_2_error_FN', 'auc','cf_matrix_train', 'accuracy_train', 'f1_train', 'precision_train', 'recall_train', 'sensitivity_train', 'type_1_error_FP_train', 'type_2_error_FN_train', 'auc_train']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cf_matrix</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>type_1_error_FP</th>\n",
       "      <th>type_2_error_FN</th>\n",
       "      <th>auc</th>\n",
       "      <th>cf_matrix_train</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>precision_train</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>sensitivity_train</th>\n",
       "      <th>type_1_error_FP_train</th>\n",
       "      <th>type_2_error_FN_train</th>\n",
       "      <th>auc_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[211, 82], [6, 15]]</td>\n",
       "      <td>0.719745</td>\n",
       "      <td>0.254237</td>\n",
       "      <td>0.154639</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>6</td>\n",
       "      <td>82</td>\n",
       "      <td>0.717211</td>\n",
       "      <td>[[634, 121], [31, 987]]</td>\n",
       "      <td>0.91427</td>\n",
       "      <td>0.928504</td>\n",
       "      <td>0.890794</td>\n",
       "      <td>0.969548</td>\n",
       "      <td>0.969548</td>\n",
       "      <td>31</td>\n",
       "      <td>121</td>\n",
       "      <td>0.904642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              cf_matrix  accuracy        f1  precision    recall  sensitivity  \\\n",
       "0  [[211, 82], [6, 15]]  0.719745  0.254237   0.154639  0.714286     0.714286   \n",
       "\n",
       "   type_1_error_FP  type_2_error_FN       auc          cf_matrix_train  \\\n",
       "0                6               82  0.717211  [[634, 121], [31, 987]]   \n",
       "\n",
       "   accuracy_train  f1_train  precision_train  recall_train  sensitivity_train  \\\n",
       "0         0.91427  0.928504         0.890794      0.969548           0.969548   \n",
       "\n",
       "   type_1_error_FP_train  type_2_error_FN_train  auc_train  \n",
       "0                     31                    121   0.904642  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3pt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "08c0539bf10c75c5b2836a432ee34201d271197da8458066aa86299ab8bcd438"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Libraries for model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function is to read, transform and join 2 data frame\n",
    "#%%\n",
    "def read_secom():\n",
    "    path = '../secom.data'\n",
    "    df = pd.read_csv(path, delimiter=' ', header=None, na_values=['NaN'])\n",
    "    df.columns = ['feature'+str(x+1) for x in range(len(df.columns))]\n",
    "    return df\n",
    "\n",
    "\n",
    "#%%\n",
    "def read_labels():\n",
    "    path = '../secom_labels.data'\n",
    "    df = pd.read_csv(path, delimiter=' ', header=None, na_values=['NaN'])\n",
    "    df.columns = ['status','timestamp']\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'],dayfirst=True)\n",
    "    return df\n",
    "\n",
    "#read 2 df \n",
    "df_features = read_secom()\n",
    "df_target = read_labels()\n",
    "\n",
    "#concat them vertically\n",
    "#df = pd.concat([df_features,df_target],axis=1)\n",
    "\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1567, 590)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>2008-07-19 11:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>2008-07-19 12:32:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2008-07-19 13:17:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>2008-07-19 14:43:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>2008-07-19 15:22:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>-1</td>\n",
       "      <td>2008-10-16 15:13:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>-1</td>\n",
       "      <td>2008-10-16 20:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>-1</td>\n",
       "      <td>2008-10-17 05:26:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>-1</td>\n",
       "      <td>2008-10-17 06:01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>-1</td>\n",
       "      <td>2008-10-17 06:07:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1567 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      status           timestamp\n",
       "0         -1 2008-07-19 11:55:00\n",
       "1         -1 2008-07-19 12:32:00\n",
       "2          1 2008-07-19 13:17:00\n",
       "3         -1 2008-07-19 14:43:00\n",
       "4         -1 2008-07-19 15:22:00\n",
       "...      ...                 ...\n",
       "1562      -1 2008-10-16 15:13:00\n",
       "1563      -1 2008-10-16 20:49:00\n",
       "1564      -1 2008-10-17 05:26:00\n",
       "1565      -1 2008-10-17 06:01:00\n",
       "1566      -1 2008-10-17 06:07:00\n",
       "\n",
       "[1567 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skipping NAN treatment\n",
    "#skipping outier treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature581</th>\n",
       "      <th>feature582</th>\n",
       "      <th>feature583</th>\n",
       "      <th>feature584</th>\n",
       "      <th>feature585</th>\n",
       "      <th>feature586</th>\n",
       "      <th>feature587</th>\n",
       "      <th>feature588</th>\n",
       "      <th>feature589</th>\n",
       "      <th>feature590</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3030.93</td>\n",
       "      <td>2564.00</td>\n",
       "      <td>2187.7333</td>\n",
       "      <td>1411.1265</td>\n",
       "      <td>1.3602</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.6133</td>\n",
       "      <td>0.1242</td>\n",
       "      <td>1.5005</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5005</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.3630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3095.78</td>\n",
       "      <td>2465.14</td>\n",
       "      <td>2230.4222</td>\n",
       "      <td>1463.6606</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>100.0</td>\n",
       "      <td>102.3433</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>1.4966</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>208.2045</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>4.4447</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>208.2045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2932.61</td>\n",
       "      <td>2559.94</td>\n",
       "      <td>2186.4111</td>\n",
       "      <td>1698.0172</td>\n",
       "      <td>1.5102</td>\n",
       "      <td>100.0</td>\n",
       "      <td>95.4878</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>1.4436</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>82.8602</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>3.1745</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>82.8602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2988.72</td>\n",
       "      <td>2479.90</td>\n",
       "      <td>2199.0333</td>\n",
       "      <td>909.7926</td>\n",
       "      <td>1.3204</td>\n",
       "      <td>100.0</td>\n",
       "      <td>104.2367</td>\n",
       "      <td>0.1217</td>\n",
       "      <td>1.4882</td>\n",
       "      <td>-0.0124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>0.4990</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>2.0544</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032.24</td>\n",
       "      <td>2502.87</td>\n",
       "      <td>2233.3667</td>\n",
       "      <td>1326.5200</td>\n",
       "      <td>1.5334</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.3967</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>1.5031</td>\n",
       "      <td>-0.0031</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.4766</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>99.3032</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>2899.41</td>\n",
       "      <td>2464.36</td>\n",
       "      <td>2179.7333</td>\n",
       "      <td>3085.3781</td>\n",
       "      <td>1.4843</td>\n",
       "      <td>100.0</td>\n",
       "      <td>82.2467</td>\n",
       "      <td>0.1248</td>\n",
       "      <td>1.3424</td>\n",
       "      <td>-0.0045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>203.1720</td>\n",
       "      <td>0.4988</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>2.8669</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>203.1720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>3052.31</td>\n",
       "      <td>2522.55</td>\n",
       "      <td>2198.5667</td>\n",
       "      <td>1124.6595</td>\n",
       "      <td>0.8763</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.4689</td>\n",
       "      <td>0.1205</td>\n",
       "      <td>1.4333</td>\n",
       "      <td>-0.0061</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4975</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>2.6238</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>203.1720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>2978.81</td>\n",
       "      <td>2379.78</td>\n",
       "      <td>2206.3000</td>\n",
       "      <td>1110.4967</td>\n",
       "      <td>0.8236</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.4122</td>\n",
       "      <td>0.1208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>43.5231</td>\n",
       "      <td>0.4987</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>3.0590</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>43.5231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>2894.92</td>\n",
       "      <td>2532.01</td>\n",
       "      <td>2177.0333</td>\n",
       "      <td>1183.7287</td>\n",
       "      <td>1.5726</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.7978</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>1.4622</td>\n",
       "      <td>-0.0072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>93.4941</td>\n",
       "      <td>0.5004</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>3.5662</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>93.4941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>2944.92</td>\n",
       "      <td>2450.76</td>\n",
       "      <td>2195.4444</td>\n",
       "      <td>2914.1792</td>\n",
       "      <td>1.5978</td>\n",
       "      <td>100.0</td>\n",
       "      <td>85.1011</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>137.7844</td>\n",
       "      <td>0.4987</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>3.6275</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>137.7844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1567 rows × 590 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature1  feature2   feature3   feature4  feature5  feature6  feature7  \\\n",
       "0      3030.93   2564.00  2187.7333  1411.1265    1.3602     100.0   97.6133   \n",
       "1      3095.78   2465.14  2230.4222  1463.6606    0.8294     100.0  102.3433   \n",
       "2      2932.61   2559.94  2186.4111  1698.0172    1.5102     100.0   95.4878   \n",
       "3      2988.72   2479.90  2199.0333   909.7926    1.3204     100.0  104.2367   \n",
       "4      3032.24   2502.87  2233.3667  1326.5200    1.5334     100.0  100.3967   \n",
       "...        ...       ...        ...        ...       ...       ...       ...   \n",
       "1562   2899.41   2464.36  2179.7333  3085.3781    1.4843     100.0   82.2467   \n",
       "1563   3052.31   2522.55  2198.5667  1124.6595    0.8763     100.0   98.4689   \n",
       "1564   2978.81   2379.78  2206.3000  1110.4967    0.8236     100.0   99.4122   \n",
       "1565   2894.92   2532.01  2177.0333  1183.7287    1.5726     100.0   98.7978   \n",
       "1566   2944.92   2450.76  2195.4444  2914.1792    1.5978     100.0   85.1011   \n",
       "\n",
       "      feature8  feature9  feature10  ...  feature581  feature582  feature583  \\\n",
       "0       0.1242    1.5005     0.0162  ...         NaN         NaN      0.5005   \n",
       "1       0.1247    1.4966    -0.0005  ...      0.0060    208.2045      0.5019   \n",
       "2       0.1241    1.4436     0.0041  ...      0.0148     82.8602      0.4958   \n",
       "3       0.1217    1.4882    -0.0124  ...      0.0044     73.8432      0.4990   \n",
       "4       0.1235    1.5031    -0.0031  ...         NaN         NaN      0.4800   \n",
       "...        ...       ...        ...  ...         ...         ...         ...   \n",
       "1562    0.1248    1.3424    -0.0045  ...      0.0047    203.1720      0.4988   \n",
       "1563    0.1205    1.4333    -0.0061  ...         NaN         NaN      0.4975   \n",
       "1564    0.1208       NaN        NaN  ...      0.0025     43.5231      0.4987   \n",
       "1565    0.1213    1.4622    -0.0072  ...      0.0075     93.4941      0.5004   \n",
       "1566    0.1235       NaN        NaN  ...      0.0045    137.7844      0.4987   \n",
       "\n",
       "      feature584  feature585  feature586  feature587  feature588  feature589  \\\n",
       "0         0.0118      0.0035      2.3630         NaN         NaN         NaN   \n",
       "1         0.0223      0.0055      4.4447      0.0096      0.0201      0.0060   \n",
       "2         0.0157      0.0039      3.1745      0.0584      0.0484      0.0148   \n",
       "3         0.0103      0.0025      2.0544      0.0202      0.0149      0.0044   \n",
       "4         0.4766      0.1045     99.3032      0.0202      0.0149      0.0044   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1562      0.0143      0.0039      2.8669      0.0068      0.0138      0.0047   \n",
       "1563      0.0131      0.0036      2.6238      0.0068      0.0138      0.0047   \n",
       "1564      0.0153      0.0041      3.0590      0.0197      0.0086      0.0025   \n",
       "1565      0.0178      0.0038      3.5662      0.0262      0.0245      0.0075   \n",
       "1566      0.0181      0.0040      3.6275      0.0117      0.0162      0.0045   \n",
       "\n",
       "      feature590  \n",
       "0            NaN  \n",
       "1       208.2045  \n",
       "2        82.8602  \n",
       "3        73.8432  \n",
       "4        73.8432  \n",
       "...          ...  \n",
       "1562    203.1720  \n",
       "1563    203.1720  \n",
       "1564     43.5231  \n",
       "1565     93.4941  \n",
       "1566    137.7844  \n",
       "\n",
       "[1567 rows x 590 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_features\n",
    "y = df_target.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      -1\n",
       "1      -1\n",
       "2       1\n",
       "3      -1\n",
       "4      -1\n",
       "       ..\n",
       "1562   -1\n",
       "1563   -1\n",
       "1564   -1\n",
       "1565   -1\n",
       "1566   -1\n",
       "Name: status, Length: 1567, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treating missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.replace(np.NaN, 0)\n",
    "y = y.replace(np.NaN, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train:  (1096, 590)\n",
      "shape of x_test:  (471, 590)\n",
      "shape of y_train:  (1096,)\n",
      "shape of y_test:  (471,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, stratify=y, random_state = 1)\n",
    "\n",
    "# gettiing the shapes\n",
    "print(\"shape of x_train: \", x_train.shape)\n",
    "print(\"shape of x_test: \", x_test.shape)\n",
    "print(\"shape of y_train: \", y_train.shape)\n",
    "print(\"shape of y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  93.63057324840764\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, random_state=1,verbose=0 )\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.rcParams['figure.figsize'] = (5, 5)\n",
    "sns.set(style = 'dark', font_scale = 1.4)\n",
    "sns.heatmap(cm, annot = True, annot_kws = {\"size\": 15})\n",
    "\n",
    "print(\"Accuracy: \", model.score(x_test,y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2926, 590)\n",
      "(2926,)\n"
     ]
    }
   ],
   "source": [
    "x_resample, y_resample  = SMOTE(random_state=1).fit_resample(x, y)\n",
    "\n",
    "print(x_resample.shape)\n",
    "print(y_resample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  100.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, random_state=1,verbose=0 )\n",
    "model.fit(x_resample, y_resample)\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.rcParams['figure.figsize'] = (5, 5)\n",
    "sns.set(style = 'dark', font_scale = 1.4)\n",
    "sns.heatmap(cm, annot = True, annot_kws = {\"size\": 15})\n",
    "\n",
    "print(\"Accuracy: \", model.score(x_test,y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2: Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras specific\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# one hot encode outputs\n",
    "y_train_c = to_categorical(y_train)\n",
    "y_test_c = to_categorical(y_test)\n",
    "\n",
    "count_classes = y_test_c.shape[1]\n",
    "print(count_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 400)               236400    \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 250)               100250    \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 100)               25100     \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 2)                 52        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 368,127\n",
      "Trainable params: 368,127\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_dim = x_train.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(400, activation='relu', input_dim=input_dim))\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature581</th>\n",
       "      <th>feature582</th>\n",
       "      <th>feature583</th>\n",
       "      <th>feature584</th>\n",
       "      <th>feature585</th>\n",
       "      <th>feature586</th>\n",
       "      <th>feature587</th>\n",
       "      <th>feature588</th>\n",
       "      <th>feature589</th>\n",
       "      <th>feature590</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>2945.22</td>\n",
       "      <td>2570.44</td>\n",
       "      <td>2194.9556</td>\n",
       "      <td>2341.7833</td>\n",
       "      <td>2.3917</td>\n",
       "      <td>100.0</td>\n",
       "      <td>86.8100</td>\n",
       "      <td>0.1231</td>\n",
       "      <td>1.4207</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4976</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>3.2945</td>\n",
       "      <td>0.0552</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>32.2058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>2938.02</td>\n",
       "      <td>2499.68</td>\n",
       "      <td>2114.6667</td>\n",
       "      <td>1549.4874</td>\n",
       "      <td>1.3393</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.7844</td>\n",
       "      <td>0.1262</td>\n",
       "      <td>1.4446</td>\n",
       "      <td>-0.0109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>65.2186</td>\n",
       "      <td>0.5014</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>1.6180</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>65.2186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>2911.22</td>\n",
       "      <td>2556.64</td>\n",
       "      <td>2204.2889</td>\n",
       "      <td>2637.9989</td>\n",
       "      <td>1.5549</td>\n",
       "      <td>100.0</td>\n",
       "      <td>86.1089</td>\n",
       "      <td>0.1234</td>\n",
       "      <td>1.4439</td>\n",
       "      <td>-0.0094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>178.0405</td>\n",
       "      <td>0.4985</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>3.0670</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>178.0405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>3047.00</td>\n",
       "      <td>2436.01</td>\n",
       "      <td>2213.7556</td>\n",
       "      <td>1113.5599</td>\n",
       "      <td>0.7217</td>\n",
       "      <td>100.0</td>\n",
       "      <td>104.1667</td>\n",
       "      <td>0.1211</td>\n",
       "      <td>1.5608</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4964</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>2.1646</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>0.0318</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>192.9130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>2992.40</td>\n",
       "      <td>2590.80</td>\n",
       "      <td>2223.9000</td>\n",
       "      <td>1745.3724</td>\n",
       "      <td>1.9974</td>\n",
       "      <td>100.0</td>\n",
       "      <td>96.7567</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>1.5519</td>\n",
       "      <td>-0.0273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5039</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>3.0039</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>79.1086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>3070.07</td>\n",
       "      <td>2459.22</td>\n",
       "      <td>2216.5111</td>\n",
       "      <td>871.2526</td>\n",
       "      <td>1.2366</td>\n",
       "      <td>100.0</td>\n",
       "      <td>107.4867</td>\n",
       "      <td>0.1194</td>\n",
       "      <td>1.4125</td>\n",
       "      <td>-0.0199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4963</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>3.0867</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>291.8040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>2948.57</td>\n",
       "      <td>2526.19</td>\n",
       "      <td>2216.5000</td>\n",
       "      <td>1111.5436</td>\n",
       "      <td>0.8373</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.9867</td>\n",
       "      <td>0.1205</td>\n",
       "      <td>1.4684</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>54.4761</td>\n",
       "      <td>0.5048</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>2.3445</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>54.4761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>3062.78</td>\n",
       "      <td>2491.31</td>\n",
       "      <td>2266.8333</td>\n",
       "      <td>2040.1937</td>\n",
       "      <td>1.6558</td>\n",
       "      <td>100.0</td>\n",
       "      <td>94.8489</td>\n",
       "      <td>0.1216</td>\n",
       "      <td>1.3909</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>44.1194</td>\n",
       "      <td>0.5021</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>2.2065</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>44.1194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>3045.71</td>\n",
       "      <td>2490.25</td>\n",
       "      <td>2197.6444</td>\n",
       "      <td>1247.0334</td>\n",
       "      <td>0.7865</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.9211</td>\n",
       "      <td>0.1203</td>\n",
       "      <td>1.4257</td>\n",
       "      <td>-0.0343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4947</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>2.4419</td>\n",
       "      <td>-0.0034</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>272.3477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>3150.47</td>\n",
       "      <td>2621.33</td>\n",
       "      <td>2231.6111</td>\n",
       "      <td>2005.8966</td>\n",
       "      <td>1.2969</td>\n",
       "      <td>100.0</td>\n",
       "      <td>93.7522</td>\n",
       "      <td>0.1234</td>\n",
       "      <td>1.4202</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5027</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>2.9228</td>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>31.0252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1253 rows × 590 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature1  feature2   feature3   feature4  feature5  feature6  feature7  \\\n",
       "1005   2945.22   2570.44  2194.9556  2341.7833    2.3917     100.0   86.8100   \n",
       "858    2938.02   2499.68  2114.6667  1549.4874    1.3393     100.0   98.7844   \n",
       "1485   2911.22   2556.64  2204.2889  2637.9989    1.5549     100.0   86.1089   \n",
       "382    3047.00   2436.01  2213.7556  1113.5599    0.7217     100.0  104.1667   \n",
       "1012   2992.40   2590.80  2223.9000  1745.3724    1.9974     100.0   96.7567   \n",
       "...        ...       ...        ...        ...       ...       ...       ...   \n",
       "715    3070.07   2459.22  2216.5111   871.2526    1.2366     100.0  107.4867   \n",
       "905    2948.57   2526.19  2216.5000  1111.5436    0.8373     100.0   99.9867   \n",
       "1096   3062.78   2491.31  2266.8333  2040.1937    1.6558     100.0   94.8489   \n",
       "235    3045.71   2490.25  2197.6444  1247.0334    0.7865     100.0   99.9211   \n",
       "1061   3150.47   2621.33  2231.6111  2005.8966    1.2969     100.0   93.7522   \n",
       "\n",
       "      feature8  feature9  feature10  ...  feature581  feature582  feature583  \\\n",
       "1005    0.1231    1.4207     0.0086  ...      0.0000      0.0000      0.4976   \n",
       "858     0.1262    1.4446    -0.0109  ...      0.0045     65.2186      0.5014   \n",
       "1485    0.1234    1.4439    -0.0094  ...      0.0061    178.0405      0.4985   \n",
       "382     0.1211    1.5608    -0.0004  ...      0.0000      0.0000      0.4964   \n",
       "1012    0.1241    1.5519    -0.0273  ...      0.0000      0.0000      0.5039   \n",
       "...        ...       ...        ...  ...         ...         ...         ...   \n",
       "715     0.1194    1.4125    -0.0199  ...      0.0000      0.0000      0.4963   \n",
       "905     0.1205    1.4684     0.0013  ...      0.0036     54.4761      0.5048   \n",
       "1096    0.1216    1.3909     0.0053  ...      0.0024     44.1194      0.5021   \n",
       "235     0.1203    1.4257    -0.0343  ...      0.0000      0.0000      0.4947   \n",
       "1061    0.1234    1.4202     0.0150  ...      0.0000      0.0000      0.5027   \n",
       "\n",
       "      feature584  feature585  feature586  feature587  feature588  feature589  \\\n",
       "1005      0.0164      0.0035      3.2945      0.0552      0.0178      0.0051   \n",
       "858       0.0081      0.0024      1.6180      0.0220      0.0143      0.0045   \n",
       "1485      0.0153      0.0041      3.0670      0.0104      0.0185      0.0061   \n",
       "382       0.0107      0.0031      2.1646      0.0165      0.0318      0.0102   \n",
       "1012      0.0151      0.0037      3.0039      0.0167      0.0132      0.0039   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "715       0.0153      0.0037      3.0867      0.0072      0.0210      0.0065   \n",
       "905       0.0118      0.0029      2.3445      0.0211      0.0115      0.0036   \n",
       "1096      0.0111      0.0034      2.2065      0.0179      0.0079      0.0024   \n",
       "235       0.0121      0.0038      2.4419     -0.0034      0.0093      0.0030   \n",
       "1061      0.0147      0.0036      2.9228      0.0189      0.0059      0.0017   \n",
       "\n",
       "      feature590  \n",
       "1005     32.2058  \n",
       "858      65.2186  \n",
       "1485    178.0405  \n",
       "382     192.9130  \n",
       "1012     79.1086  \n",
       "...          ...  \n",
       "715     291.8040  \n",
       "905      54.4761  \n",
       "1096     44.1194  \n",
       "235     272.3477  \n",
       "1061     31.0252  \n",
       "\n",
       "[1253 rows x 590 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 3ms/step - loss: 14.1592 - accuracy: 0.9516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa9ffb67a00>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train_c, epochs=1, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 2ms/step\n",
      "Accuracy on training data: 1.0 \n",
      " Error on training data: 0.0\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "Accuracy on test data: 1.0 \n",
      " Error on test data: 0.0\n"
     ]
    }
   ],
   "source": [
    "pred_train= model.predict(x_train)\n",
    "scores = model.evaluate(x_train, y_train_c, verbose=0)\n",
    "print('Accuracy on training data: {} \\n Error on training data: {}'.format(scores[1], 1 - scores[1]))   \n",
    " \n",
    "pred_test= model.predict(x_test)\n",
    "scores2 = model.evaluate(x_test, y_test_c, verbose=0)\n",
    "print('Accuracy on test data: {} \\n Error on test data: {}'.format(scores2[1], 1 - scores2[1]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [471, 314]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-7d9ed0e8db12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'figure.figsize'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'dark'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfont_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannot_kws\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"size\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \"\"\"\n\u001b[0;32m--> 307\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \"\"\"\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_pred\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    388\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [471, 314]"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.rcParams['figure.figsize'] = (5, 5)\n",
    "sns.set(style = 'dark', font_scale = 1.4)\n",
    "sns.heatmap(cm, annot = True, annot_kws = {\"size\": 15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_c = model.predict(x_test)\n",
    "cm = confusion_matrix(y_test_c.argmax(axis=1), y_pred_c.argmax(axis=1))\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (5, 5)\n",
    "sns.set(style = 'dark', font_scale = 1.4)\n",
    "sns.heatmap(cm, annot = True, annot_kws = {\"size\": 15})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction with softmax\n",
    "#https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-predict-new-samples-with-your-keras-model.md\n",
    "#https://stackoverflow.com/questions/63093045/keras-softmax-output-and-accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skip this for now\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3aeb15c8c31224d9ef37a76c0046f703a279f439b6efd04fb2681e5f2715bf2f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.11.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statistics\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from plotly.offline import init_notebook_mode, iplot, plot\n",
    "import plotly as py\n",
    "init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import statistics as stat\n",
    "from scipy.stats import binom\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib.patches import Rectangle\n",
    "# splitting merge_data into train test and split\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from scipy import stats\n",
    "from scipy.stats import normaltest\n",
    "import os \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "import matplotlib as mpl\n",
    "import warnings; warnings.filterwarnings(action='once')\n",
    "# to keep track of training time\n",
    "import datetime\n",
    "# logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# metrics used for evaluation\n",
    "from sklearn.metrics import f1_score, matthews_corrcoef\n",
    "# visualizations\n",
    "from yellowbrick.classifier import ClassPredictionError, ConfusionMatrix\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "# KNN imputation\n",
    "from sklearn.impute import KNNImputer\n",
    "# normalizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "# variance threshold\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "# RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# evaluation metric\n",
    "from sklearn.metrics import matthews_corrcoef, make_scorer\n",
    "from scipy import stats \n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split \n",
    "from sklearn.model_selection import cross_val_score # Evaluate a score by cross-validation\n",
    "from sklearn.model_selection import GridSearchCV # Exhaustive search over specified parameter values for an estimator\n",
    "from sklearn.metrics import classification_report # Build a text report showing the main classification metrics\n",
    "from sklearn.metrics import accuracy_score # Accuracy classification score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay # to show confusion matrix\n",
    "from sklearn import metrics # Evaluate ROC curve\n",
    "from sklearn.experimental import enable_iterative_imputer # Enables IterativeImputer. The API and results of this estimator might change without any deprecation cycle\n",
    "from sklearn.impute import IterativeImputer\n",
    "from imblearn.combine import SMOTEENN # Combine over- and under-sampling using SMOTE and Edited Nearest Neighbours\n",
    "from sklearn import decomposition\n",
    "from boruta import BorutaPy\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_secom():\n",
    "    path ='C:/Users/duygu/OneDrive/Documents/VS_CODE_REPOS/Fault-Detection-SECOM/secom.data'\n",
    "    df = pd.read_csv(path, delimiter=' ', header=None, na_values=['NaN'])\n",
    "    df.columns = ['feature'+str(x+1) for x in range(len(df.columns))]\n",
    "    return df\n",
    "\n",
    "#%%\n",
    "def read_labels():\n",
    "    path = 'C:/Users/duygu/OneDrive/Documents/VS_CODE_REPOS/Fault-Detection-SECOM/secom_labels.data'\n",
    "    df = pd.read_csv(path, delimiter=' ', header=None, na_values=['NaN'])\n",
    "    df.columns = ['status','timestamp']\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'],dayfirst=True)\n",
    "    return df\n",
    "\n",
    "#read 2 df \n",
    "df_features = read_secom()\n",
    "df_target = read_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.concat([df_features,df_target],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature583</th>\n",
       "      <th>feature584</th>\n",
       "      <th>feature585</th>\n",
       "      <th>feature586</th>\n",
       "      <th>feature587</th>\n",
       "      <th>feature588</th>\n",
       "      <th>feature589</th>\n",
       "      <th>feature590</th>\n",
       "      <th>status</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3030.93</td>\n",
       "      <td>2564.00</td>\n",
       "      <td>2187.7333</td>\n",
       "      <td>1411.1265</td>\n",
       "      <td>1.3602</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.6133</td>\n",
       "      <td>0.1242</td>\n",
       "      <td>1.5005</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5005</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.3630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>2008-07-19 11:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3095.78</td>\n",
       "      <td>2465.14</td>\n",
       "      <td>2230.4222</td>\n",
       "      <td>1463.6606</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>100.0</td>\n",
       "      <td>102.3433</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>1.4966</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>4.4447</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>208.2045</td>\n",
       "      <td>-1</td>\n",
       "      <td>2008-07-19 12:32:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2932.61</td>\n",
       "      <td>2559.94</td>\n",
       "      <td>2186.4111</td>\n",
       "      <td>1698.0172</td>\n",
       "      <td>1.5102</td>\n",
       "      <td>100.0</td>\n",
       "      <td>95.4878</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>1.4436</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>3.1745</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>82.8602</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-07-19 13:17:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2988.72</td>\n",
       "      <td>2479.90</td>\n",
       "      <td>2199.0333</td>\n",
       "      <td>909.7926</td>\n",
       "      <td>1.3204</td>\n",
       "      <td>100.0</td>\n",
       "      <td>104.2367</td>\n",
       "      <td>0.1217</td>\n",
       "      <td>1.4882</td>\n",
       "      <td>-0.0124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4990</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>2.0544</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>-1</td>\n",
       "      <td>2008-07-19 14:43:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032.24</td>\n",
       "      <td>2502.87</td>\n",
       "      <td>2233.3667</td>\n",
       "      <td>1326.5200</td>\n",
       "      <td>1.5334</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.3967</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>1.5031</td>\n",
       "      <td>-0.0031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.4766</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>99.3032</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>-1</td>\n",
       "      <td>2008-07-19 15:22:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>2899.41</td>\n",
       "      <td>2464.36</td>\n",
       "      <td>2179.7333</td>\n",
       "      <td>3085.3781</td>\n",
       "      <td>1.4843</td>\n",
       "      <td>100.0</td>\n",
       "      <td>82.2467</td>\n",
       "      <td>0.1248</td>\n",
       "      <td>1.3424</td>\n",
       "      <td>-0.0045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4988</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>2.8669</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>203.1720</td>\n",
       "      <td>-1</td>\n",
       "      <td>2008-10-16 15:13:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>3052.31</td>\n",
       "      <td>2522.55</td>\n",
       "      <td>2198.5667</td>\n",
       "      <td>1124.6595</td>\n",
       "      <td>0.8763</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.4689</td>\n",
       "      <td>0.1205</td>\n",
       "      <td>1.4333</td>\n",
       "      <td>-0.0061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4975</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>2.6238</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>203.1720</td>\n",
       "      <td>-1</td>\n",
       "      <td>2008-10-16 20:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>2978.81</td>\n",
       "      <td>2379.78</td>\n",
       "      <td>2206.3000</td>\n",
       "      <td>1110.4967</td>\n",
       "      <td>0.8236</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.4122</td>\n",
       "      <td>0.1208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4987</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>3.0590</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>43.5231</td>\n",
       "      <td>-1</td>\n",
       "      <td>2008-10-17 05:26:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>2894.92</td>\n",
       "      <td>2532.01</td>\n",
       "      <td>2177.0333</td>\n",
       "      <td>1183.7287</td>\n",
       "      <td>1.5726</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.7978</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>1.4622</td>\n",
       "      <td>-0.0072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5004</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>3.5662</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>93.4941</td>\n",
       "      <td>-1</td>\n",
       "      <td>2008-10-17 06:01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>2944.92</td>\n",
       "      <td>2450.76</td>\n",
       "      <td>2195.4444</td>\n",
       "      <td>2914.1792</td>\n",
       "      <td>1.5978</td>\n",
       "      <td>100.0</td>\n",
       "      <td>85.1011</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4987</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>3.6275</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>137.7844</td>\n",
       "      <td>-1</td>\n",
       "      <td>2008-10-17 06:07:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1567 rows × 592 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature1  feature2   feature3   feature4  feature5  feature6  feature7  \\\n",
       "0      3030.93   2564.00  2187.7333  1411.1265    1.3602     100.0   97.6133   \n",
       "1      3095.78   2465.14  2230.4222  1463.6606    0.8294     100.0  102.3433   \n",
       "2      2932.61   2559.94  2186.4111  1698.0172    1.5102     100.0   95.4878   \n",
       "3      2988.72   2479.90  2199.0333   909.7926    1.3204     100.0  104.2367   \n",
       "4      3032.24   2502.87  2233.3667  1326.5200    1.5334     100.0  100.3967   \n",
       "...        ...       ...        ...        ...       ...       ...       ...   \n",
       "1562   2899.41   2464.36  2179.7333  3085.3781    1.4843     100.0   82.2467   \n",
       "1563   3052.31   2522.55  2198.5667  1124.6595    0.8763     100.0   98.4689   \n",
       "1564   2978.81   2379.78  2206.3000  1110.4967    0.8236     100.0   99.4122   \n",
       "1565   2894.92   2532.01  2177.0333  1183.7287    1.5726     100.0   98.7978   \n",
       "1566   2944.92   2450.76  2195.4444  2914.1792    1.5978     100.0   85.1011   \n",
       "\n",
       "      feature8  feature9  feature10  ...  feature583  feature584  feature585  \\\n",
       "0       0.1242    1.5005     0.0162  ...      0.5005      0.0118      0.0035   \n",
       "1       0.1247    1.4966    -0.0005  ...      0.5019      0.0223      0.0055   \n",
       "2       0.1241    1.4436     0.0041  ...      0.4958      0.0157      0.0039   \n",
       "3       0.1217    1.4882    -0.0124  ...      0.4990      0.0103      0.0025   \n",
       "4       0.1235    1.5031    -0.0031  ...      0.4800      0.4766      0.1045   \n",
       "...        ...       ...        ...  ...         ...         ...         ...   \n",
       "1562    0.1248    1.3424    -0.0045  ...      0.4988      0.0143      0.0039   \n",
       "1563    0.1205    1.4333    -0.0061  ...      0.4975      0.0131      0.0036   \n",
       "1564    0.1208       NaN        NaN  ...      0.4987      0.0153      0.0041   \n",
       "1565    0.1213    1.4622    -0.0072  ...      0.5004      0.0178      0.0038   \n",
       "1566    0.1235       NaN        NaN  ...      0.4987      0.0181      0.0040   \n",
       "\n",
       "      feature586  feature587  feature588  feature589  feature590  status  \\\n",
       "0         2.3630         NaN         NaN         NaN         NaN      -1   \n",
       "1         4.4447      0.0096      0.0201      0.0060    208.2045      -1   \n",
       "2         3.1745      0.0584      0.0484      0.0148     82.8602       1   \n",
       "3         2.0544      0.0202      0.0149      0.0044     73.8432      -1   \n",
       "4        99.3032      0.0202      0.0149      0.0044     73.8432      -1   \n",
       "...          ...         ...         ...         ...         ...     ...   \n",
       "1562      2.8669      0.0068      0.0138      0.0047    203.1720      -1   \n",
       "1563      2.6238      0.0068      0.0138      0.0047    203.1720      -1   \n",
       "1564      3.0590      0.0197      0.0086      0.0025     43.5231      -1   \n",
       "1565      3.5662      0.0262      0.0245      0.0075     93.4941      -1   \n",
       "1566      3.6275      0.0117      0.0162      0.0045    137.7844      -1   \n",
       "\n",
       "               timestamp  \n",
       "0    2008-07-19 11:55:00  \n",
       "1    2008-07-19 12:32:00  \n",
       "2    2008-07-19 13:17:00  \n",
       "3    2008-07-19 14:43:00  \n",
       "4    2008-07-19 15:22:00  \n",
       "...                  ...  \n",
       "1562 2008-10-16 15:13:00  \n",
       "1563 2008-10-16 20:49:00  \n",
       "1564 2008-10-17 05:26:00  \n",
       "1565 2008-10-17 06:01:00  \n",
       "1566 2008-10-17 06:07:00  \n",
       "\n",
       "[1567 rows x 592 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Training and test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:,:590]\n",
    "y = df.iloc[:,590]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 1,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33219"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature581</th>\n",
       "      <th>feature582</th>\n",
       "      <th>feature583</th>\n",
       "      <th>feature584</th>\n",
       "      <th>feature585</th>\n",
       "      <th>feature586</th>\n",
       "      <th>feature587</th>\n",
       "      <th>feature588</th>\n",
       "      <th>feature589</th>\n",
       "      <th>feature590</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>3079.77</td>\n",
       "      <td>2354.51</td>\n",
       "      <td>2207.0444</td>\n",
       "      <td>1269.6078</td>\n",
       "      <td>1.7571</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.0189</td>\n",
       "      <td>0.1221</td>\n",
       "      <td>1.4607</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>68.7444</td>\n",
       "      <td>0.5001</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>2.1899</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>68.7444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>3001.36</td>\n",
       "      <td>2491.23</td>\n",
       "      <td>2155.3111</td>\n",
       "      <td>918.2161</td>\n",
       "      <td>1.2753</td>\n",
       "      <td>100.0</td>\n",
       "      <td>105.0478</td>\n",
       "      <td>0.1227</td>\n",
       "      <td>1.4206</td>\n",
       "      <td>-0.0052</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4943</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>4.0318</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>163.9998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>3042.78</td>\n",
       "      <td>2377.89</td>\n",
       "      <td>2173.4556</td>\n",
       "      <td>1433.6732</td>\n",
       "      <td>1.0304</td>\n",
       "      <td>100.0</td>\n",
       "      <td>110.5422</td>\n",
       "      <td>0.1245</td>\n",
       "      <td>1.4964</td>\n",
       "      <td>0.0204</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4962</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>2.2877</td>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.0287</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>138.2861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>3018.64</td>\n",
       "      <td>2401.80</td>\n",
       "      <td>2224.0000</td>\n",
       "      <td>1510.0797</td>\n",
       "      <td>1.5611</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.8300</td>\n",
       "      <td>0.1199</td>\n",
       "      <td>1.4428</td>\n",
       "      <td>-0.0110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>49.7490</td>\n",
       "      <td>0.5047</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>1.9927</td>\n",
       "      <td>0.0284</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>49.7490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>3020.29</td>\n",
       "      <td>2433.99</td>\n",
       "      <td>2217.8111</td>\n",
       "      <td>1744.7771</td>\n",
       "      <td>0.9618</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.1789</td>\n",
       "      <td>0.1218</td>\n",
       "      <td>1.4950</td>\n",
       "      <td>-0.0097</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5010</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>2.9338</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>68.9871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>3057.31</td>\n",
       "      <td>2481.53</td>\n",
       "      <td>2214.9333</td>\n",
       "      <td>1663.7024</td>\n",
       "      <td>1.0203</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.4456</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>1.4830</td>\n",
       "      <td>-0.0328</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5037</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>3.4736</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>44.3686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>3009.71</td>\n",
       "      <td>2565.53</td>\n",
       "      <td>2224.6778</td>\n",
       "      <td>1308.6479</td>\n",
       "      <td>1.3907</td>\n",
       "      <td>100.0</td>\n",
       "      <td>101.1333</td>\n",
       "      <td>0.1208</td>\n",
       "      <td>1.4440</td>\n",
       "      <td>-0.0079</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4979</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>1.5724</td>\n",
       "      <td>0.0275</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>78.1199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>3034.34</td>\n",
       "      <td>2631.47</td>\n",
       "      <td>2179.0445</td>\n",
       "      <td>2028.2208</td>\n",
       "      <td>1.5552</td>\n",
       "      <td>100.0</td>\n",
       "      <td>95.4256</td>\n",
       "      <td>0.1234</td>\n",
       "      <td>1.4281</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4968</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.5829</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>38.9781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1556</th>\n",
       "      <td>3025.21</td>\n",
       "      <td>2503.30</td>\n",
       "      <td>2179.7333</td>\n",
       "      <td>3085.3781</td>\n",
       "      <td>1.4843</td>\n",
       "      <td>100.0</td>\n",
       "      <td>82.2467</td>\n",
       "      <td>0.1248</td>\n",
       "      <td>1.3687</td>\n",
       "      <td>-0.0070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>46.1076</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>3.1428</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>46.1076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>2997.07</td>\n",
       "      <td>2543.11</td>\n",
       "      <td>2256.1222</td>\n",
       "      <td>1226.2217</td>\n",
       "      <td>1.4656</td>\n",
       "      <td>100.0</td>\n",
       "      <td>106.3122</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>1.4779</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5014</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>2.3055</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1253 rows × 590 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature1  feature2   feature3   feature4  feature5  feature6  feature7  \\\n",
       "443    3079.77   2354.51  2207.0444  1269.6078    1.7571     100.0   97.0189   \n",
       "760    3001.36   2491.23  2155.3111   918.2161    1.2753     100.0  105.0478   \n",
       "479    3042.78   2377.89  2173.4556  1433.6732    1.0304     100.0  110.5422   \n",
       "362    3018.64   2401.80  2224.0000  1510.0797    1.5611     100.0   99.8300   \n",
       "662    3020.29   2433.99  2217.8111  1744.7771    0.9618     100.0  100.1789   \n",
       "...        ...       ...        ...        ...       ...       ...       ...   \n",
       "669    3057.31   2481.53  2214.9333  1663.7024    1.0203     100.0  100.4456   \n",
       "821    3009.71   2565.53  2224.6778  1308.6479    1.3907     100.0  101.1333   \n",
       "213    3034.34   2631.47  2179.0445  2028.2208    1.5552     100.0   95.4256   \n",
       "1556   3025.21   2503.30  2179.7333  3085.3781    1.4843     100.0   82.2467   \n",
       "181    2997.07   2543.11  2256.1222  1226.2217    1.4656     100.0  106.3122   \n",
       "\n",
       "      feature8  feature9  feature10  ...  feature581  feature582  feature583  \\\n",
       "443     0.1221    1.4607     0.0155  ...      0.0059     68.7444      0.5001   \n",
       "760     0.1227    1.4206    -0.0052  ...         NaN         NaN      0.4943   \n",
       "479     0.1245    1.4964     0.0204  ...         NaN         NaN      0.4962   \n",
       "362     0.1199    1.4428    -0.0110  ...      0.0038     49.7490      0.5047   \n",
       "662     0.1218    1.4950    -0.0097  ...         NaN         NaN      0.5010   \n",
       "...        ...       ...        ...  ...         ...         ...         ...   \n",
       "669     0.1247    1.4830    -0.0328  ...         NaN         NaN      0.5037   \n",
       "821     0.1208    1.4440    -0.0079  ...         NaN         NaN      0.4979   \n",
       "213     0.1234    1.4281     0.0049  ...         NaN         NaN      0.4968   \n",
       "1556    0.1248    1.3687    -0.0070  ...      0.0016     46.1076      0.5019   \n",
       "181     0.1209    1.4779     0.0052  ...         NaN         NaN      0.5014   \n",
       "\n",
       "      feature584  feature585  feature586  feature587  feature588  feature589  \\\n",
       "443       0.0110      0.0034      2.1899      0.0282      0.0194      0.0059   \n",
       "760       0.0199      0.0042      4.0318      0.0169      0.0276      0.0081   \n",
       "479       0.0114      0.0034      2.2877      0.0208      0.0287      0.0091   \n",
       "362       0.0101      0.0031      1.9927      0.0284      0.0141      0.0038   \n",
       "662       0.0147      0.0036      2.9338      0.0165      0.0114      0.0043   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "669       0.0175      0.0039      3.4736      0.0263      0.0117      0.0033   \n",
       "821       0.0078      0.0024      1.5724      0.0275      0.0215      0.0076   \n",
       "213       0.0128      0.0035      2.5829      0.0298      0.0116      0.0039   \n",
       "1556      0.0158      0.0043      3.1428      0.0120      0.0055      0.0016   \n",
       "181       0.0116      0.0031      2.3055     -0.0012      0.0220      0.0072   \n",
       "\n",
       "      feature590  \n",
       "443      68.7444  \n",
       "760     163.9998  \n",
       "479     138.2861  \n",
       "362      49.7490  \n",
       "662      68.9871  \n",
       "...          ...  \n",
       "669      44.3686  \n",
       "821      78.1199  \n",
       "213      38.9781  \n",
       "1556     46.1076  \n",
       "181       0.0000  \n",
       "\n",
       "[1253 rows x 590 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train2=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reducing dimensionality "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_values(df):\n",
    "    \"\"\"a function to show null values with percentage\"\"\"\n",
    "    nv=pd.concat([df.isnull().sum(), 100 * df.isnull().sum()/df.shape[0]],axis=1).rename(columns={0:'Missing_Records', 1:'Percentage (%)'})\n",
    "    return nv[nv.Missing_Records>0].sort_values('Missing_Records', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing_Records</th>\n",
       "      <th>Percentage (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feature293</th>\n",
       "      <td>1144</td>\n",
       "      <td>91.300878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature158</th>\n",
       "      <td>1144</td>\n",
       "      <td>91.300878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature159</th>\n",
       "      <td>1144</td>\n",
       "      <td>91.300878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature294</th>\n",
       "      <td>1144</td>\n",
       "      <td>91.300878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature221</th>\n",
       "      <td>1072</td>\n",
       "      <td>85.554669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature500</th>\n",
       "      <td>1</td>\n",
       "      <td>0.079808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature367</th>\n",
       "      <td>1</td>\n",
       "      <td>0.079808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature377</th>\n",
       "      <td>1</td>\n",
       "      <td>0.079808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature378</th>\n",
       "      <td>1</td>\n",
       "      <td>0.079808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature590</th>\n",
       "      <td>1</td>\n",
       "      <td>0.079808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>494 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Missing_Records  Percentage (%)\n",
       "feature293             1144       91.300878\n",
       "feature158             1144       91.300878\n",
       "feature159             1144       91.300878\n",
       "feature294             1144       91.300878\n",
       "feature221             1072       85.554669\n",
       "...                     ...             ...\n",
       "feature500                1        0.079808\n",
       "feature367                1        0.079808\n",
       "feature377                1        0.079808\n",
       "feature378                1        0.079808\n",
       "feature590                1        0.079808\n",
       "\n",
       "[494 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_na = null_values(x_train)\n",
    "x_train_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing_Records</th>\n",
       "      <th>Percentage (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feature293</th>\n",
       "      <td>1144</td>\n",
       "      <td>91.300878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature158</th>\n",
       "      <td>1144</td>\n",
       "      <td>91.300878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature159</th>\n",
       "      <td>1144</td>\n",
       "      <td>91.300878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature294</th>\n",
       "      <td>1144</td>\n",
       "      <td>91.300878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature221</th>\n",
       "      <td>1072</td>\n",
       "      <td>85.554669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature86</th>\n",
       "      <td>1072</td>\n",
       "      <td>85.554669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature359</th>\n",
       "      <td>1072</td>\n",
       "      <td>85.554669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature493</th>\n",
       "      <td>1072</td>\n",
       "      <td>85.554669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Missing_Records  Percentage (%)\n",
       "feature293             1144       91.300878\n",
       "feature158             1144       91.300878\n",
       "feature159             1144       91.300878\n",
       "feature294             1144       91.300878\n",
       "feature221             1072       85.554669\n",
       "feature86              1072       85.554669\n",
       "feature359             1072       85.554669\n",
       "feature493             1072       85.554669"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miss_threshold=80\n",
    "x_train_na= x_train_na[x_train_na[\"Percentage (%)\"] > miss_threshold]\n",
    "x_train_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1253, 582)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_new = x_train.drop(axis=1, columns=x_train_na.index)\n",
    "x_train_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### removing constant voltality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feature1</th>\n",
       "      <td>1248.0</td>\n",
       "      <td>3014.113686</td>\n",
       "      <td>73.877303</td>\n",
       "      <td>2743.2400</td>\n",
       "      <td>2966.2300</td>\n",
       "      <td>3011.40500</td>\n",
       "      <td>3056.310000</td>\n",
       "      <td>3356.3500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature2</th>\n",
       "      <td>1247.0</td>\n",
       "      <td>2496.400585</td>\n",
       "      <td>79.188651</td>\n",
       "      <td>2162.8700</td>\n",
       "      <td>2452.3350</td>\n",
       "      <td>2500.38000</td>\n",
       "      <td>2539.600000</td>\n",
       "      <td>2846.4400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature3</th>\n",
       "      <td>1243.0</td>\n",
       "      <td>2200.216525</td>\n",
       "      <td>29.939025</td>\n",
       "      <td>2060.6600</td>\n",
       "      <td>2180.8611</td>\n",
       "      <td>2200.98890</td>\n",
       "      <td>2218.055500</td>\n",
       "      <td>2315.2667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature4</th>\n",
       "      <td>1243.0</td>\n",
       "      <td>1394.907987</td>\n",
       "      <td>436.632421</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1083.8858</td>\n",
       "      <td>1283.43680</td>\n",
       "      <td>1593.122000</td>\n",
       "      <td>3715.0417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature5</th>\n",
       "      <td>1243.0</td>\n",
       "      <td>4.018582</td>\n",
       "      <td>54.572445</td>\n",
       "      <td>0.6815</td>\n",
       "      <td>1.0160</td>\n",
       "      <td>1.31710</td>\n",
       "      <td>1.525700</td>\n",
       "      <td>1114.5366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature586</th>\n",
       "      <td>1252.0</td>\n",
       "      <td>3.084501</td>\n",
       "      <td>3.968128</td>\n",
       "      <td>1.1975</td>\n",
       "      <td>2.3058</td>\n",
       "      <td>2.74655</td>\n",
       "      <td>3.258475</td>\n",
       "      <td>99.3032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature587</th>\n",
       "      <td>1252.0</td>\n",
       "      <td>0.021521</td>\n",
       "      <td>0.012421</td>\n",
       "      <td>-0.0060</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>0.02070</td>\n",
       "      <td>0.027600</td>\n",
       "      <td>0.1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature588</th>\n",
       "      <td>1252.0</td>\n",
       "      <td>0.016344</td>\n",
       "      <td>0.008698</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>0.01480</td>\n",
       "      <td>0.019800</td>\n",
       "      <td>0.0799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature589</th>\n",
       "      <td>1252.0</td>\n",
       "      <td>0.005248</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.00460</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>0.0286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature590</th>\n",
       "      <td>1252.0</td>\n",
       "      <td>98.616399</td>\n",
       "      <td>92.379122</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>44.3686</td>\n",
       "      <td>71.53330</td>\n",
       "      <td>114.415300</td>\n",
       "      <td>737.3048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>582 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             count         mean         std        min        25%         50%  \\\n",
       "feature1    1248.0  3014.113686   73.877303  2743.2400  2966.2300  3011.40500   \n",
       "feature2    1247.0  2496.400585   79.188651  2162.8700  2452.3350  2500.38000   \n",
       "feature3    1243.0  2200.216525   29.939025  2060.6600  2180.8611  2200.98890   \n",
       "feature4    1243.0  1394.907987  436.632421     0.0000  1083.8858  1283.43680   \n",
       "feature5    1243.0     4.018582   54.572445     0.6815     1.0160     1.31710   \n",
       "...            ...          ...         ...        ...        ...         ...   \n",
       "feature586  1252.0     3.084501    3.968128     1.1975     2.3058     2.74655   \n",
       "feature587  1252.0     0.021521    0.012421    -0.0060     0.0134     0.02070   \n",
       "feature588  1252.0     0.016344    0.008698     0.0042     0.0106     0.01480   \n",
       "feature589  1252.0     0.005248    0.002850     0.0012     0.0033     0.00460   \n",
       "feature590  1252.0    98.616399   92.379122     0.0000    44.3686    71.53330   \n",
       "\n",
       "                    75%        max  \n",
       "feature1    3056.310000  3356.3500  \n",
       "feature2    2539.600000  2846.4400  \n",
       "feature3    2218.055500  2315.2667  \n",
       "feature4    1593.122000  3715.0417  \n",
       "feature5       1.525700  1114.5366  \n",
       "...                 ...        ...  \n",
       "feature586     3.258475    99.3032  \n",
       "feature587     0.027600     0.1028  \n",
       "feature588     0.019800     0.0799  \n",
       "feature589     0.006300     0.0286  \n",
       "feature590   114.415300   737.3048  \n",
       "\n",
       "[582 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_new_eda= x_train_new.describe().T\n",
    "x_train_new_eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feature6</th>\n",
       "      <td>1243.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature14</th>\n",
       "      <td>1251.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature43</th>\n",
       "      <td>1253.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature50</th>\n",
       "      <td>1253.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature53</th>\n",
       "      <td>1253.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature535</th>\n",
       "      <td>1247.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature536</th>\n",
       "      <td>1247.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature537</th>\n",
       "      <td>1247.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature538</th>\n",
       "      <td>1247.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature539</th>\n",
       "      <td>1247.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             count   mean  std    min    25%    50%    75%    max\n",
       "feature6    1243.0  100.0  0.0  100.0  100.0  100.0  100.0  100.0\n",
       "feature14   1251.0    0.0  0.0    0.0    0.0    0.0    0.0    0.0\n",
       "feature43   1253.0   70.0  0.0   70.0   70.0   70.0   70.0   70.0\n",
       "feature50   1253.0    1.0  0.0    1.0    1.0    1.0    1.0    1.0\n",
       "feature53   1253.0    0.0  0.0    0.0    0.0    0.0    0.0    0.0\n",
       "...            ...    ...  ...    ...    ...    ...    ...    ...\n",
       "feature535  1247.0    0.0  0.0    0.0    0.0    0.0    0.0    0.0\n",
       "feature536  1247.0    0.0  0.0    0.0    0.0    0.0    0.0    0.0\n",
       "feature537  1247.0    0.0  0.0    0.0    0.0    0.0    0.0    0.0\n",
       "feature538  1247.0    0.0  0.0    0.0    0.0    0.0    0.0    0.0\n",
       "feature539  1247.0    0.0  0.0    0.0    0.0    0.0    0.0    0.0\n",
       "\n",
       "[116 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_new_eda[x_train_new_eda['std']==0]\n",
    "x_train_new_std= x_train_new_eda[x_train_new_eda[\"std\"] == 0]\n",
    "x_train_new_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1253, 466)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_new_2 = x_train_new.drop(axis=1, columns=x_train_new_std.index)\n",
    "x_train_new_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_3s=x_train_new_2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore(df,cols,thr):\n",
    "    for col in cols:\n",
    "        mean=df[col].mean()\n",
    "        std=df[col].std()\n",
    "        upper_bound=mean+ thr*std\n",
    "        lower_bound=mean- thr*std\n",
    "        df[col]=np.where(df[col]>upper_bound,upper_bound,np.where(df[col]<lower_bound,lower_bound,df[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "zscore(x_train_3s,x_train_3s.columns,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1394.907986725665"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_new_2['feature4'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "436.63242083048897"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x_train_new_2['feature4'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2704.805249217132"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_new_2['feature4'].mean()+3*x_train_new_2['feature4'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3715.0417"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_new_2['feature4'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2704.805249217132"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_3s['feature4'].max()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with fit_transform we already scaled data.\n",
    "#scaler = MinMaxScaler()\n",
    "#x_train_scaled = pd.DataFrame(scaler.fit_transform(x_train_3s), columns=x_train_3s.columns)\n",
    "#x_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing values and save it as a temporary dataset.\n",
    "knn = KNNImputer()\n",
    "knn.fit(x_train_3s)\n",
    "imputed_train = pd.DataFrame(knn.transform(x_train_3s), columns = x_train_3s.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>...</th>\n",
       "      <th>feature581</th>\n",
       "      <th>feature582</th>\n",
       "      <th>feature583</th>\n",
       "      <th>feature584</th>\n",
       "      <th>feature585</th>\n",
       "      <th>feature586</th>\n",
       "      <th>feature587</th>\n",
       "      <th>feature588</th>\n",
       "      <th>feature589</th>\n",
       "      <th>feature590</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3079.77</td>\n",
       "      <td>2354.51</td>\n",
       "      <td>2207.0444</td>\n",
       "      <td>1269.607800</td>\n",
       "      <td>1.7571</td>\n",
       "      <td>97.018900</td>\n",
       "      <td>0.1221</td>\n",
       "      <td>1.4607</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00590</td>\n",
       "      <td>68.74440</td>\n",
       "      <td>0.5001</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>2.1899</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>68.7444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3001.36</td>\n",
       "      <td>2491.23</td>\n",
       "      <td>2155.3111</td>\n",
       "      <td>918.216100</td>\n",
       "      <td>1.2753</td>\n",
       "      <td>105.047800</td>\n",
       "      <td>0.1227</td>\n",
       "      <td>1.4206</td>\n",
       "      <td>-0.0052</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00720</td>\n",
       "      <td>63.99824</td>\n",
       "      <td>0.4943</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>4.0318</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>163.9998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3042.78</td>\n",
       "      <td>2377.89</td>\n",
       "      <td>2173.4556</td>\n",
       "      <td>1433.673200</td>\n",
       "      <td>1.0304</td>\n",
       "      <td>110.542200</td>\n",
       "      <td>0.1245</td>\n",
       "      <td>1.4964</td>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.0133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00330</td>\n",
       "      <td>72.86980</td>\n",
       "      <td>0.4962</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>2.2877</td>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.0287</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>138.2861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3018.64</td>\n",
       "      <td>2401.80</td>\n",
       "      <td>2224.0000</td>\n",
       "      <td>1510.079700</td>\n",
       "      <td>1.5611</td>\n",
       "      <td>99.830000</td>\n",
       "      <td>0.1199</td>\n",
       "      <td>1.4428</td>\n",
       "      <td>-0.0110</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00380</td>\n",
       "      <td>49.74900</td>\n",
       "      <td>0.5047</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>1.9927</td>\n",
       "      <td>0.0284</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>49.7490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3020.29</td>\n",
       "      <td>2433.99</td>\n",
       "      <td>2217.8111</td>\n",
       "      <td>1744.777100</td>\n",
       "      <td>0.9618</td>\n",
       "      <td>100.178900</td>\n",
       "      <td>0.1218</td>\n",
       "      <td>1.4950</td>\n",
       "      <td>-0.0097</td>\n",
       "      <td>-0.0054</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00540</td>\n",
       "      <td>69.47592</td>\n",
       "      <td>0.5010</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>2.9338</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>68.9871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>3057.31</td>\n",
       "      <td>2481.53</td>\n",
       "      <td>2214.9333</td>\n",
       "      <td>1663.702400</td>\n",
       "      <td>1.0203</td>\n",
       "      <td>100.445600</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>1.4830</td>\n",
       "      <td>-0.0328</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00480</td>\n",
       "      <td>55.49078</td>\n",
       "      <td>0.5037</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>3.4736</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>44.3686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>3009.71</td>\n",
       "      <td>2565.53</td>\n",
       "      <td>2224.6778</td>\n",
       "      <td>1308.647900</td>\n",
       "      <td>1.3907</td>\n",
       "      <td>101.133300</td>\n",
       "      <td>0.1208</td>\n",
       "      <td>1.4440</td>\n",
       "      <td>-0.0079</td>\n",
       "      <td>-0.0076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00484</td>\n",
       "      <td>151.46970</td>\n",
       "      <td>0.4979</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>1.5724</td>\n",
       "      <td>0.0275</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>78.1199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>3034.34</td>\n",
       "      <td>2631.47</td>\n",
       "      <td>2179.0445</td>\n",
       "      <td>2028.220800</td>\n",
       "      <td>1.5552</td>\n",
       "      <td>95.425600</td>\n",
       "      <td>0.1234</td>\n",
       "      <td>1.4281</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00436</td>\n",
       "      <td>84.81790</td>\n",
       "      <td>0.4968</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.5829</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>38.9781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>3025.21</td>\n",
       "      <td>2503.30</td>\n",
       "      <td>2179.7333</td>\n",
       "      <td>2704.805249</td>\n",
       "      <td>1.4843</td>\n",
       "      <td>82.357569</td>\n",
       "      <td>0.1248</td>\n",
       "      <td>1.3687</td>\n",
       "      <td>-0.0070</td>\n",
       "      <td>-0.0033</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00160</td>\n",
       "      <td>46.10760</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>3.1428</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>46.1076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>2997.07</td>\n",
       "      <td>2543.11</td>\n",
       "      <td>2256.1222</td>\n",
       "      <td>1226.221700</td>\n",
       "      <td>1.4656</td>\n",
       "      <td>106.312200</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>1.4779</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>-0.0013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00510</td>\n",
       "      <td>82.73494</td>\n",
       "      <td>0.5014</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>2.3055</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1253 rows × 466 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature1  feature2   feature3     feature4  feature5    feature7  \\\n",
       "0      3079.77   2354.51  2207.0444  1269.607800    1.7571   97.018900   \n",
       "1      3001.36   2491.23  2155.3111   918.216100    1.2753  105.047800   \n",
       "2      3042.78   2377.89  2173.4556  1433.673200    1.0304  110.542200   \n",
       "3      3018.64   2401.80  2224.0000  1510.079700    1.5611   99.830000   \n",
       "4      3020.29   2433.99  2217.8111  1744.777100    0.9618  100.178900   \n",
       "...        ...       ...        ...          ...       ...         ...   \n",
       "1248   3057.31   2481.53  2214.9333  1663.702400    1.0203  100.445600   \n",
       "1249   3009.71   2565.53  2224.6778  1308.647900    1.3907  101.133300   \n",
       "1250   3034.34   2631.47  2179.0445  2028.220800    1.5552   95.425600   \n",
       "1251   3025.21   2503.30  2179.7333  2704.805249    1.4843   82.357569   \n",
       "1252   2997.07   2543.11  2256.1222  1226.221700    1.4656  106.312200   \n",
       "\n",
       "      feature8  feature9  feature10  feature11  ...  feature581  feature582  \\\n",
       "0       0.1221    1.4607     0.0155     0.0093  ...     0.00590    68.74440   \n",
       "1       0.1227    1.4206    -0.0052     0.0010  ...     0.00720    63.99824   \n",
       "2       0.1245    1.4964     0.0204     0.0133  ...     0.00330    72.86980   \n",
       "3       0.1199    1.4428    -0.0110     0.0101  ...     0.00380    49.74900   \n",
       "4       0.1218    1.4950    -0.0097    -0.0054  ...     0.00540    69.47592   \n",
       "...        ...       ...        ...        ...  ...         ...         ...   \n",
       "1248    0.1247    1.4830    -0.0328     0.0048  ...     0.00480    55.49078   \n",
       "1249    0.1208    1.4440    -0.0079    -0.0076  ...     0.00484   151.46970   \n",
       "1250    0.1234    1.4281     0.0049     0.0092  ...     0.00436    84.81790   \n",
       "1251    0.1248    1.3687    -0.0070    -0.0033  ...     0.00160    46.10760   \n",
       "1252    0.1209    1.4779     0.0052    -0.0013  ...     0.00510    82.73494   \n",
       "\n",
       "      feature583  feature584  feature585  feature586  feature587  feature588  \\\n",
       "0         0.5001      0.0110      0.0034      2.1899      0.0282      0.0194   \n",
       "1         0.4943      0.0199      0.0042      4.0318      0.0169      0.0276   \n",
       "2         0.4962      0.0114      0.0034      2.2877      0.0208      0.0287   \n",
       "3         0.5047      0.0101      0.0031      1.9927      0.0284      0.0141   \n",
       "4         0.5010      0.0147      0.0036      2.9338      0.0165      0.0114   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1248      0.5037      0.0175      0.0039      3.4736      0.0263      0.0117   \n",
       "1249      0.4979      0.0078      0.0024      1.5724      0.0275      0.0215   \n",
       "1250      0.4968      0.0128      0.0035      2.5829      0.0298      0.0116   \n",
       "1251      0.5019      0.0158      0.0043      3.1428      0.0120      0.0055   \n",
       "1252      0.5014      0.0116      0.0031      2.3055     -0.0012      0.0220   \n",
       "\n",
       "      feature589  feature590  \n",
       "0         0.0059     68.7444  \n",
       "1         0.0081    163.9998  \n",
       "2         0.0091    138.2861  \n",
       "3         0.0038     49.7490  \n",
       "4         0.0043     68.9871  \n",
       "...          ...         ...  \n",
       "1248      0.0033     44.3686  \n",
       "1249      0.0076     78.1199  \n",
       "1250      0.0039     38.9781  \n",
       "1251      0.0016     46.1076  \n",
       "1252      0.0072      0.0000  \n",
       "\n",
       "[1253 rows x 466 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_train.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retransformed_train= pd.DataFrame(scaler.inverse_transform(imputed_train), columns=imputed_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BORUTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier _ {'n_jobs': -1, 'class_weight': 'balanced_subsample', 'max_depth': 5, 'random_state': 100}\n",
      "RandomForestClassifier _ {'n_jobs': -1, 'class_weight': 'balanced_subsample', 'max_depth': 7, 'random_state': 100}\n",
      "RandomForestClassifier _ {'n_jobs': -1, 'class_weight': 'balanced_subsample', 'max_depth': 9, 'random_state': 100}\n",
      "XGB _ {'a': 100, 'b': 'a', 'c': 111, 'd': 100}\n",
      "XGB _ {'a': 3333, 'b': 'b', 'c': 555, 'd': 100}\n"
     ]
    }
   ],
   "source": [
    "#Boruta function\n",
    "which_model = ['RandomForestClassifier', 'XGB']\n",
    "\n",
    "\n",
    "list_of_list_dict = [ [ {                   'n_jobs':         -1, \n",
    "                                            'class_weight':   'balanced_subsample',\n",
    "                                            'max_depth':      5,\n",
    "                                            'random_state':   100\n",
    "                                        },\n",
    "\n",
    "                                    {       'n_jobs':         -1, \n",
    "                                            'class_weight':   'balanced_subsample',\n",
    "                                            'max_depth':      7,\n",
    "                                            'random_state':   100\n",
    "                                        },\n",
    "\n",
    "                                    {       'n_jobs':         -1, \n",
    "                                            'class_weight':   'balanced_subsample',\n",
    "                                            'max_depth':      9,\n",
    "                                            'random_state':   100\n",
    "                                                        }\n",
    "                                    ],\n",
    "\n",
    "                    [ {                     'a':   100, \n",
    "                                            'b':   'a',\n",
    "                                            'c':   111,\n",
    "                                            'd':   100\n",
    "                                        },\n",
    "\n",
    "                                    {       'a':    3333, \n",
    "                                            'b':   'b',\n",
    "                                            'c':   555,\n",
    "                                            'd':   100\n",
    "                                        }\n",
    "                                        ]\n",
    "                    ]\n",
    "\n",
    "for m in which_model:\n",
    "    if m=='RandomForestClassifier': \n",
    "        for p in list_of_list_dict[0]:\n",
    "            print(m,'_',p)\n",
    "            X_train = BorutaFeatureSelection(X, y, m, p)\n",
    "            print(X_train.columns)\n",
    "    if m=='XGB': \n",
    "        for p in list_of_list_dict[1]:\n",
    "            print(m,'_',p)\n",
    "            X_train = BorutaFeatureSelection(X, y, m, p)\n",
    "            print(X_train.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier _ {'n_jobs': -1, 'class_weight': 'balanced_subsample', 'max_depth': 5, 'random_state': 100}\n",
      "RandomForestClassifier _ {'n_jobs': -1, 'class_weight': 'balanced_subsample', 'max_depth': 7, 'random_state': 100}\n",
      "RandomForestClassifier _ {'n_jobs': -1, 'class_weight': 'balanced_subsample', 'max_depth': 9, 'random_state': 100}\n",
      "XGB _ {'a': 100, 'b': 'a', 'c': 111, 'd': 100}\n",
      "XGB _ {'a': 3333, 'b': 'b', 'c': 555, 'd': 100}\n"
     ]
    }
   ],
   "source": [
    "#Boruta function\n",
    "which_model = ['RandomForestClassifier', 'XGB']\n",
    "\n",
    "\n",
    "list_dict_RF = [ {                   'n_jobs':         -1, \n",
    "                                            'class_weight':   'balanced_subsample',\n",
    "                                            'max_depth':      5,\n",
    "                                            'random_state':   100\n",
    "                                        },\n",
    "\n",
    "                                    {       'n_jobs':         -1, \n",
    "                                            'class_weight':   'balanced_subsample',\n",
    "                                            'max_depth':      7,\n",
    "                                            'random_state':   100\n",
    "                                        },\n",
    "\n",
    "                                    {       'n_jobs':         -1, \n",
    "                                            'class_weight':   'balanced_subsample',\n",
    "                                            'max_depth':      9,\n",
    "                                            'random_state':   100\n",
    "                                                        }\n",
    "                                    ]\n",
    "#-------------------\n",
    "list_dict_XGB =                    [ {                     'a':   100, \n",
    "                                            'b':   'a',\n",
    "                                            'c':   111,\n",
    "                                            'd':   100\n",
    "                                        },\n",
    "\n",
    "                                    {       'a':    3333, \n",
    "                                            'b':   'b',\n",
    "                                            'c':   555,\n",
    "                                            'd':   100\n",
    "                                        }\n",
    "                                        ]\n",
    "                    \n",
    "\n",
    "for m in which_model:\n",
    "    if m=='RandomForestClassifier': \n",
    "        for p in list_dict_RF:\n",
    "            print(m,'_',p)\n",
    "            #X_train = BorutaFeatureSelection(X, y, m, p)\n",
    "            #print(X_train.columns)\n",
    "    if m=='XGB': \n",
    "        for p in list_dict_XGB:\n",
    "            print(m,'_',p)\n",
    "            #X_train = BorutaFeatureSelection(X, y, m, p)\n",
    "            #print(X_train.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boruta function\n",
    "which_model = ['RandomForestClassifier', 'XGB']\n",
    "\n",
    "model_params = {   n_jobs:         -1, \n",
    "                        class_weight:   'balanced_subsample',\n",
    "                        max_depth:      5,\n",
    "                        random_state:   100\n",
    "                     }\n",
    "\n",
    "\n",
    "random=5, width=10\n",
    "\n",
    "def BorutaFeatureSelection(X, y, which_model, model_params) :\n",
    "\n",
    "    if which_model == 'RandomForestClassifier':\n",
    "        model = RandomForestClassifier(X,y,**model_params)\n",
    "    elif which_model == 'XGB':\n",
    "        model = XGB(X,y**model_params)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #--------------------------\n",
    "    feature_names = np.array(X.columns)\n",
    "    model.fit(X, y)\n",
    "    # define Boruta feature selection method\n",
    "    feature_selector = BorutaPy(model, n_estimators='auto', verbose=2, random_state=100, max_iter=100)\n",
    "\n",
    "    # find all relevant features\n",
    "    feature_selector.fit(X.to_numpy(),y)\n",
    "\n",
    "    # check selected features\n",
    "    feature_selector.support_\n",
    "\n",
    "    # check ranking of features\n",
    "    feature_selector.ranking_\n",
    "\n",
    "    # zip feature names, ranks, and decisions \n",
    "    feature_ranks = list(zip(feature_names, \n",
    "                             feature_selector.ranking_, \n",
    "                             feature_selector.support_))\n",
    "\n",
    "    # print the results\n",
    "    for feat in feature_ranks:\n",
    "        print('Feature: {:<30} Rank: {},  Keep: {}'.format(feat[0], feat[1], feat[2]))\n",
    "        \n",
    "    final_features = list()\n",
    "    indexes = np.where(feature_selector.ranking_ <= 1)\n",
    "    for x in np.nditer(indexes):\n",
    "        final_features.append(feature_names[x])\n",
    "    print(final_features)\n",
    "    \n",
    "    # call transform() on X to filter it down to selected features\n",
    "    #--------------------------\n",
    "\n",
    "\n",
    "    return pd.DataFrame(X.filter(final_features)) , final_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t1 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t466\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t466\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t466\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t466\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t466\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t466\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t466\n",
      "Rejected: \t0\n",
      "Iteration: \t8 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t17\n",
      "Rejected: \t449\n",
      "Iteration: \t9 / 100\n",
      "Confirmed: \t1\n",
      "Tentative: \t16\n",
      "Rejected: \t449\n",
      "Iteration: \t10 / 100\n",
      "Confirmed: \t1\n",
      "Tentative: \t16\n",
      "Rejected: \t449\n",
      "Iteration: \t11 / 100\n",
      "Confirmed: \t1\n",
      "Tentative: \t16\n",
      "Rejected: \t449\n",
      "Iteration: \t12 / 100\n",
      "Confirmed: \t1\n",
      "Tentative: \t16\n",
      "Rejected: \t449\n",
      "Iteration: \t13 / 100\n",
      "Confirmed: \t1\n",
      "Tentative: \t16\n",
      "Rejected: \t449\n",
      "Iteration: \t14 / 100\n",
      "Confirmed: \t1\n",
      "Tentative: \t16\n",
      "Rejected: \t449\n",
      "Iteration: \t15 / 100\n",
      "Confirmed: \t1\n",
      "Tentative: \t16\n",
      "Rejected: \t449\n",
      "Iteration: \t16 / 100\n",
      "Confirmed: \t4\n",
      "Tentative: \t13\n",
      "Rejected: \t449\n",
      "Iteration: \t17 / 100\n",
      "Confirmed: \t4\n",
      "Tentative: \t13\n",
      "Rejected: \t449\n",
      "Iteration: \t18 / 100\n",
      "Confirmed: \t4\n",
      "Tentative: \t13\n",
      "Rejected: \t449\n",
      "Iteration: \t19 / 100\n",
      "Confirmed: \t4\n",
      "Tentative: \t13\n",
      "Rejected: \t449\n",
      "Iteration: \t20 / 100\n",
      "Confirmed: \t4\n",
      "Tentative: \t13\n",
      "Rejected: \t449\n",
      "Iteration: \t21 / 100\n",
      "Confirmed: \t4\n",
      "Tentative: \t13\n",
      "Rejected: \t449\n",
      "Iteration: \t22 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t12\n",
      "Rejected: \t449\n",
      "Iteration: \t23 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t12\n",
      "Rejected: \t449\n",
      "Iteration: \t24 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t12\n",
      "Rejected: \t449\n",
      "Iteration: \t25 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t12\n",
      "Rejected: \t449\n",
      "Iteration: \t26 / 100\n",
      "Confirmed: \t7\n",
      "Tentative: \t10\n",
      "Rejected: \t449\n",
      "Iteration: \t27 / 100\n",
      "Confirmed: \t7\n",
      "Tentative: \t10\n",
      "Rejected: \t449\n",
      "Iteration: \t28 / 100\n",
      "Confirmed: \t7\n",
      "Tentative: \t10\n",
      "Rejected: \t449\n",
      "Iteration: \t29 / 100\n",
      "Confirmed: \t8\n",
      "Tentative: \t9\n",
      "Rejected: \t449\n",
      "Iteration: \t30 / 100\n",
      "Confirmed: \t8\n",
      "Tentative: \t9\n",
      "Rejected: \t449\n",
      "Iteration: \t31 / 100\n",
      "Confirmed: \t8\n",
      "Tentative: \t9\n",
      "Rejected: \t449\n",
      "Iteration: \t32 / 100\n",
      "Confirmed: \t8\n",
      "Tentative: \t9\n",
      "Rejected: \t449\n",
      "Iteration: \t33 / 100\n",
      "Confirmed: \t8\n",
      "Tentative: \t9\n",
      "Rejected: \t449\n",
      "Iteration: \t34 / 100\n",
      "Confirmed: \t8\n",
      "Tentative: \t9\n",
      "Rejected: \t449\n",
      "Iteration: \t35 / 100\n",
      "Confirmed: \t8\n",
      "Tentative: \t9\n",
      "Rejected: \t449\n",
      "Iteration: \t36 / 100\n",
      "Confirmed: \t8\n",
      "Tentative: \t9\n",
      "Rejected: \t449\n",
      "Iteration: \t37 / 100\n",
      "Confirmed: \t10\n",
      "Tentative: \t7\n",
      "Rejected: \t449\n",
      "Iteration: \t38 / 100\n",
      "Confirmed: \t10\n",
      "Tentative: \t7\n",
      "Rejected: \t449\n",
      "Iteration: \t39 / 100\n",
      "Confirmed: \t10\n",
      "Tentative: \t7\n",
      "Rejected: \t449\n",
      "Iteration: \t40 / 100\n",
      "Confirmed: \t11\n",
      "Tentative: \t6\n",
      "Rejected: \t449\n",
      "Iteration: \t41 / 100\n",
      "Confirmed: \t11\n",
      "Tentative: \t6\n",
      "Rejected: \t449\n",
      "Iteration: \t42 / 100\n",
      "Confirmed: \t11\n",
      "Tentative: \t6\n",
      "Rejected: \t449\n",
      "Iteration: \t43 / 100\n",
      "Confirmed: \t11\n",
      "Tentative: \t6\n",
      "Rejected: \t449\n",
      "Iteration: \t44 / 100\n",
      "Confirmed: \t11\n",
      "Tentative: \t6\n",
      "Rejected: \t449\n",
      "Iteration: \t45 / 100\n",
      "Confirmed: \t11\n",
      "Tentative: \t6\n",
      "Rejected: \t449\n",
      "Iteration: \t46 / 100\n",
      "Confirmed: \t12\n",
      "Tentative: \t5\n",
      "Rejected: \t449\n",
      "Iteration: \t47 / 100\n",
      "Confirmed: \t12\n",
      "Tentative: \t5\n",
      "Rejected: \t449\n",
      "Iteration: \t48 / 100\n",
      "Confirmed: \t12\n",
      "Tentative: \t5\n",
      "Rejected: \t449\n",
      "Iteration: \t49 / 100\n",
      "Confirmed: \t12\n",
      "Tentative: \t5\n",
      "Rejected: \t449\n",
      "Iteration: \t50 / 100\n",
      "Confirmed: \t12\n",
      "Tentative: \t5\n",
      "Rejected: \t449\n",
      "Iteration: \t51 / 100\n",
      "Confirmed: \t12\n",
      "Tentative: \t5\n",
      "Rejected: \t449\n",
      "Iteration: \t52 / 100\n",
      "Confirmed: \t12\n",
      "Tentative: \t5\n",
      "Rejected: \t449\n",
      "Iteration: \t53 / 100\n",
      "Confirmed: \t12\n",
      "Tentative: \t5\n",
      "Rejected: \t449\n",
      "Iteration: \t54 / 100\n",
      "Confirmed: \t12\n",
      "Tentative: \t5\n",
      "Rejected: \t449\n",
      "Iteration: \t55 / 100\n",
      "Confirmed: \t12\n",
      "Tentative: \t5\n",
      "Rejected: \t449\n",
      "Iteration: \t56 / 100\n",
      "Confirmed: \t12\n",
      "Tentative: \t5\n",
      "Rejected: \t449\n",
      "Iteration: \t57 / 100\n",
      "Confirmed: \t12\n",
      "Tentative: \t5\n",
      "Rejected: \t449\n",
      "Iteration: \t58 / 100\n",
      "Confirmed: \t12\n",
      "Tentative: \t5\n",
      "Rejected: \t449\n",
      "Iteration: \t59 / 100\n",
      "Confirmed: \t12\n",
      "Tentative: \t5\n",
      "Rejected: \t449\n",
      "Iteration: \t60 / 100\n",
      "Confirmed: \t12\n",
      "Tentative: \t5\n",
      "Rejected: \t449\n",
      "Iteration: \t61 / 100\n",
      "Confirmed: \t12\n",
      "Tentative: \t5\n",
      "Rejected: \t449\n",
      "Iteration: \t62 / 100\n",
      "Confirmed: \t12\n",
      "Tentative: \t5\n",
      "Rejected: \t449\n",
      "Iteration: \t63 / 100\n",
      "Confirmed: \t12\n",
      "Tentative: \t5\n",
      "Rejected: \t449\n",
      "Iteration: \t64 / 100\n",
      "Confirmed: \t12\n",
      "Tentative: \t5\n",
      "Rejected: \t449\n",
      "Iteration: \t65 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t4\n",
      "Rejected: \t449\n",
      "Iteration: \t66 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t4\n",
      "Rejected: \t449\n",
      "Iteration: \t67 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t4\n",
      "Rejected: \t449\n",
      "Iteration: \t68 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t4\n",
      "Rejected: \t449\n",
      "Iteration: \t69 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t4\n",
      "Rejected: \t449\n",
      "Iteration: \t70 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t4\n",
      "Rejected: \t449\n",
      "Iteration: \t71 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t4\n",
      "Rejected: \t449\n",
      "Iteration: \t72 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t4\n",
      "Rejected: \t449\n",
      "Iteration: \t73 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t4\n",
      "Rejected: \t449\n",
      "Iteration: \t74 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t4\n",
      "Rejected: \t449\n",
      "Iteration: \t75 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t4\n",
      "Rejected: \t449\n",
      "Iteration: \t76 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t4\n",
      "Rejected: \t449\n",
      "Iteration: \t77 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t4\n",
      "Rejected: \t449\n",
      "Iteration: \t78 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t4\n",
      "Rejected: \t449\n",
      "Iteration: \t79 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t4\n",
      "Rejected: \t449\n",
      "Iteration: \t80 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t4\n",
      "Rejected: \t449\n",
      "Iteration: \t81 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t4\n",
      "Rejected: \t449\n",
      "Iteration: \t82 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t4\n",
      "Rejected: \t449\n",
      "Iteration: \t83 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t4\n",
      "Rejected: \t449\n",
      "Iteration: \t84 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t4\n",
      "Rejected: \t449\n",
      "Iteration: \t85 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t4\n",
      "Rejected: \t449\n",
      "Iteration: \t86 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t4\n",
      "Rejected: \t449\n",
      "Iteration: \t87 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t4\n",
      "Rejected: \t449\n",
      "Iteration: \t88 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t4\n",
      "Rejected: \t449\n",
      "Iteration: \t89 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t4\n",
      "Rejected: \t449\n",
      "Iteration: \t90 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t4\n",
      "Rejected: \t449\n",
      "Iteration: \t91 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t4\n",
      "Rejected: \t449\n",
      "Iteration: \t92 / 100\n",
      "Confirmed: \t13\n",
      "Tentative: \t4\n",
      "Rejected: \t449\n",
      "Iteration: \t93 / 100\n",
      "Confirmed: \t14\n",
      "Tentative: \t3\n",
      "Rejected: \t449\n",
      "Iteration: \t94 / 100\n",
      "Confirmed: \t14\n",
      "Tentative: \t3\n",
      "Rejected: \t449\n",
      "Iteration: \t95 / 100\n",
      "Confirmed: \t14\n",
      "Tentative: \t3\n",
      "Rejected: \t449\n",
      "Iteration: \t96 / 100\n",
      "Confirmed: \t14\n",
      "Tentative: \t3\n",
      "Rejected: \t449\n",
      "Iteration: \t97 / 100\n",
      "Confirmed: \t14\n",
      "Tentative: \t3\n",
      "Rejected: \t449\n",
      "Iteration: \t98 / 100\n",
      "Confirmed: \t14\n",
      "Tentative: \t3\n",
      "Rejected: \t449\n",
      "Iteration: \t99 / 100\n",
      "Confirmed: \t14\n",
      "Tentative: \t3\n",
      "Rejected: \t449\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t100 / 100\n",
      "Confirmed: \t14\n",
      "Tentative: \t3\n",
      "Rejected: \t449\n",
      "Feature: feature1                       Rank: 1,  Keep: True\n",
      "Feature: feature2                       Rank: 400,  Keep: False\n",
      "Feature: feature3                       Rank: 162,  Keep: False\n",
      "Feature: feature4                       Rank: 147,  Keep: False\n",
      "Feature: feature5                       Rank: 406,  Keep: False\n",
      "Feature: feature7                       Rank: 321,  Keep: False\n",
      "Feature: feature8                       Rank: 170,  Keep: False\n",
      "Feature: feature9                       Rank: 59,  Keep: False\n",
      "Feature: feature10                      Rank: 321,  Keep: False\n",
      "Feature: feature11                      Rank: 151,  Keep: False\n",
      "Feature: feature12                      Rank: 125,  Keep: False\n",
      "Feature: feature13                      Rank: 275,  Keep: False\n",
      "Feature: feature15                      Rank: 103,  Keep: False\n",
      "Feature: feature16                      Rank: 286,  Keep: False\n",
      "Feature: feature17                      Rank: 49,  Keep: False\n",
      "Feature: feature18                      Rank: 52,  Keep: False\n",
      "Feature: feature19                      Rank: 358,  Keep: False\n",
      "Feature: feature20                      Rank: 1,  Keep: True\n",
      "Feature: feature21                      Rank: 394,  Keep: False\n",
      "Feature: feature22                      Rank: 1,  Keep: True\n",
      "Feature: feature23                      Rank: 293,  Keep: False\n",
      "Feature: feature24                      Rank: 424,  Keep: False\n",
      "Feature: feature25                      Rank: 93,  Keep: False\n",
      "Feature: feature26                      Rank: 174,  Keep: False\n",
      "Feature: feature27                      Rank: 325,  Keep: False\n",
      "Feature: feature28                      Rank: 135,  Keep: False\n",
      "Feature: feature29                      Rank: 14,  Keep: False\n",
      "Feature: feature30                      Rank: 282,  Keep: False\n",
      "Feature: feature31                      Rank: 204,  Keep: False\n",
      "Feature: feature32                      Rank: 16,  Keep: False\n",
      "Feature: feature33                      Rank: 118,  Keep: False\n",
      "Feature: feature34                      Rank: 1,  Keep: True\n",
      "Feature: feature35                      Rank: 318,  Keep: False\n",
      "Feature: feature36                      Rank: 157,  Keep: False\n",
      "Feature: feature37                      Rank: 242,  Keep: False\n",
      "Feature: feature38                      Rank: 101,  Keep: False\n",
      "Feature: feature39                      Rank: 142,  Keep: False\n",
      "Feature: feature40                      Rank: 211,  Keep: False\n",
      "Feature: feature41                      Rank: 39,  Keep: False\n",
      "Feature: feature42                      Rank: 76,  Keep: False\n",
      "Feature: feature44                      Rank: 325,  Keep: False\n",
      "Feature: feature45                      Rank: 301,  Keep: False\n",
      "Feature: feature46                      Rank: 167,  Keep: False\n",
      "Feature: feature47                      Rank: 341,  Keep: False\n",
      "Feature: feature48                      Rank: 199,  Keep: False\n",
      "Feature: feature49                      Rank: 181,  Keep: False\n",
      "Feature: feature51                      Rank: 395,  Keep: False\n",
      "Feature: feature52                      Rank: 148,  Keep: False\n",
      "Feature: feature54                      Rank: 318,  Keep: False\n",
      "Feature: feature55                      Rank: 416,  Keep: False\n",
      "Feature: feature56                      Rank: 116,  Keep: False\n",
      "Feature: feature57                      Rank: 47,  Keep: False\n",
      "Feature: feature58                      Rank: 288,  Keep: False\n",
      "Feature: feature59                      Rank: 50,  Keep: False\n",
      "Feature: feature60                      Rank: 1,  Keep: True\n",
      "Feature: feature61                      Rank: 249,  Keep: False\n",
      "Feature: feature62                      Rank: 184,  Keep: False\n",
      "Feature: feature63                      Rank: 163,  Keep: False\n",
      "Feature: feature64                      Rank: 57,  Keep: False\n",
      "Feature: feature65                      Rank: 3,  Keep: False\n",
      "Feature: feature66                      Rank: 11,  Keep: False\n",
      "Feature: feature67                      Rank: 110,  Keep: False\n",
      "Feature: feature68                      Rank: 84,  Keep: False\n",
      "Feature: feature69                      Rank: 165,  Keep: False\n",
      "Feature: feature71                      Rank: 166,  Keep: False\n",
      "Feature: feature72                      Rank: 397,  Keep: False\n",
      "Feature: feature73                      Rank: 223,  Keep: False\n",
      "Feature: feature74                      Rank: 189,  Keep: False\n",
      "Feature: feature75                      Rank: 449,  Keep: False\n",
      "Feature: feature76                      Rank: 337,  Keep: False\n",
      "Feature: feature77                      Rank: 28,  Keep: False\n",
      "Feature: feature78                      Rank: 329,  Keep: False\n",
      "Feature: feature79                      Rank: 16,  Keep: False\n",
      "Feature: feature80                      Rank: 112,  Keep: False\n",
      "Feature: feature81                      Rank: 93,  Keep: False\n",
      "Feature: feature82                      Rank: 78,  Keep: False\n",
      "Feature: feature83                      Rank: 343,  Keep: False\n",
      "Feature: feature84                      Rank: 132,  Keep: False\n",
      "Feature: feature85                      Rank: 409,  Keep: False\n",
      "Feature: feature87                      Rank: 312,  Keep: False\n",
      "Feature: feature88                      Rank: 346,  Keep: False\n",
      "Feature: feature89                      Rank: 392,  Keep: False\n",
      "Feature: feature90                      Rank: 414,  Keep: False\n",
      "Feature: feature91                      Rank: 6,  Keep: False\n",
      "Feature: feature92                      Rank: 22,  Keep: False\n",
      "Feature: feature93                      Rank: 197,  Keep: False\n",
      "Feature: feature94                      Rank: 407,  Keep: False\n",
      "Feature: feature95                      Rank: 440,  Keep: False\n",
      "Feature: feature96                      Rank: 440,  Keep: False\n",
      "Feature: feature97                      Rank: 180,  Keep: False\n",
      "Feature: feature99                      Rank: 289,  Keep: False\n",
      "Feature: feature100                     Rank: 223,  Keep: False\n",
      "Feature: feature101                     Rank: 435,  Keep: False\n",
      "Feature: feature102                     Rank: 439,  Keep: False\n",
      "Feature: feature103                     Rank: 62,  Keep: False\n",
      "Feature: feature104                     Rank: 2,  Keep: False\n",
      "Feature: feature105                     Rank: 395,  Keep: False\n",
      "Feature: feature106                     Rank: 309,  Keep: False\n",
      "Feature: feature107                     Rank: 368,  Keep: False\n",
      "Feature: feature108                     Rank: 237,  Keep: False\n",
      "Feature: feature109                     Rank: 415,  Keep: False\n",
      "Feature: feature110                     Rank: 109,  Keep: False\n",
      "Feature: feature111                     Rank: 348,  Keep: False\n",
      "Feature: feature112                     Rank: 38,  Keep: False\n",
      "Feature: feature113                     Rank: 79,  Keep: False\n",
      "Feature: feature114                     Rank: 356,  Keep: False\n",
      "Feature: feature115                     Rank: 444,  Keep: False\n",
      "Feature: feature116                     Rank: 20,  Keep: False\n",
      "Feature: feature117                     Rank: 279,  Keep: False\n",
      "Feature: feature118                     Rank: 4,  Keep: False\n",
      "Feature: feature119                     Rank: 303,  Keep: False\n",
      "Feature: feature120                     Rank: 191,  Keep: False\n",
      "Feature: feature121                     Rank: 74,  Keep: False\n",
      "Feature: feature122                     Rank: 1,  Keep: True\n",
      "Feature: feature123                     Rank: 60,  Keep: False\n",
      "Feature: feature124                     Rank: 79,  Keep: False\n",
      "Feature: feature125                     Rank: 7,  Keep: False\n",
      "Feature: feature126                     Rank: 29,  Keep: False\n",
      "Feature: feature127                     Rank: 10,  Keep: False\n",
      "Feature: feature128                     Rank: 112,  Keep: False\n",
      "Feature: feature129                     Rank: 238,  Keep: False\n",
      "Feature: feature130                     Rank: 2,  Keep: False\n",
      "Feature: feature131                     Rank: 1,  Keep: True\n",
      "Feature: feature132                     Rank: 417,  Keep: False\n",
      "Feature: feature133                     Rank: 95,  Keep: False\n",
      "Feature: feature134                     Rank: 19,  Keep: False\n",
      "Feature: feature135                     Rank: 420,  Keep: False\n",
      "Feature: feature136                     Rank: 121,  Keep: False\n",
      "Feature: feature137                     Rank: 353,  Keep: False\n",
      "Feature: feature138                     Rank: 117,  Keep: False\n",
      "Feature: feature139                     Rank: 209,  Keep: False\n",
      "Feature: feature140                     Rank: 65,  Keep: False\n",
      "Feature: feature141                     Rank: 373,  Keep: False\n",
      "Feature: feature143                     Rank: 370,  Keep: False\n",
      "Feature: feature144                     Rank: 88,  Keep: False\n",
      "Feature: feature145                     Rank: 163,  Keep: False\n",
      "Feature: feature146                     Rank: 357,  Keep: False\n",
      "Feature: feature147                     Rank: 152,  Keep: False\n",
      "Feature: feature148                     Rank: 34,  Keep: False\n",
      "Feature: feature149                     Rank: 277,  Keep: False\n",
      "Feature: feature151                     Rank: 245,  Keep: False\n",
      "Feature: feature152                     Rank: 376,  Keep: False\n",
      "Feature: feature153                     Rank: 5,  Keep: False\n",
      "Feature: feature154                     Rank: 1,  Keep: True\n",
      "Feature: feature155                     Rank: 316,  Keep: False\n",
      "Feature: feature156                     Rank: 155,  Keep: False\n",
      "Feature: feature157                     Rank: 199,  Keep: False\n",
      "Feature: feature160                     Rank: 138,  Keep: False\n",
      "Feature: feature161                     Rank: 61,  Keep: False\n",
      "Feature: feature162                     Rank: 74,  Keep: False\n",
      "Feature: feature163                     Rank: 296,  Keep: False\n",
      "Feature: feature164                     Rank: 36,  Keep: False\n",
      "Feature: feature165                     Rank: 106,  Keep: False\n",
      "Feature: feature166                     Rank: 235,  Keep: False\n",
      "Feature: feature167                     Rank: 431,  Keep: False\n",
      "Feature: feature168                     Rank: 426,  Keep: False\n",
      "Feature: feature169                     Rank: 320,  Keep: False\n",
      "Feature: feature170                     Rank: 304,  Keep: False\n",
      "Feature: feature171                     Rank: 215,  Keep: False\n",
      "Feature: feature172                     Rank: 419,  Keep: False\n",
      "Feature: feature173                     Rank: 137,  Keep: False\n",
      "Feature: feature174                     Rank: 405,  Keep: False\n",
      "Feature: feature175                     Rank: 91,  Keep: False\n",
      "Feature: feature176                     Rank: 210,  Keep: False\n",
      "Feature: feature177                     Rank: 220,  Keep: False\n",
      "Feature: feature178                     Rank: 341,  Keep: False\n",
      "Feature: feature181                     Rank: 24,  Keep: False\n",
      "Feature: feature182                     Rank: 259,  Keep: False\n",
      "Feature: feature183                     Rank: 146,  Keep: False\n",
      "Feature: feature184                     Rank: 35,  Keep: False\n",
      "Feature: feature185                     Rank: 177,  Keep: False\n",
      "Feature: feature186                     Rank: 408,  Keep: False\n",
      "Feature: feature188                     Rank: 255,  Keep: False\n",
      "Feature: feature189                     Rank: 68,  Keep: False\n",
      "Feature: feature196                     Rank: 48,  Keep: False\n",
      "Feature: feature197                     Rank: 207,  Keep: False\n",
      "Feature: feature198                     Rank: 138,  Keep: False\n",
      "Feature: feature199                     Rank: 282,  Keep: False\n",
      "Feature: feature200                     Rank: 317,  Keep: False\n",
      "Feature: feature201                     Rank: 149,  Keep: False\n",
      "Feature: feature202                     Rank: 190,  Keep: False\n",
      "Feature: feature203                     Rank: 284,  Keep: False\n",
      "Feature: feature204                     Rank: 67,  Keep: False\n",
      "Feature: feature205                     Rank: 341,  Keep: False\n",
      "Feature: feature206                     Rank: 1,  Keep: True\n",
      "Feature: feature207                     Rank: 449,  Keep: False\n",
      "Feature: feature208                     Rank: 284,  Keep: False\n",
      "Feature: feature209                     Rank: 380,  Keep: False\n",
      "Feature: feature210                     Rank: 449,  Keep: False\n",
      "Feature: feature211                     Rank: 29,  Keep: False\n",
      "Feature: feature212                     Rank: 294,  Keep: False\n",
      "Feature: feature213                     Rank: 265,  Keep: False\n",
      "Feature: feature214                     Rank: 81,  Keep: False\n",
      "Feature: feature215                     Rank: 179,  Keep: False\n",
      "Feature: feature216                     Rank: 267,  Keep: False\n",
      "Feature: feature217                     Rank: 152,  Keep: False\n",
      "Feature: feature218                     Rank: 351,  Keep: False\n",
      "Feature: feature219                     Rank: 114,  Keep: False\n",
      "Feature: feature220                     Rank: 257,  Keep: False\n",
      "Feature: feature222                     Rank: 427,  Keep: False\n",
      "Feature: feature223                     Rank: 269,  Keep: False\n",
      "Feature: feature224                     Rank: 334,  Keep: False\n",
      "Feature: feature225                     Rank: 390,  Keep: False\n",
      "Feature: feature226                     Rank: 246,  Keep: False\n",
      "Feature: feature228                     Rank: 84,  Keep: False\n",
      "Feature: feature229                     Rank: 307,  Keep: False\n",
      "Feature: feature239                     Rank: 191,  Keep: False\n",
      "Feature: feature240                     Rank: 175,  Keep: False\n",
      "Feature: feature245                     Rank: 167,  Keep: False\n",
      "Feature: feature246                     Rank: 425,  Keep: False\n",
      "Feature: feature247                     Rank: 269,  Keep: False\n",
      "Feature: feature248                     Rank: 1,  Keep: True\n",
      "Feature: feature249                     Rank: 260,  Keep: False\n",
      "Feature: feature250                     Rank: 445,  Keep: False\n",
      "Feature: feature251                     Rank: 232,  Keep: False\n",
      "Feature: feature252                     Rank: 264,  Keep: False\n",
      "Feature: feature253                     Rank: 361,  Keep: False\n",
      "Feature: feature254                     Rank: 361,  Keep: False\n",
      "Feature: feature255                     Rank: 251,  Keep: False\n",
      "Feature: feature256                     Rank: 334,  Keep: False\n",
      "Feature: feature268                     Rank: 98,  Keep: False\n",
      "Feature: feature269                     Rank: 96,  Keep: False\n",
      "Feature: feature270                     Rank: 369,  Keep: False\n",
      "Feature: feature271                     Rank: 171,  Keep: False\n",
      "Feature: feature272                     Rank: 355,  Keep: False\n",
      "Feature: feature273                     Rank: 195,  Keep: False\n",
      "Feature: feature274                     Rank: 300,  Keep: False\n",
      "Feature: feature275                     Rank: 97,  Keep: False\n",
      "Feature: feature276                     Rank: 377,  Keep: False\n",
      "Feature: feature278                     Rank: 390,  Keep: False\n",
      "Feature: feature279                     Rank: 130,  Keep: False\n",
      "Feature: feature280                     Rank: 291,  Keep: False\n",
      "Feature: feature281                     Rank: 124,  Keep: False\n",
      "Feature: feature282                     Rank: 99,  Keep: False\n",
      "Feature: feature283                     Rank: 26,  Keep: False\n",
      "Feature: feature284                     Rank: 385,  Keep: False\n",
      "Feature: feature286                     Rank: 134,  Keep: False\n",
      "Feature: feature287                     Rank: 331,  Keep: False\n",
      "Feature: feature288                     Rank: 8,  Keep: False\n",
      "Feature: feature289                     Rank: 44,  Keep: False\n",
      "Feature: feature290                     Rank: 315,  Keep: False\n",
      "Feature: feature291                     Rank: 46,  Keep: False\n",
      "Feature: feature292                     Rank: 127,  Keep: False\n",
      "Feature: feature295                     Rank: 186,  Keep: False\n",
      "Feature: feature296                     Rank: 88,  Keep: False\n",
      "Feature: feature297                     Rank: 56,  Keep: False\n",
      "Feature: feature298                     Rank: 265,  Keep: False\n",
      "Feature: feature299                     Rank: 27,  Keep: False\n",
      "Feature: feature300                     Rank: 40,  Keep: False\n",
      "Feature: feature301                     Rank: 327,  Keep: False\n",
      "Feature: feature302                     Rank: 418,  Keep: False\n",
      "Feature: feature303                     Rank: 366,  Keep: False\n",
      "Feature: feature304                     Rank: 217,  Keep: False\n",
      "Feature: feature305                     Rank: 307,  Keep: False\n",
      "Feature: feature306                     Rank: 312,  Keep: False\n",
      "Feature: feature307                     Rank: 346,  Keep: False\n",
      "Feature: feature308                     Rank: 171,  Keep: False\n",
      "Feature: feature309                     Rank: 353,  Keep: False\n",
      "Feature: feature310                     Rank: 154,  Keep: False\n",
      "Feature: feature311                     Rank: 82,  Keep: False\n",
      "Feature: feature312                     Rank: 332,  Keep: False\n",
      "Feature: feature313                     Rank: 353,  Keep: False\n",
      "Feature: feature317                     Rank: 14,  Keep: False\n",
      "Feature: feature318                     Rank: 330,  Keep: False\n",
      "Feature: feature319                     Rank: 161,  Keep: False\n",
      "Feature: feature320                     Rank: 23,  Keep: False\n",
      "Feature: feature321                     Rank: 275,  Keep: False\n",
      "Feature: feature322                     Rank: 386,  Keep: False\n",
      "Feature: feature324                     Rank: 202,  Keep: False\n",
      "Feature: feature325                     Rank: 175,  Keep: False\n",
      "Feature: feature332                     Rank: 159,  Keep: False\n",
      "Feature: feature333                     Rank: 306,  Keep: False\n",
      "Feature: feature334                     Rank: 87,  Keep: False\n",
      "Feature: feature335                     Rank: 302,  Keep: False\n",
      "Feature: feature336                     Rank: 297,  Keep: False\n",
      "Feature: feature337                     Rank: 12,  Keep: False\n",
      "Feature: feature338                     Rank: 339,  Keep: False\n",
      "Feature: feature339                     Rank: 233,  Keep: False\n",
      "Feature: feature340                     Rank: 63,  Keep: False\n",
      "Feature: feature341                     Rank: 118,  Keep: False\n",
      "Feature: feature342                     Rank: 1,  Keep: True\n",
      "Feature: feature343                     Rank: 446,  Keep: False\n",
      "Feature: feature344                     Rank: 287,  Keep: False\n",
      "Feature: feature345                     Rank: 279,  Keep: False\n",
      "Feature: feature346                     Rank: 373,  Keep: False\n",
      "Feature: feature347                     Rank: 227,  Keep: False\n",
      "Feature: feature348                     Rank: 446,  Keep: False\n",
      "Feature: feature349                     Rank: 1,  Keep: True\n",
      "Feature: feature350                     Rank: 228,  Keep: False\n",
      "Feature: feature351                     Rank: 375,  Keep: False\n",
      "Feature: feature352                     Rank: 102,  Keep: False\n",
      "Feature: feature353                     Rank: 121,  Keep: False\n",
      "Feature: feature354                     Rank: 135,  Keep: False\n",
      "Feature: feature355                     Rank: 129,  Keep: False\n",
      "Feature: feature356                     Rank: 366,  Keep: False\n",
      "Feature: feature357                     Rank: 201,  Keep: False\n",
      "Feature: feature358                     Rank: 401,  Keep: False\n",
      "Feature: feature360                     Rank: 260,  Keep: False\n",
      "Feature: feature361                     Rank: 372,  Keep: False\n",
      "Feature: feature362                     Rank: 350,  Keep: False\n",
      "Feature: feature363                     Rank: 434,  Keep: False\n",
      "Feature: feature364                     Rank: 238,  Keep: False\n",
      "Feature: feature366                     Rank: 312,  Keep: False\n",
      "Feature: feature367                     Rank: 310,  Keep: False\n",
      "Feature: feature368                     Rank: 364,  Keep: False\n",
      "Feature: feature369                     Rank: 399,  Keep: False\n",
      "Feature: feature377                     Rank: 421,  Keep: False\n",
      "Feature: feature378                     Rank: 183,  Keep: False\n",
      "Feature: feature383                     Rank: 258,  Keep: False\n",
      "Feature: feature384                     Rank: 382,  Keep: False\n",
      "Feature: feature385                     Rank: 187,  Keep: False\n",
      "Feature: feature386                     Rank: 31,  Keep: False\n",
      "Feature: feature387                     Rank: 228,  Keep: False\n",
      "Feature: feature388                     Rank: 442,  Keep: False\n",
      "Feature: feature389                     Rank: 281,  Keep: False\n",
      "Feature: feature390                     Rank: 430,  Keep: False\n",
      "Feature: feature391                     Rank: 214,  Keep: False\n",
      "Feature: feature392                     Rank: 291,  Keep: False\n",
      "Feature: feature393                     Rank: 312,  Keep: False\n",
      "Feature: feature394                     Rank: 383,  Keep: False\n",
      "Feature: feature406                     Rank: 69,  Keep: False\n",
      "Feature: feature407                     Rank: 121,  Keep: False\n",
      "Feature: feature408                     Rank: 411,  Keep: False\n",
      "Feature: feature409                     Rank: 121,  Keep: False\n",
      "Feature: feature410                     Rank: 345,  Keep: False\n",
      "Feature: feature411                     Rank: 247,  Keep: False\n",
      "Feature: feature412                     Rank: 299,  Keep: False\n",
      "Feature: feature413                     Rank: 381,  Keep: False\n",
      "Feature: feature414                     Rank: 410,  Keep: False\n",
      "Feature: feature416                     Rank: 324,  Keep: False\n",
      "Feature: feature417                     Rank: 44,  Keep: False\n",
      "Feature: feature418                     Rank: 91,  Keep: False\n",
      "Feature: feature419                     Rank: 413,  Keep: False\n",
      "Feature: feature420                     Rank: 378,  Keep: False\n",
      "Feature: feature421                     Rank: 13,  Keep: False\n",
      "Feature: feature422                     Rank: 304,  Keep: False\n",
      "Feature: feature424                     Rank: 86,  Keep: False\n",
      "Feature: feature425                     Rank: 222,  Keep: False\n",
      "Feature: feature426                     Rank: 8,  Keep: False\n",
      "Feature: feature427                     Rank: 18,  Keep: False\n",
      "Feature: feature428                     Rank: 404,  Keep: False\n",
      "Feature: feature429                     Rank: 145,  Keep: False\n",
      "Feature: feature430                     Rank: 144,  Keep: False\n",
      "Feature: feature431                     Rank: 149,  Keep: False\n",
      "Feature: feature432                     Rank: 21,  Keep: False\n",
      "Feature: feature433                     Rank: 111,  Keep: False\n",
      "Feature: feature434                     Rank: 212,  Keep: False\n",
      "Feature: feature435                     Rank: 53,  Keep: False\n",
      "Feature: feature436                     Rank: 125,  Keep: False\n",
      "Feature: feature437                     Rank: 370,  Keep: False\n",
      "Feature: feature438                     Rank: 251,  Keep: False\n",
      "Feature: feature439                     Rank: 272,  Keep: False\n",
      "Feature: feature440                     Rank: 204,  Keep: False\n",
      "Feature: feature441                     Rank: 207,  Keep: False\n",
      "Feature: feature442                     Rank: 114,  Keep: False\n",
      "Feature: feature443                     Rank: 218,  Keep: False\n",
      "Feature: feature444                     Rank: 159,  Keep: False\n",
      "Feature: feature445                     Rank: 361,  Keep: False\n",
      "Feature: feature446                     Rank: 106,  Keep: False\n",
      "Feature: feature447                     Rank: 231,  Keep: False\n",
      "Feature: feature448                     Rank: 428,  Keep: False\n",
      "Feature: feature449                     Rank: 403,  Keep: False\n",
      "Feature: feature453                     Rank: 43,  Keep: False\n",
      "Feature: feature454                     Rank: 273,  Keep: False\n",
      "Feature: feature455                     Rank: 140,  Keep: False\n",
      "Feature: feature456                     Rank: 37,  Keep: False\n",
      "Feature: feature457                     Rank: 173,  Keep: False\n",
      "Feature: feature458                     Rank: 429,  Keep: False\n",
      "Feature: feature460                     Rank: 130,  Keep: False\n",
      "Feature: feature461                     Rank: 24,  Keep: False\n",
      "Feature: feature468                     Rank: 55,  Keep: False\n",
      "Feature: feature469                     Rank: 41,  Keep: False\n",
      "Feature: feature470                     Rank: 72,  Keep: False\n",
      "Feature: feature471                     Rank: 247,  Keep: False\n",
      "Feature: feature472                     Rank: 156,  Keep: False\n",
      "Feature: feature473                     Rank: 251,  Keep: False\n",
      "Feature: feature474                     Rank: 384,  Keep: False\n",
      "Feature: feature475                     Rank: 365,  Keep: False\n",
      "Feature: feature476                     Rank: 33,  Keep: False\n",
      "Feature: feature477                     Rank: 199,  Keep: False\n",
      "Feature: feature478                     Rank: 1,  Keep: True\n",
      "Feature: feature479                     Rank: 449,  Keep: False\n",
      "Feature: feature480                     Rank: 387,  Keep: False\n",
      "Feature: feature481                     Rank: 337,  Keep: False\n",
      "Feature: feature483                     Rank: 433,  Keep: False\n",
      "Feature: feature484                     Rank: 236,  Keep: False\n",
      "Feature: feature485                     Rank: 412,  Keep: False\n",
      "Feature: feature486                     Rank: 100,  Keep: False\n",
      "Feature: feature487                     Rank: 328,  Keep: False\n",
      "Feature: feature488                     Rank: 203,  Keep: False\n",
      "Feature: feature489                     Rank: 41,  Keep: False\n",
      "Feature: feature490                     Rank: 244,  Keep: False\n",
      "Feature: feature491                     Rank: 243,  Keep: False\n",
      "Feature: feature492                     Rank: 133,  Keep: False\n",
      "Feature: feature494                     Rank: 431,  Keep: False\n",
      "Feature: feature495                     Rank: 267,  Keep: False\n",
      "Feature: feature496                     Rank: 332,  Keep: False\n",
      "Feature: feature497                     Rank: 389,  Keep: False\n",
      "Feature: feature498                     Rank: 337,  Keep: False\n",
      "Feature: feature500                     Rank: 436,  Keep: False\n",
      "Feature: feature501                     Rank: 398,  Keep: False\n",
      "Feature: feature511                     Rank: 2,  Keep: False\n",
      "Feature: feature512                     Rank: 72,  Keep: False\n",
      "Feature: feature517                     Rank: 71,  Keep: False\n",
      "Feature: feature518                     Rank: 423,  Keep: False\n",
      "Feature: feature519                     Rank: 194,  Keep: False\n",
      "Feature: feature520                     Rank: 1,  Keep: True\n",
      "Feature: feature521                     Rank: 361,  Keep: False\n",
      "Feature: feature522                     Rank: 442,  Keep: False\n",
      "Feature: feature523                     Rank: 254,  Keep: False\n",
      "Feature: feature524                     Rank: 219,  Keep: False\n",
      "Feature: feature525                     Rank: 378,  Keep: False\n",
      "Feature: feature526                     Rank: 349,  Keep: False\n",
      "Feature: feature527                     Rank: 230,  Keep: False\n",
      "Feature: feature528                     Rank: 225,  Keep: False\n",
      "Feature: feature540                     Rank: 82,  Keep: False\n",
      "Feature: feature541                     Rank: 181,  Keep: False\n",
      "Feature: feature542                     Rank: 240,  Keep: False\n",
      "Feature: feature543                     Rank: 169,  Keep: False\n",
      "Feature: feature544                     Rank: 188,  Keep: False\n",
      "Feature: feature545                     Rank: 437,  Keep: False\n",
      "Feature: feature546                     Rank: 128,  Keep: False\n",
      "Feature: feature547                     Rank: 234,  Keep: False\n",
      "Feature: feature548                     Rank: 108,  Keep: False\n",
      "Feature: feature549                     Rank: 401,  Keep: False\n",
      "Feature: feature550                     Rank: 256,  Keep: False\n",
      "Feature: feature551                     Rank: 220,  Keep: False\n",
      "Feature: feature552                     Rank: 196,  Keep: False\n",
      "Feature: feature553                     Rank: 298,  Keep: False\n",
      "Feature: feature554                     Rank: 240,  Keep: False\n",
      "Feature: feature555                     Rank: 141,  Keep: False\n",
      "Feature: feature556                     Rank: 291,  Keep: False\n",
      "Feature: feature557                     Rank: 275,  Keep: False\n",
      "Feature: feature558                     Rank: 212,  Keep: False\n",
      "Feature: feature559                     Rank: 271,  Keep: False\n",
      "Feature: feature560                     Rank: 143,  Keep: False\n",
      "Feature: feature561                     Rank: 323,  Keep: False\n",
      "Feature: feature562                     Rank: 177,  Keep: False\n",
      "Feature: feature563                     Rank: 90,  Keep: False\n",
      "Feature: feature564                     Rank: 53,  Keep: False\n",
      "Feature: feature565                     Rank: 57,  Keep: False\n",
      "Feature: feature566                     Rank: 193,  Keep: False\n",
      "Feature: feature567                     Rank: 64,  Keep: False\n",
      "Feature: feature568                     Rank: 263,  Keep: False\n",
      "Feature: feature569                     Rank: 51,  Keep: False\n",
      "Feature: feature570                     Rank: 215,  Keep: False\n",
      "Feature: feature571                     Rank: 361,  Keep: False\n",
      "Feature: feature572                     Rank: 104,  Keep: False\n",
      "Feature: feature573                     Rank: 437,  Keep: False\n",
      "Feature: feature574                     Rank: 66,  Keep: False\n",
      "Feature: feature575                     Rank: 421,  Keep: False\n",
      "Feature: feature576                     Rank: 158,  Keep: False\n",
      "Feature: feature577                     Rank: 388,  Keep: False\n",
      "Feature: feature578                     Rank: 76,  Keep: False\n",
      "Feature: feature579                     Rank: 343,  Keep: False\n",
      "Feature: feature580                     Rank: 279,  Keep: False\n",
      "Feature: feature581                     Rank: 392,  Keep: False\n",
      "Feature: feature582                     Rank: 262,  Keep: False\n",
      "Feature: feature583                     Rank: 70,  Keep: False\n",
      "Feature: feature584                     Rank: 105,  Keep: False\n",
      "Feature: feature585                     Rank: 295,  Keep: False\n",
      "Feature: feature586                     Rank: 185,  Keep: False\n",
      "Feature: feature587                     Rank: 253,  Keep: False\n",
      "Feature: feature588                     Rank: 31,  Keep: False\n",
      "Feature: feature589                     Rank: 225,  Keep: False\n",
      "Feature: feature590                     Rank: 206,  Keep: False\n",
      "['feature1', 'feature20', 'feature22', 'feature34', 'feature60', 'feature122', 'feature131', 'feature154', 'feature206', 'feature248', 'feature342', 'feature349', 'feature478', 'feature520']\n"
     ]
    }
   ],
   "source": [
    "# apply Boruta and store selected features in a variable\n",
    "X_train , final_features = BorutaFeatureSelection(imputed_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature1',\n",
       " 'feature20',\n",
       " 'feature22',\n",
       " 'feature34',\n",
       " 'feature60',\n",
       " 'feature122',\n",
       " 'feature131',\n",
       " 'feature154',\n",
       " 'feature206',\n",
       " 'feature248',\n",
       " 'feature342',\n",
       " 'feature349',\n",
       " 'feature478',\n",
       " 'feature520']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#green_area = retransformed_train.columns[feat_selector.support_].to_list()\n",
    "#blue_area = retransformed_train.columns[feat_selector.ranking_].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature20</th>\n",
       "      <th>feature22</th>\n",
       "      <th>feature34</th>\n",
       "      <th>feature60</th>\n",
       "      <th>feature122</th>\n",
       "      <th>feature131</th>\n",
       "      <th>feature154</th>\n",
       "      <th>feature206</th>\n",
       "      <th>feature248</th>\n",
       "      <th>feature342</th>\n",
       "      <th>feature349</th>\n",
       "      <th>feature478</th>\n",
       "      <th>feature520</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3079.77</td>\n",
       "      <td>12.3686</td>\n",
       "      <td>-4750.75</td>\n",
       "      <td>8.6915</td>\n",
       "      <td>0.6991</td>\n",
       "      <td>15.76</td>\n",
       "      <td>0.8203</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>9.22</td>\n",
       "      <td>0.015200</td>\n",
       "      <td>2.6547</td>\n",
       "      <td>0.02370</td>\n",
       "      <td>6.0266</td>\n",
       "      <td>3.292400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3001.36</td>\n",
       "      <td>12.4959</td>\n",
       "      <td>-5410.75</td>\n",
       "      <td>8.3006</td>\n",
       "      <td>-1.4173</td>\n",
       "      <td>15.76</td>\n",
       "      <td>0.8291</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>7.31</td>\n",
       "      <td>0.054460</td>\n",
       "      <td>2.0989</td>\n",
       "      <td>0.02720</td>\n",
       "      <td>4.8218</td>\n",
       "      <td>11.584860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3042.78</td>\n",
       "      <td>12.5553</td>\n",
       "      <td>-6456.75</td>\n",
       "      <td>8.7418</td>\n",
       "      <td>10.2355</td>\n",
       "      <td>15.65</td>\n",
       "      <td>0.5438</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>8.80</td>\n",
       "      <td>0.034500</td>\n",
       "      <td>2.5012</td>\n",
       "      <td>0.01630</td>\n",
       "      <td>6.1589</td>\n",
       "      <td>7.439200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3018.64</td>\n",
       "      <td>12.4469</td>\n",
       "      <td>-5775.00</td>\n",
       "      <td>8.6829</td>\n",
       "      <td>9.8518</td>\n",
       "      <td>15.73</td>\n",
       "      <td>0.8048</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>7.77</td>\n",
       "      <td>0.260816</td>\n",
       "      <td>2.4329</td>\n",
       "      <td>0.03000</td>\n",
       "      <td>5.0612</td>\n",
       "      <td>61.263283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3020.29</td>\n",
       "      <td>12.4618</td>\n",
       "      <td>-6900.50</td>\n",
       "      <td>8.5891</td>\n",
       "      <td>1.0336</td>\n",
       "      <td>15.90</td>\n",
       "      <td>0.7611</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>11.06</td>\n",
       "      <td>0.034680</td>\n",
       "      <td>3.2653</td>\n",
       "      <td>0.02430</td>\n",
       "      <td>7.4828</td>\n",
       "      <td>7.412560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>3057.31</td>\n",
       "      <td>12.4824</td>\n",
       "      <td>-6451.75</td>\n",
       "      <td>9.1156</td>\n",
       "      <td>3.2964</td>\n",
       "      <td>15.96</td>\n",
       "      <td>0.7527</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>6.83</td>\n",
       "      <td>0.032820</td>\n",
       "      <td>1.8996</td>\n",
       "      <td>0.02640</td>\n",
       "      <td>4.6390</td>\n",
       "      <td>7.059080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>3009.71</td>\n",
       "      <td>12.5280</td>\n",
       "      <td>-5470.25</td>\n",
       "      <td>8.4278</td>\n",
       "      <td>3.0345</td>\n",
       "      <td>15.79</td>\n",
       "      <td>0.7217</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>9.58</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>2.7085</td>\n",
       "      <td>0.01830</td>\n",
       "      <td>6.6740</td>\n",
       "      <td>4.373000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>3034.34</td>\n",
       "      <td>12.6278</td>\n",
       "      <td>-5972.75</td>\n",
       "      <td>8.5155</td>\n",
       "      <td>11.4855</td>\n",
       "      <td>15.94</td>\n",
       "      <td>0.8380</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>9.74</td>\n",
       "      <td>0.138300</td>\n",
       "      <td>3.1945</td>\n",
       "      <td>0.02680</td>\n",
       "      <td>6.3958</td>\n",
       "      <td>29.569300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>3025.21</td>\n",
       "      <td>12.5373</td>\n",
       "      <td>-5735.25</td>\n",
       "      <td>9.0650</td>\n",
       "      <td>-2.3109</td>\n",
       "      <td>15.69</td>\n",
       "      <td>0.5768</td>\n",
       "      <td>0.0137</td>\n",
       "      <td>6.56</td>\n",
       "      <td>0.024160</td>\n",
       "      <td>1.9995</td>\n",
       "      <td>0.02106</td>\n",
       "      <td>4.3482</td>\n",
       "      <td>5.177020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>2997.07</td>\n",
       "      <td>12.5724</td>\n",
       "      <td>-5527.00</td>\n",
       "      <td>8.6309</td>\n",
       "      <td>0.3764</td>\n",
       "      <td>15.76</td>\n",
       "      <td>0.8434</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>4.32</td>\n",
       "      <td>0.122666</td>\n",
       "      <td>1.4101</td>\n",
       "      <td>0.02030</td>\n",
       "      <td>2.9581</td>\n",
       "      <td>28.442373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1253 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature1  feature20  feature22  feature34  feature60  feature122  \\\n",
       "0      3079.77    12.3686   -4750.75     8.6915     0.6991       15.76   \n",
       "1      3001.36    12.4959   -5410.75     8.3006    -1.4173       15.76   \n",
       "2      3042.78    12.5553   -6456.75     8.7418    10.2355       15.65   \n",
       "3      3018.64    12.4469   -5775.00     8.6829     9.8518       15.73   \n",
       "4      3020.29    12.4618   -6900.50     8.5891     1.0336       15.90   \n",
       "...        ...        ...        ...        ...        ...         ...   \n",
       "1248   3057.31    12.4824   -6451.75     9.1156     3.2964       15.96   \n",
       "1249   3009.71    12.5280   -5470.25     8.4278     3.0345       15.79   \n",
       "1250   3034.34    12.6278   -5972.75     8.5155    11.4855       15.94   \n",
       "1251   3025.21    12.5373   -5735.25     9.0650    -2.3109       15.69   \n",
       "1252   2997.07    12.5724   -5527.00     8.6309     0.3764       15.76   \n",
       "\n",
       "      feature131  feature154  feature206  feature248  feature342  feature349  \\\n",
       "0         0.8203      0.0127        9.22    0.015200      2.6547     0.02370   \n",
       "1         0.8291      0.0065        7.31    0.054460      2.0989     0.02720   \n",
       "2         0.5438      0.0148        8.80    0.034500      2.5012     0.01630   \n",
       "3         0.8048      0.0159        7.77    0.260816      2.4329     0.03000   \n",
       "4         0.7611      0.0078       11.06    0.034680      3.2653     0.02430   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1248      0.7527      0.0091        6.83    0.032820      1.8996     0.02640   \n",
       "1249      0.7217      0.0055        9.58    0.020300      2.7085     0.01830   \n",
       "1250      0.8380      0.0177        9.74    0.138300      3.1945     0.02680   \n",
       "1251      0.5768      0.0137        6.56    0.024160      1.9995     0.02106   \n",
       "1252      0.8434      0.0065        4.32    0.122666      1.4101     0.02030   \n",
       "\n",
       "      feature478  feature520  \n",
       "0         6.0266    3.292400  \n",
       "1         4.8218   11.584860  \n",
       "2         6.1589    7.439200  \n",
       "3         5.0612   61.263283  \n",
       "4         7.4828    7.412560  \n",
       "...          ...         ...  \n",
       "1248      4.6390    7.059080  \n",
       "1249      6.6740    4.373000  \n",
       "1250      6.3958   29.569300  \n",
       "1251      4.3482    5.177020  \n",
       "1252      2.9581   28.442373  \n",
       "\n",
       "[1253 rows x 14 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#important features after boruta\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x396 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train.corr()\n",
    "sns.heatmap(X_train.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boruta Shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BorutaShap import BorutaShap#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No Importance_measure was specified select one of (shap, gini)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15180/4033043991.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mFeature_Selector3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBorutaShap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimportance_measure\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gain'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassification\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mFeature_Selector3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimputed_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\BorutaShap.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, n_trials, random_state, sample, train_or_test, normalize, verbose, stratify)\u001b[0m\n\u001b[0;32m    361\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCheck_if_chose_train_or_test_and_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_feature_import\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mShadow_feature_import\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_importance_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m                 \u001b[0mhits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalculate_hits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\BorutaShap.py\u001b[0m in \u001b[0;36mfeature_importance\u001b[1;34m(self, normalize)\u001b[0m\n\u001b[0;32m    628\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 630\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'No Importance_measure was specified select one of (shap, gini)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    631\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No Importance_measure was specified select one of (shap, gini)"
     ]
    }
   ],
   "source": [
    "Feature_Selector3 = BorutaShap(importance_measure='gain', classification=True)\n",
    "\n",
    "Feature_Selector3.fit(X=imputed_train, y=y_train, n_trials=10, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RFE Feature selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import RFECV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFE function\n",
    "\n",
    "def RFEFeatureSelection (X, y) :\n",
    "    feature_names = np.array(X.columns)\n",
    "\n",
    "    # define random forest classifier\n",
    "    model = RandomForestClassifier(n_jobs=-1, class_weight='balanced_subsample', max_depth=5, random_state=100)\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # define RFE feature selection method\n",
    "    rfe = RFE(estimator = model,n_features_to_select = 15)\n",
    "\n",
    "    # find all relevant features\n",
    "    rfe.fit(X,y)\n",
    "\n",
    "    # check selected features\n",
    "    rfe.support_\n",
    "\n",
    "    # check ranking of features\n",
    "    rfe.ranking_\n",
    "\n",
    "    # zip feature names, ranks, and decisions \n",
    "    feature_ranks = list(zip(feature_names, \n",
    "                             rfe.ranking_, \n",
    "                             rfe.support_))\n",
    "\n",
    "    # print the results\n",
    "    for feat in feature_ranks:\n",
    "        print('Feature: {:<30} Rank: {},  Keep: {}'.format(feat[0], feat[1], feat[2]))\n",
    "        \n",
    "    final_features_rfe = list()\n",
    "    indexes = np.where(rfe.ranking_ <= 1)\n",
    "    for x in np.nditer(indexes):\n",
    "        final_features_rfe.append(feature_names[x])\n",
    "    print(final_features_rfe)\n",
    "    \n",
    " # call transform() on X to filter it down to selected features\n",
    "    return pd.DataFrame(X.filter(final_features_rfe)) , final_features_rfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: feature1                       Rank: 1,  Keep: True\n",
      "Feature: feature2                       Rank: 400,  Keep: False\n",
      "Feature: feature3                       Rank: 381,  Keep: False\n",
      "Feature: feature4                       Rank: 121,  Keep: False\n",
      "Feature: feature5                       Rank: 314,  Keep: False\n",
      "Feature: feature7                       Rank: 199,  Keep: False\n",
      "Feature: feature8                       Rank: 175,  Keep: False\n",
      "Feature: feature9                       Rank: 27,  Keep: False\n",
      "Feature: feature10                      Rank: 308,  Keep: False\n",
      "Feature: feature11                      Rank: 217,  Keep: False\n",
      "Feature: feature12                      Rank: 194,  Keep: False\n",
      "Feature: feature13                      Rank: 92,  Keep: False\n",
      "Feature: feature15                      Rank: 54,  Keep: False\n",
      "Feature: feature16                      Rank: 214,  Keep: False\n",
      "Feature: feature17                      Rank: 17,  Keep: False\n",
      "Feature: feature18                      Rank: 62,  Keep: False\n",
      "Feature: feature19                      Rank: 241,  Keep: False\n",
      "Feature: feature20                      Rank: 1,  Keep: True\n",
      "Feature: feature21                      Rank: 355,  Keep: False\n",
      "Feature: feature22                      Rank: 2,  Keep: False\n",
      "Feature: feature23                      Rank: 184,  Keep: False\n",
      "Feature: feature24                      Rank: 444,  Keep: False\n",
      "Feature: feature25                      Rank: 48,  Keep: False\n",
      "Feature: feature26                      Rank: 91,  Keep: False\n",
      "Feature: feature27                      Rank: 176,  Keep: False\n",
      "Feature: feature28                      Rank: 406,  Keep: False\n",
      "Feature: feature29                      Rank: 19,  Keep: False\n",
      "Feature: feature30                      Rank: 415,  Keep: False\n",
      "Feature: feature31                      Rank: 138,  Keep: False\n",
      "Feature: feature32                      Rank: 1,  Keep: True\n",
      "Feature: feature33                      Rank: 149,  Keep: False\n",
      "Feature: feature34                      Rank: 1,  Keep: True\n",
      "Feature: feature35                      Rank: 124,  Keep: False\n",
      "Feature: feature36                      Rank: 122,  Keep: False\n",
      "Feature: feature37                      Rank: 427,  Keep: False\n",
      "Feature: feature38                      Rank: 75,  Keep: False\n",
      "Feature: feature39                      Rank: 228,  Keep: False\n",
      "Feature: feature40                      Rank: 280,  Keep: False\n",
      "Feature: feature41                      Rank: 111,  Keep: False\n",
      "Feature: feature42                      Rank: 67,  Keep: False\n",
      "Feature: feature44                      Rank: 397,  Keep: False\n",
      "Feature: feature45                      Rank: 270,  Keep: False\n",
      "Feature: feature46                      Rank: 89,  Keep: False\n",
      "Feature: feature47                      Rank: 93,  Keep: False\n",
      "Feature: feature48                      Rank: 84,  Keep: False\n",
      "Feature: feature49                      Rank: 99,  Keep: False\n",
      "Feature: feature51                      Rank: 119,  Keep: False\n",
      "Feature: feature52                      Rank: 160,  Keep: False\n",
      "Feature: feature54                      Rank: 306,  Keep: False\n",
      "Feature: feature55                      Rank: 213,  Keep: False\n",
      "Feature: feature56                      Rank: 97,  Keep: False\n",
      "Feature: feature57                      Rank: 126,  Keep: False\n",
      "Feature: feature58                      Rank: 375,  Keep: False\n",
      "Feature: feature59                      Rank: 189,  Keep: False\n",
      "Feature: feature60                      Rank: 1,  Keep: True\n",
      "Feature: feature61                      Rank: 331,  Keep: False\n",
      "Feature: feature62                      Rank: 417,  Keep: False\n",
      "Feature: feature63                      Rank: 256,  Keep: False\n",
      "Feature: feature64                      Rank: 278,  Keep: False\n",
      "Feature: feature65                      Rank: 9,  Keep: False\n",
      "Feature: feature66                      Rank: 32,  Keep: False\n",
      "Feature: feature67                      Rank: 246,  Keep: False\n",
      "Feature: feature68                      Rank: 25,  Keep: False\n",
      "Feature: feature69                      Rank: 120,  Keep: False\n",
      "Feature: feature71                      Rank: 291,  Keep: False\n",
      "Feature: feature72                      Rank: 182,  Keep: False\n",
      "Feature: feature73                      Rank: 242,  Keep: False\n",
      "Feature: feature74                      Rank: 425,  Keep: False\n",
      "Feature: feature75                      Rank: 429,  Keep: False\n",
      "Feature: feature76                      Rank: 383,  Keep: False\n",
      "Feature: feature77                      Rank: 70,  Keep: False\n",
      "Feature: feature78                      Rank: 166,  Keep: False\n",
      "Feature: feature79                      Rank: 42,  Keep: False\n",
      "Feature: feature80                      Rank: 46,  Keep: False\n",
      "Feature: feature81                      Rank: 180,  Keep: False\n",
      "Feature: feature82                      Rank: 66,  Keep: False\n",
      "Feature: feature83                      Rank: 112,  Keep: False\n",
      "Feature: feature84                      Rank: 178,  Keep: False\n",
      "Feature: feature85                      Rank: 423,  Keep: False\n",
      "Feature: feature87                      Rank: 401,  Keep: False\n",
      "Feature: feature88                      Rank: 267,  Keep: False\n",
      "Feature: feature89                      Rank: 350,  Keep: False\n",
      "Feature: feature90                      Rank: 285,  Keep: False\n",
      "Feature: feature91                      Rank: 30,  Keep: False\n",
      "Feature: feature92                      Rank: 14,  Keep: False\n",
      "Feature: feature93                      Rank: 123,  Keep: False\n",
      "Feature: feature94                      Rank: 360,  Keep: False\n",
      "Feature: feature95                      Rank: 424,  Keep: False\n",
      "Feature: feature96                      Rank: 443,  Keep: False\n",
      "Feature: feature97                      Rank: 156,  Keep: False\n",
      "Feature: feature99                      Rank: 186,  Keep: False\n",
      "Feature: feature100                     Rank: 61,  Keep: False\n",
      "Feature: feature101                     Rank: 382,  Keep: False\n",
      "Feature: feature102                     Rank: 348,  Keep: False\n",
      "Feature: feature103                     Rank: 11,  Keep: False\n",
      "Feature: feature104                     Rank: 40,  Keep: False\n",
      "Feature: feature105                     Rank: 283,  Keep: False\n",
      "Feature: feature106                     Rank: 247,  Keep: False\n",
      "Feature: feature107                     Rank: 277,  Keep: False\n",
      "Feature: feature108                     Rank: 216,  Keep: False\n",
      "Feature: feature109                     Rank: 223,  Keep: False\n",
      "Feature: feature110                     Rank: 195,  Keep: False\n",
      "Feature: feature111                     Rank: 307,  Keep: False\n",
      "Feature: feature112                     Rank: 6,  Keep: False\n",
      "Feature: feature113                     Rank: 203,  Keep: False\n",
      "Feature: feature114                     Rank: 319,  Keep: False\n",
      "Feature: feature115                     Rank: 450,  Keep: False\n",
      "Feature: feature116                     Rank: 4,  Keep: False\n",
      "Feature: feature117                     Rank: 258,  Keep: False\n",
      "Feature: feature118                     Rank: 5,  Keep: False\n",
      "Feature: feature119                     Rank: 374,  Keep: False\n",
      "Feature: feature120                     Rank: 136,  Keep: False\n",
      "Feature: feature121                     Rank: 79,  Keep: False\n",
      "Feature: feature122                     Rank: 1,  Keep: True\n",
      "Feature: feature123                     Rank: 81,  Keep: False\n",
      "Feature: feature124                     Rank: 55,  Keep: False\n",
      "Feature: feature125                     Rank: 209,  Keep: False\n",
      "Feature: feature126                     Rank: 144,  Keep: False\n",
      "Feature: feature127                     Rank: 218,  Keep: False\n",
      "Feature: feature128                     Rank: 261,  Keep: False\n",
      "Feature: feature129                     Rank: 439,  Keep: False\n",
      "Feature: feature130                     Rank: 1,  Keep: True\n",
      "Feature: feature131                     Rank: 1,  Keep: True\n",
      "Feature: feature132                     Rank: 259,  Keep: False\n",
      "Feature: feature133                     Rank: 104,  Keep: False\n",
      "Feature: feature134                     Rank: 12,  Keep: False\n",
      "Feature: feature135                     Rank: 243,  Keep: False\n",
      "Feature: feature136                     Rank: 110,  Keep: False\n",
      "Feature: feature137                     Rank: 361,  Keep: False\n",
      "Feature: feature138                     Rank: 131,  Keep: False\n",
      "Feature: feature139                     Rank: 326,  Keep: False\n",
      "Feature: feature140                     Rank: 52,  Keep: False\n",
      "Feature: feature141                     Rank: 237,  Keep: False\n",
      "Feature: feature143                     Rank: 412,  Keep: False\n",
      "Feature: feature144                     Rank: 312,  Keep: False\n",
      "Feature: feature145                     Rank: 248,  Keep: False\n",
      "Feature: feature146                     Rank: 155,  Keep: False\n",
      "Feature: feature147                     Rank: 159,  Keep: False\n",
      "Feature: feature148                     Rank: 170,  Keep: False\n",
      "Feature: feature149                     Rank: 139,  Keep: False\n",
      "Feature: feature151                     Rank: 125,  Keep: False\n",
      "Feature: feature152                     Rank: 420,  Keep: False\n",
      "Feature: feature153                     Rank: 21,  Keep: False\n",
      "Feature: feature154                     Rank: 7,  Keep: False\n",
      "Feature: feature155                     Rank: 222,  Keep: False\n",
      "Feature: feature156                     Rank: 379,  Keep: False\n",
      "Feature: feature157                     Rank: 298,  Keep: False\n",
      "Feature: feature160                     Rank: 102,  Keep: False\n",
      "Feature: feature161                     Rank: 50,  Keep: False\n",
      "Feature: feature162                     Rank: 172,  Keep: False\n",
      "Feature: feature163                     Rank: 260,  Keep: False\n",
      "Feature: feature164                     Rank: 146,  Keep: False\n",
      "Feature: feature165                     Rank: 430,  Keep: False\n",
      "Feature: feature166                     Rank: 101,  Keep: False\n",
      "Feature: feature167                     Rank: 290,  Keep: False\n",
      "Feature: feature168                     Rank: 335,  Keep: False\n",
      "Feature: feature169                     Rank: 416,  Keep: False\n",
      "Feature: feature170                     Rank: 181,  Keep: False\n",
      "Feature: feature171                     Rank: 309,  Keep: False\n",
      "Feature: feature172                     Rank: 322,  Keep: False\n",
      "Feature: feature173                     Rank: 368,  Keep: False\n",
      "Feature: feature174                     Rank: 244,  Keep: False\n",
      "Feature: feature175                     Rank: 265,  Keep: False\n",
      "Feature: feature176                     Rank: 287,  Keep: False\n",
      "Feature: feature177                     Rank: 232,  Keep: False\n",
      "Feature: feature178                     Rank: 193,  Keep: False\n",
      "Feature: feature181                     Rank: 385,  Keep: False\n",
      "Feature: feature182                     Rank: 152,  Keep: False\n",
      "Feature: feature183                     Rank: 80,  Keep: False\n",
      "Feature: feature184                     Rank: 143,  Keep: False\n",
      "Feature: feature185                     Rank: 145,  Keep: False\n",
      "Feature: feature186                     Rank: 226,  Keep: False\n",
      "Feature: feature188                     Rank: 103,  Keep: False\n",
      "Feature: feature189                     Rank: 28,  Keep: False\n",
      "Feature: feature196                     Rank: 106,  Keep: False\n",
      "Feature: feature197                     Rank: 204,  Keep: False\n",
      "Feature: feature198                     Rank: 68,  Keep: False\n",
      "Feature: feature199                     Rank: 115,  Keep: False\n",
      "Feature: feature200                     Rank: 347,  Keep: False\n",
      "Feature: feature201                     Rank: 135,  Keep: False\n",
      "Feature: feature202                     Rank: 37,  Keep: False\n",
      "Feature: feature203                     Rank: 238,  Keep: False\n",
      "Feature: feature204                     Rank: 179,  Keep: False\n",
      "Feature: feature205                     Rank: 163,  Keep: False\n",
      "Feature: feature206                     Rank: 1,  Keep: True\n",
      "Feature: feature207                     Rank: 389,  Keep: False\n",
      "Feature: feature208                     Rank: 221,  Keep: False\n",
      "Feature: feature209                     Rank: 211,  Keep: False\n",
      "Feature: feature210                     Rank: 447,  Keep: False\n",
      "Feature: feature211                     Rank: 137,  Keep: False\n",
      "Feature: feature212                     Rank: 305,  Keep: False\n",
      "Feature: feature213                     Rank: 202,  Keep: False\n",
      "Feature: feature214                     Rank: 85,  Keep: False\n",
      "Feature: feature215                     Rank: 107,  Keep: False\n",
      "Feature: feature216                     Rank: 250,  Keep: False\n",
      "Feature: feature217                     Rank: 108,  Keep: False\n",
      "Feature: feature218                     Rank: 282,  Keep: False\n",
      "Feature: feature219                     Rank: 200,  Keep: False\n",
      "Feature: feature220                     Rank: 225,  Keep: False\n",
      "Feature: feature222                     Rank: 205,  Keep: False\n",
      "Feature: feature223                     Rank: 409,  Keep: False\n",
      "Feature: feature224                     Rank: 154,  Keep: False\n",
      "Feature: feature225                     Rank: 410,  Keep: False\n",
      "Feature: feature226                     Rank: 365,  Keep: False\n",
      "Feature: feature228                     Rank: 34,  Keep: False\n",
      "Feature: feature229                     Rank: 252,  Keep: False\n",
      "Feature: feature239                     Rank: 275,  Keep: False\n",
      "Feature: feature240                     Rank: 117,  Keep: False\n",
      "Feature: feature245                     Rank: 88,  Keep: False\n",
      "Feature: feature246                     Rank: 384,  Keep: False\n",
      "Feature: feature247                     Rank: 297,  Keep: False\n",
      "Feature: feature248                     Rank: 1,  Keep: True\n",
      "Feature: feature249                     Rank: 386,  Keep: False\n",
      "Feature: feature250                     Rank: 452,  Keep: False\n",
      "Feature: feature251                     Rank: 151,  Keep: False\n",
      "Feature: feature252                     Rank: 340,  Keep: False\n",
      "Feature: feature253                     Rank: 236,  Keep: False\n",
      "Feature: feature254                     Rank: 185,  Keep: False\n",
      "Feature: feature255                     Rank: 272,  Keep: False\n",
      "Feature: feature256                     Rank: 402,  Keep: False\n",
      "Feature: feature268                     Rank: 35,  Keep: False\n",
      "Feature: feature269                     Rank: 349,  Keep: False\n",
      "Feature: feature270                     Rank: 413,  Keep: False\n",
      "Feature: feature271                     Rank: 165,  Keep: False\n",
      "Feature: feature272                     Rank: 329,  Keep: False\n",
      "Feature: feature273                     Rank: 83,  Keep: False\n",
      "Feature: feature274                     Rank: 234,  Keep: False\n",
      "Feature: feature275                     Rank: 392,  Keep: False\n",
      "Feature: feature276                     Rank: 449,  Keep: False\n",
      "Feature: feature278                     Rank: 426,  Keep: False\n",
      "Feature: feature279                     Rank: 391,  Keep: False\n",
      "Feature: feature280                     Rank: 69,  Keep: False\n",
      "Feature: feature281                     Rank: 431,  Keep: False\n",
      "Feature: feature282                     Rank: 268,  Keep: False\n",
      "Feature: feature283                     Rank: 13,  Keep: False\n",
      "Feature: feature284                     Rank: 369,  Keep: False\n",
      "Feature: feature286                     Rank: 315,  Keep: False\n",
      "Feature: feature287                     Rank: 370,  Keep: False\n",
      "Feature: feature288                     Rank: 33,  Keep: False\n",
      "Feature: feature289                     Rank: 134,  Keep: False\n",
      "Feature: feature290                     Rank: 407,  Keep: False\n",
      "Feature: feature291                     Rank: 72,  Keep: False\n",
      "Feature: feature292                     Rank: 95,  Keep: False\n",
      "Feature: feature295                     Rank: 142,  Keep: False\n",
      "Feature: feature296                     Rank: 45,  Keep: False\n",
      "Feature: feature297                     Rank: 47,  Keep: False\n",
      "Feature: feature298                     Rank: 208,  Keep: False\n",
      "Feature: feature299                     Rank: 39,  Keep: False\n",
      "Feature: feature300                     Rank: 24,  Keep: False\n",
      "Feature: feature301                     Rank: 74,  Keep: False\n",
      "Feature: feature302                     Rank: 188,  Keep: False\n",
      "Feature: feature303                     Rank: 140,  Keep: False\n",
      "Feature: feature304                     Rank: 279,  Keep: False\n",
      "Feature: feature305                     Rank: 421,  Keep: False\n",
      "Feature: feature306                     Rank: 437,  Keep: False\n",
      "Feature: feature307                     Rank: 276,  Keep: False\n",
      "Feature: feature308                     Rank: 284,  Keep: False\n",
      "Feature: feature309                     Rank: 358,  Keep: False\n",
      "Feature: feature310                     Rank: 168,  Keep: False\n",
      "Feature: feature311                     Rank: 206,  Keep: False\n",
      "Feature: feature312                     Rank: 414,  Keep: False\n",
      "Feature: feature313                     Rank: 219,  Keep: False\n",
      "Feature: feature317                     Rank: 23,  Keep: False\n",
      "Feature: feature318                     Rank: 301,  Keep: False\n",
      "Feature: feature319                     Rank: 157,  Keep: False\n",
      "Feature: feature320                     Rank: 15,  Keep: False\n",
      "Feature: feature321                     Rank: 352,  Keep: False\n",
      "Feature: feature322                     Rank: 373,  Keep: False\n",
      "Feature: feature324                     Rank: 128,  Keep: False\n",
      "Feature: feature325                     Rank: 71,  Keep: False\n",
      "Feature: feature332                     Rank: 173,  Keep: False\n",
      "Feature: feature333                     Rank: 288,  Keep: False\n",
      "Feature: feature334                     Rank: 292,  Keep: False\n",
      "Feature: feature335                     Rank: 254,  Keep: False\n",
      "Feature: feature336                     Rank: 220,  Keep: False\n",
      "Feature: feature337                     Rank: 16,  Keep: False\n",
      "Feature: feature338                     Rank: 330,  Keep: False\n",
      "Feature: feature339                     Rank: 233,  Keep: False\n",
      "Feature: feature340                     Rank: 158,  Keep: False\n",
      "Feature: feature341                     Rank: 187,  Keep: False\n",
      "Feature: feature342                     Rank: 1,  Keep: True\n",
      "Feature: feature343                     Rank: 435,  Keep: False\n",
      "Feature: feature344                     Rank: 376,  Keep: False\n",
      "Feature: feature345                     Rank: 76,  Keep: False\n",
      "Feature: feature346                     Rank: 334,  Keep: False\n",
      "Feature: feature347                     Rank: 132,  Keep: False\n",
      "Feature: feature348                     Rank: 448,  Keep: False\n",
      "Feature: feature349                     Rank: 3,  Keep: False\n",
      "Feature: feature350                     Rank: 167,  Keep: False\n",
      "Feature: feature351                     Rank: 324,  Keep: False\n",
      "Feature: feature352                     Rank: 327,  Keep: False\n",
      "Feature: feature353                     Rank: 210,  Keep: False\n",
      "Feature: feature354                     Rank: 422,  Keep: False\n",
      "Feature: feature355                     Rank: 86,  Keep: False\n",
      "Feature: feature356                     Rank: 388,  Keep: False\n",
      "Feature: feature357                     Rank: 114,  Keep: False\n",
      "Feature: feature358                     Rank: 311,  Keep: False\n",
      "Feature: feature360                     Rank: 304,  Keep: False\n",
      "Feature: feature361                     Rank: 320,  Keep: False\n",
      "Feature: feature362                     Rank: 357,  Keep: False\n",
      "Feature: feature363                     Rank: 286,  Keep: False\n",
      "Feature: feature364                     Rank: 161,  Keep: False\n",
      "Feature: feature366                     Rank: 336,  Keep: False\n",
      "Feature: feature367                     Rank: 299,  Keep: False\n",
      "Feature: feature368                     Rank: 337,  Keep: False\n",
      "Feature: feature369                     Rank: 399,  Keep: False\n",
      "Feature: feature377                     Rank: 235,  Keep: False\n",
      "Feature: feature378                     Rank: 227,  Keep: False\n",
      "Feature: feature383                     Rank: 313,  Keep: False\n",
      "Feature: feature384                     Rank: 310,  Keep: False\n",
      "Feature: feature385                     Rank: 148,  Keep: False\n",
      "Feature: feature386                     Rank: 64,  Keep: False\n",
      "Feature: feature387                     Rank: 364,  Keep: False\n",
      "Feature: feature388                     Rank: 432,  Keep: False\n",
      "Feature: feature389                     Rank: 398,  Keep: False\n",
      "Feature: feature390                     Rank: 328,  Keep: False\n",
      "Feature: feature391                     Rank: 57,  Keep: False\n",
      "Feature: feature392                     Rank: 87,  Keep: False\n",
      "Feature: feature393                     Rank: 212,  Keep: False\n",
      "Feature: feature394                     Rank: 390,  Keep: False\n",
      "Feature: feature406                     Rank: 190,  Keep: False\n",
      "Feature: feature407                     Rank: 113,  Keep: False\n",
      "Feature: feature408                     Rank: 339,  Keep: False\n",
      "Feature: feature409                     Rank: 316,  Keep: False\n",
      "Feature: feature410                     Rank: 90,  Keep: False\n",
      "Feature: feature411                     Rank: 56,  Keep: False\n",
      "Feature: feature412                     Rank: 338,  Keep: False\n",
      "Feature: feature413                     Rank: 177,  Keep: False\n",
      "Feature: feature414                     Rank: 245,  Keep: False\n",
      "Feature: feature416                     Rank: 436,  Keep: False\n",
      "Feature: feature417                     Rank: 22,  Keep: False\n",
      "Feature: feature418                     Rank: 44,  Keep: False\n",
      "Feature: feature419                     Rank: 393,  Keep: False\n",
      "Feature: feature420                     Rank: 404,  Keep: False\n",
      "Feature: feature421                     Rank: 20,  Keep: False\n",
      "Feature: feature422                     Rank: 377,  Keep: False\n",
      "Feature: feature424                     Rank: 43,  Keep: False\n",
      "Feature: feature425                     Rank: 303,  Keep: False\n",
      "Feature: feature426                     Rank: 18,  Keep: False\n",
      "Feature: feature427                     Rank: 1,  Keep: True\n",
      "Feature: feature428                     Rank: 201,  Keep: False\n",
      "Feature: feature429                     Rank: 198,  Keep: False\n",
      "Feature: feature430                     Rank: 418,  Keep: False\n",
      "Feature: feature431                     Rank: 133,  Keep: False\n",
      "Feature: feature432                     Rank: 8,  Keep: False\n",
      "Feature: feature433                     Rank: 215,  Keep: False\n",
      "Feature: feature434                     Rank: 129,  Keep: False\n",
      "Feature: feature435                     Rank: 41,  Keep: False\n",
      "Feature: feature436                     Rank: 264,  Keep: False\n",
      "Feature: feature437                     Rank: 446,  Keep: False\n",
      "Feature: feature438                     Rank: 333,  Keep: False\n",
      "Feature: feature439                     Rank: 372,  Keep: False\n",
      "Feature: feature440                     Rank: 82,  Keep: False\n",
      "Feature: feature441                     Rank: 229,  Keep: False\n",
      "Feature: feature442                     Rank: 293,  Keep: False\n",
      "Feature: feature443                     Rank: 318,  Keep: False\n",
      "Feature: feature444                     Rank: 346,  Keep: False\n",
      "Feature: feature445                     Rank: 359,  Keep: False\n",
      "Feature: feature446                     Rank: 239,  Keep: False\n",
      "Feature: feature447                     Rank: 294,  Keep: False\n",
      "Feature: feature448                     Rank: 434,  Keep: False\n",
      "Feature: feature449                     Rank: 344,  Keep: False\n",
      "Feature: feature453                     Rank: 29,  Keep: False\n",
      "Feature: feature454                     Rank: 255,  Keep: False\n",
      "Feature: feature455                     Rank: 271,  Keep: False\n",
      "Feature: feature456                     Rank: 58,  Keep: False\n",
      "Feature: feature457                     Rank: 191,  Keep: False\n",
      "Feature: feature458                     Rank: 405,  Keep: False\n",
      "Feature: feature460                     Rank: 98,  Keep: False\n",
      "Feature: feature461                     Rank: 1,  Keep: True\n",
      "Feature: feature468                     Rank: 31,  Keep: False\n",
      "Feature: feature469                     Rank: 96,  Keep: False\n",
      "Feature: feature470                     Rank: 36,  Keep: False\n",
      "Feature: feature471                     Rank: 428,  Keep: False\n",
      "Feature: feature472                     Rank: 105,  Keep: False\n",
      "Feature: feature473                     Rank: 230,  Keep: False\n",
      "Feature: feature474                     Rank: 262,  Keep: False\n",
      "Feature: feature475                     Rank: 164,  Keep: False\n",
      "Feature: feature476                     Rank: 38,  Keep: False\n",
      "Feature: feature477                     Rank: 408,  Keep: False\n",
      "Feature: feature478                     Rank: 1,  Keep: True\n",
      "Feature: feature479                     Rank: 441,  Keep: False\n",
      "Feature: feature480                     Rank: 127,  Keep: False\n",
      "Feature: feature481                     Rank: 116,  Keep: False\n",
      "Feature: feature483                     Rank: 354,  Keep: False\n",
      "Feature: feature484                     Rank: 300,  Keep: False\n",
      "Feature: feature485                     Rank: 403,  Keep: False\n",
      "Feature: feature486                     Rank: 321,  Keep: False\n",
      "Feature: feature487                     Rank: 411,  Keep: False\n",
      "Feature: feature488                     Rank: 53,  Keep: False\n",
      "Feature: feature489                     Rank: 51,  Keep: False\n",
      "Feature: feature490                     Rank: 183,  Keep: False\n",
      "Feature: feature491                     Rank: 207,  Keep: False\n",
      "Feature: feature492                     Rank: 362,  Keep: False\n",
      "Feature: feature494                     Rank: 394,  Keep: False\n",
      "Feature: feature495                     Rank: 445,  Keep: False\n",
      "Feature: feature496                     Rank: 263,  Keep: False\n",
      "Feature: feature497                     Rank: 274,  Keep: False\n",
      "Feature: feature498                     Rank: 302,  Keep: False\n",
      "Feature: feature500                     Rank: 451,  Keep: False\n",
      "Feature: feature501                     Rank: 231,  Keep: False\n",
      "Feature: feature511                     Rank: 10,  Keep: False\n",
      "Feature: feature512                     Rank: 59,  Keep: False\n",
      "Feature: feature517                     Rank: 26,  Keep: False\n",
      "Feature: feature518                     Rank: 356,  Keep: False\n",
      "Feature: feature519                     Rank: 440,  Keep: False\n",
      "Feature: feature520                     Rank: 1,  Keep: True\n",
      "Feature: feature521                     Rank: 141,  Keep: False\n",
      "Feature: feature522                     Rank: 433,  Keep: False\n",
      "Feature: feature523                     Rank: 325,  Keep: False\n",
      "Feature: feature524                     Rank: 442,  Keep: False\n",
      "Feature: feature525                     Rank: 295,  Keep: False\n",
      "Feature: feature526                     Rank: 249,  Keep: False\n",
      "Feature: feature527                     Rank: 197,  Keep: False\n",
      "Feature: feature528                     Rank: 351,  Keep: False\n",
      "Feature: feature540                     Rank: 150,  Keep: False\n",
      "Feature: feature541                     Rank: 345,  Keep: False\n",
      "Feature: feature542                     Rank: 289,  Keep: False\n",
      "Feature: feature543                     Rank: 317,  Keep: False\n",
      "Feature: feature544                     Rank: 281,  Keep: False\n",
      "Feature: feature545                     Rank: 342,  Keep: False\n",
      "Feature: feature546                     Rank: 371,  Keep: False\n",
      "Feature: feature547                     Rank: 353,  Keep: False\n",
      "Feature: feature548                     Rank: 396,  Keep: False\n",
      "Feature: feature549                     Rank: 387,  Keep: False\n",
      "Feature: feature550                     Rank: 240,  Keep: False\n",
      "Feature: feature551                     Rank: 366,  Keep: False\n",
      "Feature: feature552                     Rank: 196,  Keep: False\n",
      "Feature: feature553                     Rank: 367,  Keep: False\n",
      "Feature: feature554                     Rank: 257,  Keep: False\n",
      "Feature: feature555                     Rank: 341,  Keep: False\n",
      "Feature: feature556                     Rank: 171,  Keep: False\n",
      "Feature: feature557                     Rank: 363,  Keep: False\n",
      "Feature: feature558                     Rank: 60,  Keep: False\n",
      "Feature: feature559                     Rank: 253,  Keep: False\n",
      "Feature: feature560                     Rank: 130,  Keep: False\n",
      "Feature: feature561                     Rank: 100,  Keep: False\n",
      "Feature: feature562                     Rank: 224,  Keep: False\n",
      "Feature: feature563                     Rank: 273,  Keep: False\n",
      "Feature: feature564                     Rank: 65,  Keep: False\n",
      "Feature: feature565                     Rank: 174,  Keep: False\n",
      "Feature: feature566                     Rank: 109,  Keep: False\n",
      "Feature: feature567                     Rank: 251,  Keep: False\n",
      "Feature: feature568                     Rank: 73,  Keep: False\n",
      "Feature: feature569                     Rank: 49,  Keep: False\n",
      "Feature: feature570                     Rank: 343,  Keep: False\n",
      "Feature: feature571                     Rank: 378,  Keep: False\n",
      "Feature: feature572                     Rank: 77,  Keep: False\n",
      "Feature: feature573                     Rank: 192,  Keep: False\n",
      "Feature: feature574                     Rank: 94,  Keep: False\n",
      "Feature: feature575                     Rank: 147,  Keep: False\n",
      "Feature: feature576                     Rank: 153,  Keep: False\n",
      "Feature: feature577                     Rank: 332,  Keep: False\n",
      "Feature: feature578                     Rank: 78,  Keep: False\n",
      "Feature: feature579                     Rank: 296,  Keep: False\n",
      "Feature: feature580                     Rank: 380,  Keep: False\n",
      "Feature: feature581                     Rank: 395,  Keep: False\n",
      "Feature: feature582                     Rank: 169,  Keep: False\n",
      "Feature: feature583                     Rank: 118,  Keep: False\n",
      "Feature: feature584                     Rank: 162,  Keep: False\n",
      "Feature: feature585                     Rank: 266,  Keep: False\n",
      "Feature: feature586                     Rank: 269,  Keep: False\n",
      "Feature: feature587                     Rank: 323,  Keep: False\n",
      "Feature: feature588                     Rank: 63,  Keep: False\n",
      "Feature: feature589                     Rank: 419,  Keep: False\n",
      "Feature: feature590                     Rank: 438,  Keep: False\n",
      "['feature1', 'feature20', 'feature32', 'feature34', 'feature60', 'feature122', 'feature130', 'feature131', 'feature206', 'feature248', 'feature342', 'feature427', 'feature461', 'feature478', 'feature520']\n"
     ]
    }
   ],
   "source": [
    "# apply RFE and store selected features in a variable\n",
    "X_train_rfe, final_features_rfe = RFEFeatureSelection(imputed_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature20</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature34</th>\n",
       "      <th>feature60</th>\n",
       "      <th>feature122</th>\n",
       "      <th>feature130</th>\n",
       "      <th>feature131</th>\n",
       "      <th>feature206</th>\n",
       "      <th>feature248</th>\n",
       "      <th>feature342</th>\n",
       "      <th>feature427</th>\n",
       "      <th>feature461</th>\n",
       "      <th>feature478</th>\n",
       "      <th>feature520</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3079.77</td>\n",
       "      <td>12.3686</td>\n",
       "      <td>3.3618</td>\n",
       "      <td>8.6915</td>\n",
       "      <td>0.6991</td>\n",
       "      <td>15.76</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8203</td>\n",
       "      <td>9.22</td>\n",
       "      <td>0.015200</td>\n",
       "      <td>2.6547</td>\n",
       "      <td>1.3155</td>\n",
       "      <td>14.7554</td>\n",
       "      <td>6.0266</td>\n",
       "      <td>3.292400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3001.36</td>\n",
       "      <td>12.4959</td>\n",
       "      <td>3.3500</td>\n",
       "      <td>8.3006</td>\n",
       "      <td>-1.4173</td>\n",
       "      <td>15.76</td>\n",
       "      <td>0.2838</td>\n",
       "      <td>0.8291</td>\n",
       "      <td>7.31</td>\n",
       "      <td>0.054460</td>\n",
       "      <td>2.0989</td>\n",
       "      <td>0.6593</td>\n",
       "      <td>12.1570</td>\n",
       "      <td>4.8218</td>\n",
       "      <td>11.584860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3042.78</td>\n",
       "      <td>12.5553</td>\n",
       "      <td>4.6781</td>\n",
       "      <td>8.7418</td>\n",
       "      <td>10.2355</td>\n",
       "      <td>15.65</td>\n",
       "      <td>-0.2838</td>\n",
       "      <td>0.5438</td>\n",
       "      <td>8.80</td>\n",
       "      <td>0.034500</td>\n",
       "      <td>2.5012</td>\n",
       "      <td>1.5403</td>\n",
       "      <td>21.1169</td>\n",
       "      <td>6.1589</td>\n",
       "      <td>7.439200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3018.64</td>\n",
       "      <td>12.4469</td>\n",
       "      <td>3.4767</td>\n",
       "      <td>8.6829</td>\n",
       "      <td>9.8518</td>\n",
       "      <td>15.73</td>\n",
       "      <td>0.0473</td>\n",
       "      <td>0.8048</td>\n",
       "      <td>7.77</td>\n",
       "      <td>0.260816</td>\n",
       "      <td>2.4329</td>\n",
       "      <td>1.6422</td>\n",
       "      <td>41.7748</td>\n",
       "      <td>5.0612</td>\n",
       "      <td>61.263283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3020.29</td>\n",
       "      <td>12.4618</td>\n",
       "      <td>4.6303</td>\n",
       "      <td>8.5891</td>\n",
       "      <td>1.0336</td>\n",
       "      <td>15.90</td>\n",
       "      <td>0.4258</td>\n",
       "      <td>0.7611</td>\n",
       "      <td>11.06</td>\n",
       "      <td>0.034680</td>\n",
       "      <td>3.2653</td>\n",
       "      <td>0.8006</td>\n",
       "      <td>23.1457</td>\n",
       "      <td>7.4828</td>\n",
       "      <td>7.412560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>3057.31</td>\n",
       "      <td>12.4824</td>\n",
       "      <td>4.5974</td>\n",
       "      <td>9.1156</td>\n",
       "      <td>3.2964</td>\n",
       "      <td>15.96</td>\n",
       "      <td>-0.9461</td>\n",
       "      <td>0.7527</td>\n",
       "      <td>6.83</td>\n",
       "      <td>0.032820</td>\n",
       "      <td>1.8996</td>\n",
       "      <td>0.9383</td>\n",
       "      <td>18.4257</td>\n",
       "      <td>4.6390</td>\n",
       "      <td>7.059080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>3009.71</td>\n",
       "      <td>12.5280</td>\n",
       "      <td>3.3153</td>\n",
       "      <td>8.4278</td>\n",
       "      <td>3.0345</td>\n",
       "      <td>15.79</td>\n",
       "      <td>-0.4258</td>\n",
       "      <td>0.7217</td>\n",
       "      <td>9.58</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>2.7085</td>\n",
       "      <td>0.5571</td>\n",
       "      <td>31.6124</td>\n",
       "      <td>6.6740</td>\n",
       "      <td>4.373000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>3034.34</td>\n",
       "      <td>12.6278</td>\n",
       "      <td>3.3313</td>\n",
       "      <td>8.5155</td>\n",
       "      <td>11.4855</td>\n",
       "      <td>15.94</td>\n",
       "      <td>0.5677</td>\n",
       "      <td>0.8380</td>\n",
       "      <td>9.74</td>\n",
       "      <td>0.138300</td>\n",
       "      <td>3.1945</td>\n",
       "      <td>1.8298</td>\n",
       "      <td>60.3473</td>\n",
       "      <td>6.3958</td>\n",
       "      <td>29.569300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>3025.21</td>\n",
       "      <td>12.5373</td>\n",
       "      <td>3.3359</td>\n",
       "      <td>9.0650</td>\n",
       "      <td>-2.3109</td>\n",
       "      <td>15.69</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5768</td>\n",
       "      <td>6.56</td>\n",
       "      <td>0.024160</td>\n",
       "      <td>1.9995</td>\n",
       "      <td>1.4074</td>\n",
       "      <td>16.9711</td>\n",
       "      <td>4.3482</td>\n",
       "      <td>5.177020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>2997.07</td>\n",
       "      <td>12.5724</td>\n",
       "      <td>3.4936</td>\n",
       "      <td>8.6309</td>\n",
       "      <td>0.3764</td>\n",
       "      <td>15.76</td>\n",
       "      <td>0.1419</td>\n",
       "      <td>0.8434</td>\n",
       "      <td>4.32</td>\n",
       "      <td>0.122666</td>\n",
       "      <td>1.4101</td>\n",
       "      <td>0.6665</td>\n",
       "      <td>32.0551</td>\n",
       "      <td>2.9581</td>\n",
       "      <td>28.442373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1253 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature1  feature20  feature32  feature34  feature60  feature122  \\\n",
       "0      3079.77    12.3686     3.3618     8.6915     0.6991       15.76   \n",
       "1      3001.36    12.4959     3.3500     8.3006    -1.4173       15.76   \n",
       "2      3042.78    12.5553     4.6781     8.7418    10.2355       15.65   \n",
       "3      3018.64    12.4469     3.4767     8.6829     9.8518       15.73   \n",
       "4      3020.29    12.4618     4.6303     8.5891     1.0336       15.90   \n",
       "...        ...        ...        ...        ...        ...         ...   \n",
       "1248   3057.31    12.4824     4.5974     9.1156     3.2964       15.96   \n",
       "1249   3009.71    12.5280     3.3153     8.4278     3.0345       15.79   \n",
       "1250   3034.34    12.6278     3.3313     8.5155    11.4855       15.94   \n",
       "1251   3025.21    12.5373     3.3359     9.0650    -2.3109       15.69   \n",
       "1252   2997.07    12.5724     3.4936     8.6309     0.3764       15.76   \n",
       "\n",
       "      feature130  feature131  feature206  feature248  feature342  feature427  \\\n",
       "0         0.0000      0.8203        9.22    0.015200      2.6547      1.3155   \n",
       "1         0.2838      0.8291        7.31    0.054460      2.0989      0.6593   \n",
       "2        -0.2838      0.5438        8.80    0.034500      2.5012      1.5403   \n",
       "3         0.0473      0.8048        7.77    0.260816      2.4329      1.6422   \n",
       "4         0.4258      0.7611       11.06    0.034680      3.2653      0.8006   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1248     -0.9461      0.7527        6.83    0.032820      1.8996      0.9383   \n",
       "1249     -0.4258      0.7217        9.58    0.020300      2.7085      0.5571   \n",
       "1250      0.5677      0.8380        9.74    0.138300      3.1945      1.8298   \n",
       "1251      0.0000      0.5768        6.56    0.024160      1.9995      1.4074   \n",
       "1252      0.1419      0.8434        4.32    0.122666      1.4101      0.6665   \n",
       "\n",
       "      feature461  feature478  feature520  \n",
       "0        14.7554      6.0266    3.292400  \n",
       "1        12.1570      4.8218   11.584860  \n",
       "2        21.1169      6.1589    7.439200  \n",
       "3        41.7748      5.0612   61.263283  \n",
       "4        23.1457      7.4828    7.412560  \n",
       "...          ...         ...         ...  \n",
       "1248     18.4257      4.6390    7.059080  \n",
       "1249     31.6124      6.6740    4.373000  \n",
       "1250     60.3473      6.3958   29.569300  \n",
       "1251     16.9711      4.3482    5.177020  \n",
       "1252     32.0551      2.9581   28.442373  \n",
       "\n",
       "[1253 rows x 15 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_rfe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x396 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_rfe.corr()\n",
    "sns.heatmap(X_train_rfe.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFECV function\n",
    "\n",
    "def RFECVFeatureSelection (X, y) :\n",
    "    feature_names = np.array(X.columns)\n",
    "\n",
    "    # define random forest classifier\n",
    "    model = RandomForestClassifier(n_jobs=-1, class_weight='balanced_subsample', max_depth=5, random_state=100)\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # define RFE feature selection method\n",
    "    rfeCV = RFECV(estimator = model,min_features_to_select = 10)\n",
    "\n",
    "    # find all relevant features\n",
    "    rfeCV.fit(X,y)\n",
    "\n",
    "    # check selected features\n",
    "    rfeCV.support_\n",
    "\n",
    "    # check ranking of features\n",
    "    rfeCV.ranking_\n",
    "\n",
    "    # zip feature names, ranks, and decisions \n",
    "    feature_ranks = list(zip(feature_names, \n",
    "                             rfeCV.ranking_, \n",
    "                             rfeCV.support_))\n",
    "\n",
    "    # print the results\n",
    "    for feat in feature_ranks:\n",
    "        print('Feature: {:<30} Rank: {},  Keep: {}'.format(feat[0], feat[1], feat[2]))\n",
    "        \n",
    "    final_features_rfeCV = list()\n",
    "    indexes = np.where(rfeCV.ranking_ <= 1)\n",
    "    for x in np.nditer(indexes):\n",
    "        final_features_rfeCV.append(feature_names[x])\n",
    "    print(final_features_rfeCV)\n",
    "    \n",
    " # call transform() on X to filter it down to selected features\n",
    "    return pd.DataFrame(X.filter(final_features_rfeCV)) , final_features_rfeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: feature1                       Rank: 1,  Keep: True\n",
      "Feature: feature2                       Rank: 81,  Keep: False\n",
      "Feature: feature3                       Rank: 62,  Keep: False\n",
      "Feature: feature4                       Rank: 1,  Keep: True\n",
      "Feature: feature5                       Rank: 1,  Keep: True\n",
      "Feature: feature7                       Rank: 1,  Keep: True\n",
      "Feature: feature8                       Rank: 1,  Keep: True\n",
      "Feature: feature9                       Rank: 1,  Keep: True\n",
      "Feature: feature10                      Rank: 1,  Keep: True\n",
      "Feature: feature11                      Rank: 1,  Keep: True\n",
      "Feature: feature12                      Rank: 1,  Keep: True\n",
      "Feature: feature13                      Rank: 1,  Keep: True\n",
      "Feature: feature15                      Rank: 1,  Keep: True\n",
      "Feature: feature16                      Rank: 1,  Keep: True\n",
      "Feature: feature17                      Rank: 1,  Keep: True\n",
      "Feature: feature18                      Rank: 1,  Keep: True\n",
      "Feature: feature19                      Rank: 1,  Keep: True\n",
      "Feature: feature20                      Rank: 1,  Keep: True\n",
      "Feature: feature21                      Rank: 36,  Keep: False\n",
      "Feature: feature22                      Rank: 1,  Keep: True\n",
      "Feature: feature23                      Rank: 1,  Keep: True\n",
      "Feature: feature24                      Rank: 125,  Keep: False\n",
      "Feature: feature25                      Rank: 1,  Keep: True\n",
      "Feature: feature26                      Rank: 1,  Keep: True\n",
      "Feature: feature27                      Rank: 1,  Keep: True\n",
      "Feature: feature28                      Rank: 87,  Keep: False\n",
      "Feature: feature29                      Rank: 1,  Keep: True\n",
      "Feature: feature30                      Rank: 96,  Keep: False\n",
      "Feature: feature31                      Rank: 1,  Keep: True\n",
      "Feature: feature32                      Rank: 1,  Keep: True\n",
      "Feature: feature33                      Rank: 1,  Keep: True\n",
      "Feature: feature34                      Rank: 1,  Keep: True\n",
      "Feature: feature35                      Rank: 1,  Keep: True\n",
      "Feature: feature36                      Rank: 1,  Keep: True\n",
      "Feature: feature37                      Rank: 108,  Keep: False\n",
      "Feature: feature38                      Rank: 1,  Keep: True\n",
      "Feature: feature39                      Rank: 1,  Keep: True\n",
      "Feature: feature40                      Rank: 1,  Keep: True\n",
      "Feature: feature41                      Rank: 1,  Keep: True\n",
      "Feature: feature42                      Rank: 1,  Keep: True\n",
      "Feature: feature44                      Rank: 78,  Keep: False\n",
      "Feature: feature45                      Rank: 1,  Keep: True\n",
      "Feature: feature46                      Rank: 1,  Keep: True\n",
      "Feature: feature47                      Rank: 1,  Keep: True\n",
      "Feature: feature48                      Rank: 1,  Keep: True\n",
      "Feature: feature49                      Rank: 1,  Keep: True\n",
      "Feature: feature51                      Rank: 1,  Keep: True\n",
      "Feature: feature52                      Rank: 1,  Keep: True\n",
      "Feature: feature54                      Rank: 1,  Keep: True\n",
      "Feature: feature55                      Rank: 1,  Keep: True\n",
      "Feature: feature56                      Rank: 1,  Keep: True\n",
      "Feature: feature57                      Rank: 1,  Keep: True\n",
      "Feature: feature58                      Rank: 56,  Keep: False\n",
      "Feature: feature59                      Rank: 1,  Keep: True\n",
      "Feature: feature60                      Rank: 1,  Keep: True\n",
      "Feature: feature61                      Rank: 12,  Keep: False\n",
      "Feature: feature62                      Rank: 98,  Keep: False\n",
      "Feature: feature63                      Rank: 1,  Keep: True\n",
      "Feature: feature64                      Rank: 1,  Keep: True\n",
      "Feature: feature65                      Rank: 1,  Keep: True\n",
      "Feature: feature66                      Rank: 1,  Keep: True\n",
      "Feature: feature67                      Rank: 1,  Keep: True\n",
      "Feature: feature68                      Rank: 1,  Keep: True\n",
      "Feature: feature69                      Rank: 1,  Keep: True\n",
      "Feature: feature71                      Rank: 1,  Keep: True\n",
      "Feature: feature72                      Rank: 1,  Keep: True\n",
      "Feature: feature73                      Rank: 1,  Keep: True\n",
      "Feature: feature74                      Rank: 106,  Keep: False\n",
      "Feature: feature75                      Rank: 110,  Keep: False\n",
      "Feature: feature76                      Rank: 64,  Keep: False\n",
      "Feature: feature77                      Rank: 1,  Keep: True\n",
      "Feature: feature78                      Rank: 1,  Keep: True\n",
      "Feature: feature79                      Rank: 1,  Keep: True\n",
      "Feature: feature80                      Rank: 1,  Keep: True\n",
      "Feature: feature81                      Rank: 1,  Keep: True\n",
      "Feature: feature82                      Rank: 1,  Keep: True\n",
      "Feature: feature83                      Rank: 1,  Keep: True\n",
      "Feature: feature84                      Rank: 1,  Keep: True\n",
      "Feature: feature85                      Rank: 104,  Keep: False\n",
      "Feature: feature87                      Rank: 82,  Keep: False\n",
      "Feature: feature88                      Rank: 1,  Keep: True\n",
      "Feature: feature89                      Rank: 31,  Keep: False\n",
      "Feature: feature90                      Rank: 1,  Keep: True\n",
      "Feature: feature91                      Rank: 1,  Keep: True\n",
      "Feature: feature92                      Rank: 1,  Keep: True\n",
      "Feature: feature93                      Rank: 1,  Keep: True\n",
      "Feature: feature94                      Rank: 41,  Keep: False\n",
      "Feature: feature95                      Rank: 105,  Keep: False\n",
      "Feature: feature96                      Rank: 124,  Keep: False\n",
      "Feature: feature97                      Rank: 1,  Keep: True\n",
      "Feature: feature99                      Rank: 1,  Keep: True\n",
      "Feature: feature100                     Rank: 1,  Keep: True\n",
      "Feature: feature101                     Rank: 63,  Keep: False\n",
      "Feature: feature102                     Rank: 29,  Keep: False\n",
      "Feature: feature103                     Rank: 1,  Keep: True\n",
      "Feature: feature104                     Rank: 1,  Keep: True\n",
      "Feature: feature105                     Rank: 1,  Keep: True\n",
      "Feature: feature106                     Rank: 1,  Keep: True\n",
      "Feature: feature107                     Rank: 1,  Keep: True\n",
      "Feature: feature108                     Rank: 1,  Keep: True\n",
      "Feature: feature109                     Rank: 1,  Keep: True\n",
      "Feature: feature110                     Rank: 1,  Keep: True\n",
      "Feature: feature111                     Rank: 1,  Keep: True\n",
      "Feature: feature112                     Rank: 1,  Keep: True\n",
      "Feature: feature113                     Rank: 1,  Keep: True\n",
      "Feature: feature114                     Rank: 1,  Keep: True\n",
      "Feature: feature115                     Rank: 131,  Keep: False\n",
      "Feature: feature116                     Rank: 1,  Keep: True\n",
      "Feature: feature117                     Rank: 1,  Keep: True\n",
      "Feature: feature118                     Rank: 1,  Keep: True\n",
      "Feature: feature119                     Rank: 55,  Keep: False\n",
      "Feature: feature120                     Rank: 1,  Keep: True\n",
      "Feature: feature121                     Rank: 1,  Keep: True\n",
      "Feature: feature122                     Rank: 1,  Keep: True\n",
      "Feature: feature123                     Rank: 1,  Keep: True\n",
      "Feature: feature124                     Rank: 1,  Keep: True\n",
      "Feature: feature125                     Rank: 1,  Keep: True\n",
      "Feature: feature126                     Rank: 1,  Keep: True\n",
      "Feature: feature127                     Rank: 1,  Keep: True\n",
      "Feature: feature128                     Rank: 1,  Keep: True\n",
      "Feature: feature129                     Rank: 120,  Keep: False\n",
      "Feature: feature130                     Rank: 1,  Keep: True\n",
      "Feature: feature131                     Rank: 1,  Keep: True\n",
      "Feature: feature132                     Rank: 1,  Keep: True\n",
      "Feature: feature133                     Rank: 1,  Keep: True\n",
      "Feature: feature134                     Rank: 1,  Keep: True\n",
      "Feature: feature135                     Rank: 1,  Keep: True\n",
      "Feature: feature136                     Rank: 1,  Keep: True\n",
      "Feature: feature137                     Rank: 42,  Keep: False\n",
      "Feature: feature138                     Rank: 1,  Keep: True\n",
      "Feature: feature139                     Rank: 7,  Keep: False\n",
      "Feature: feature140                     Rank: 1,  Keep: True\n",
      "Feature: feature141                     Rank: 1,  Keep: True\n",
      "Feature: feature143                     Rank: 93,  Keep: False\n",
      "Feature: feature144                     Rank: 1,  Keep: True\n",
      "Feature: feature145                     Rank: 1,  Keep: True\n",
      "Feature: feature146                     Rank: 1,  Keep: True\n",
      "Feature: feature147                     Rank: 1,  Keep: True\n",
      "Feature: feature148                     Rank: 1,  Keep: True\n",
      "Feature: feature149                     Rank: 1,  Keep: True\n",
      "Feature: feature151                     Rank: 1,  Keep: True\n",
      "Feature: feature152                     Rank: 101,  Keep: False\n",
      "Feature: feature153                     Rank: 1,  Keep: True\n",
      "Feature: feature154                     Rank: 1,  Keep: True\n",
      "Feature: feature155                     Rank: 1,  Keep: True\n",
      "Feature: feature156                     Rank: 60,  Keep: False\n",
      "Feature: feature157                     Rank: 1,  Keep: True\n",
      "Feature: feature160                     Rank: 1,  Keep: True\n",
      "Feature: feature161                     Rank: 1,  Keep: True\n",
      "Feature: feature162                     Rank: 1,  Keep: True\n",
      "Feature: feature163                     Rank: 1,  Keep: True\n",
      "Feature: feature164                     Rank: 1,  Keep: True\n",
      "Feature: feature165                     Rank: 111,  Keep: False\n",
      "Feature: feature166                     Rank: 1,  Keep: True\n",
      "Feature: feature167                     Rank: 1,  Keep: True\n",
      "Feature: feature168                     Rank: 16,  Keep: False\n",
      "Feature: feature169                     Rank: 97,  Keep: False\n",
      "Feature: feature170                     Rank: 1,  Keep: True\n",
      "Feature: feature171                     Rank: 1,  Keep: True\n",
      "Feature: feature172                     Rank: 3,  Keep: False\n",
      "Feature: feature173                     Rank: 49,  Keep: False\n",
      "Feature: feature174                     Rank: 1,  Keep: True\n",
      "Feature: feature175                     Rank: 1,  Keep: True\n",
      "Feature: feature176                     Rank: 1,  Keep: True\n",
      "Feature: feature177                     Rank: 1,  Keep: True\n",
      "Feature: feature178                     Rank: 1,  Keep: True\n",
      "Feature: feature181                     Rank: 66,  Keep: False\n",
      "Feature: feature182                     Rank: 1,  Keep: True\n",
      "Feature: feature183                     Rank: 1,  Keep: True\n",
      "Feature: feature184                     Rank: 1,  Keep: True\n",
      "Feature: feature185                     Rank: 1,  Keep: True\n",
      "Feature: feature186                     Rank: 1,  Keep: True\n",
      "Feature: feature188                     Rank: 1,  Keep: True\n",
      "Feature: feature189                     Rank: 1,  Keep: True\n",
      "Feature: feature196                     Rank: 1,  Keep: True\n",
      "Feature: feature197                     Rank: 1,  Keep: True\n",
      "Feature: feature198                     Rank: 1,  Keep: True\n",
      "Feature: feature199                     Rank: 1,  Keep: True\n",
      "Feature: feature200                     Rank: 28,  Keep: False\n",
      "Feature: feature201                     Rank: 1,  Keep: True\n",
      "Feature: feature202                     Rank: 1,  Keep: True\n",
      "Feature: feature203                     Rank: 1,  Keep: True\n",
      "Feature: feature204                     Rank: 1,  Keep: True\n",
      "Feature: feature205                     Rank: 1,  Keep: True\n",
      "Feature: feature206                     Rank: 1,  Keep: True\n",
      "Feature: feature207                     Rank: 70,  Keep: False\n",
      "Feature: feature208                     Rank: 1,  Keep: True\n",
      "Feature: feature209                     Rank: 1,  Keep: True\n",
      "Feature: feature210                     Rank: 128,  Keep: False\n",
      "Feature: feature211                     Rank: 1,  Keep: True\n",
      "Feature: feature212                     Rank: 1,  Keep: True\n",
      "Feature: feature213                     Rank: 1,  Keep: True\n",
      "Feature: feature214                     Rank: 1,  Keep: True\n",
      "Feature: feature215                     Rank: 1,  Keep: True\n",
      "Feature: feature216                     Rank: 1,  Keep: True\n",
      "Feature: feature217                     Rank: 1,  Keep: True\n",
      "Feature: feature218                     Rank: 1,  Keep: True\n",
      "Feature: feature219                     Rank: 1,  Keep: True\n",
      "Feature: feature220                     Rank: 1,  Keep: True\n",
      "Feature: feature222                     Rank: 1,  Keep: True\n",
      "Feature: feature223                     Rank: 90,  Keep: False\n",
      "Feature: feature224                     Rank: 1,  Keep: True\n",
      "Feature: feature225                     Rank: 91,  Keep: False\n",
      "Feature: feature226                     Rank: 46,  Keep: False\n",
      "Feature: feature228                     Rank: 1,  Keep: True\n",
      "Feature: feature229                     Rank: 1,  Keep: True\n",
      "Feature: feature239                     Rank: 1,  Keep: True\n",
      "Feature: feature240                     Rank: 1,  Keep: True\n",
      "Feature: feature245                     Rank: 1,  Keep: True\n",
      "Feature: feature246                     Rank: 65,  Keep: False\n",
      "Feature: feature247                     Rank: 1,  Keep: True\n",
      "Feature: feature248                     Rank: 1,  Keep: True\n",
      "Feature: feature249                     Rank: 67,  Keep: False\n",
      "Feature: feature250                     Rank: 133,  Keep: False\n",
      "Feature: feature251                     Rank: 1,  Keep: True\n",
      "Feature: feature252                     Rank: 21,  Keep: False\n",
      "Feature: feature253                     Rank: 1,  Keep: True\n",
      "Feature: feature254                     Rank: 1,  Keep: True\n",
      "Feature: feature255                     Rank: 1,  Keep: True\n",
      "Feature: feature256                     Rank: 83,  Keep: False\n",
      "Feature: feature268                     Rank: 1,  Keep: True\n",
      "Feature: feature269                     Rank: 30,  Keep: False\n",
      "Feature: feature270                     Rank: 94,  Keep: False\n",
      "Feature: feature271                     Rank: 1,  Keep: True\n",
      "Feature: feature272                     Rank: 10,  Keep: False\n",
      "Feature: feature273                     Rank: 1,  Keep: True\n",
      "Feature: feature274                     Rank: 1,  Keep: True\n",
      "Feature: feature275                     Rank: 73,  Keep: False\n",
      "Feature: feature276                     Rank: 130,  Keep: False\n",
      "Feature: feature278                     Rank: 107,  Keep: False\n",
      "Feature: feature279                     Rank: 72,  Keep: False\n",
      "Feature: feature280                     Rank: 1,  Keep: True\n",
      "Feature: feature281                     Rank: 112,  Keep: False\n",
      "Feature: feature282                     Rank: 1,  Keep: True\n",
      "Feature: feature283                     Rank: 1,  Keep: True\n",
      "Feature: feature284                     Rank: 50,  Keep: False\n",
      "Feature: feature286                     Rank: 1,  Keep: True\n",
      "Feature: feature287                     Rank: 51,  Keep: False\n",
      "Feature: feature288                     Rank: 1,  Keep: True\n",
      "Feature: feature289                     Rank: 1,  Keep: True\n",
      "Feature: feature290                     Rank: 88,  Keep: False\n",
      "Feature: feature291                     Rank: 1,  Keep: True\n",
      "Feature: feature292                     Rank: 1,  Keep: True\n",
      "Feature: feature295                     Rank: 1,  Keep: True\n",
      "Feature: feature296                     Rank: 1,  Keep: True\n",
      "Feature: feature297                     Rank: 1,  Keep: True\n",
      "Feature: feature298                     Rank: 1,  Keep: True\n",
      "Feature: feature299                     Rank: 1,  Keep: True\n",
      "Feature: feature300                     Rank: 1,  Keep: True\n",
      "Feature: feature301                     Rank: 1,  Keep: True\n",
      "Feature: feature302                     Rank: 1,  Keep: True\n",
      "Feature: feature303                     Rank: 1,  Keep: True\n",
      "Feature: feature304                     Rank: 1,  Keep: True\n",
      "Feature: feature305                     Rank: 102,  Keep: False\n",
      "Feature: feature306                     Rank: 118,  Keep: False\n",
      "Feature: feature307                     Rank: 1,  Keep: True\n",
      "Feature: feature308                     Rank: 1,  Keep: True\n",
      "Feature: feature309                     Rank: 39,  Keep: False\n",
      "Feature: feature310                     Rank: 1,  Keep: True\n",
      "Feature: feature311                     Rank: 1,  Keep: True\n",
      "Feature: feature312                     Rank: 95,  Keep: False\n",
      "Feature: feature313                     Rank: 1,  Keep: True\n",
      "Feature: feature317                     Rank: 1,  Keep: True\n",
      "Feature: feature318                     Rank: 1,  Keep: True\n",
      "Feature: feature319                     Rank: 1,  Keep: True\n",
      "Feature: feature320                     Rank: 1,  Keep: True\n",
      "Feature: feature321                     Rank: 33,  Keep: False\n",
      "Feature: feature322                     Rank: 54,  Keep: False\n",
      "Feature: feature324                     Rank: 1,  Keep: True\n",
      "Feature: feature325                     Rank: 1,  Keep: True\n",
      "Feature: feature332                     Rank: 1,  Keep: True\n",
      "Feature: feature333                     Rank: 1,  Keep: True\n",
      "Feature: feature334                     Rank: 1,  Keep: True\n",
      "Feature: feature335                     Rank: 1,  Keep: True\n",
      "Feature: feature336                     Rank: 1,  Keep: True\n",
      "Feature: feature337                     Rank: 1,  Keep: True\n",
      "Feature: feature338                     Rank: 11,  Keep: False\n",
      "Feature: feature339                     Rank: 1,  Keep: True\n",
      "Feature: feature340                     Rank: 1,  Keep: True\n",
      "Feature: feature341                     Rank: 1,  Keep: True\n",
      "Feature: feature342                     Rank: 1,  Keep: True\n",
      "Feature: feature343                     Rank: 116,  Keep: False\n",
      "Feature: feature344                     Rank: 57,  Keep: False\n",
      "Feature: feature345                     Rank: 1,  Keep: True\n",
      "Feature: feature346                     Rank: 15,  Keep: False\n",
      "Feature: feature347                     Rank: 1,  Keep: True\n",
      "Feature: feature348                     Rank: 129,  Keep: False\n",
      "Feature: feature349                     Rank: 1,  Keep: True\n",
      "Feature: feature350                     Rank: 1,  Keep: True\n",
      "Feature: feature351                     Rank: 5,  Keep: False\n",
      "Feature: feature352                     Rank: 8,  Keep: False\n",
      "Feature: feature353                     Rank: 1,  Keep: True\n",
      "Feature: feature354                     Rank: 103,  Keep: False\n",
      "Feature: feature355                     Rank: 1,  Keep: True\n",
      "Feature: feature356                     Rank: 69,  Keep: False\n",
      "Feature: feature357                     Rank: 1,  Keep: True\n",
      "Feature: feature358                     Rank: 1,  Keep: True\n",
      "Feature: feature360                     Rank: 1,  Keep: True\n",
      "Feature: feature361                     Rank: 1,  Keep: True\n",
      "Feature: feature362                     Rank: 38,  Keep: False\n",
      "Feature: feature363                     Rank: 1,  Keep: True\n",
      "Feature: feature364                     Rank: 1,  Keep: True\n",
      "Feature: feature366                     Rank: 17,  Keep: False\n",
      "Feature: feature367                     Rank: 1,  Keep: True\n",
      "Feature: feature368                     Rank: 18,  Keep: False\n",
      "Feature: feature369                     Rank: 80,  Keep: False\n",
      "Feature: feature377                     Rank: 1,  Keep: True\n",
      "Feature: feature378                     Rank: 1,  Keep: True\n",
      "Feature: feature383                     Rank: 1,  Keep: True\n",
      "Feature: feature384                     Rank: 1,  Keep: True\n",
      "Feature: feature385                     Rank: 1,  Keep: True\n",
      "Feature: feature386                     Rank: 1,  Keep: True\n",
      "Feature: feature387                     Rank: 45,  Keep: False\n",
      "Feature: feature388                     Rank: 113,  Keep: False\n",
      "Feature: feature389                     Rank: 79,  Keep: False\n",
      "Feature: feature390                     Rank: 9,  Keep: False\n",
      "Feature: feature391                     Rank: 1,  Keep: True\n",
      "Feature: feature392                     Rank: 1,  Keep: True\n",
      "Feature: feature393                     Rank: 1,  Keep: True\n",
      "Feature: feature394                     Rank: 71,  Keep: False\n",
      "Feature: feature406                     Rank: 1,  Keep: True\n",
      "Feature: feature407                     Rank: 1,  Keep: True\n",
      "Feature: feature408                     Rank: 20,  Keep: False\n",
      "Feature: feature409                     Rank: 1,  Keep: True\n",
      "Feature: feature410                     Rank: 1,  Keep: True\n",
      "Feature: feature411                     Rank: 1,  Keep: True\n",
      "Feature: feature412                     Rank: 19,  Keep: False\n",
      "Feature: feature413                     Rank: 1,  Keep: True\n",
      "Feature: feature414                     Rank: 1,  Keep: True\n",
      "Feature: feature416                     Rank: 117,  Keep: False\n",
      "Feature: feature417                     Rank: 1,  Keep: True\n",
      "Feature: feature418                     Rank: 1,  Keep: True\n",
      "Feature: feature419                     Rank: 74,  Keep: False\n",
      "Feature: feature420                     Rank: 85,  Keep: False\n",
      "Feature: feature421                     Rank: 1,  Keep: True\n",
      "Feature: feature422                     Rank: 58,  Keep: False\n",
      "Feature: feature424                     Rank: 1,  Keep: True\n",
      "Feature: feature425                     Rank: 1,  Keep: True\n",
      "Feature: feature426                     Rank: 1,  Keep: True\n",
      "Feature: feature427                     Rank: 1,  Keep: True\n",
      "Feature: feature428                     Rank: 1,  Keep: True\n",
      "Feature: feature429                     Rank: 1,  Keep: True\n",
      "Feature: feature430                     Rank: 99,  Keep: False\n",
      "Feature: feature431                     Rank: 1,  Keep: True\n",
      "Feature: feature432                     Rank: 1,  Keep: True\n",
      "Feature: feature433                     Rank: 1,  Keep: True\n",
      "Feature: feature434                     Rank: 1,  Keep: True\n",
      "Feature: feature435                     Rank: 1,  Keep: True\n",
      "Feature: feature436                     Rank: 1,  Keep: True\n",
      "Feature: feature437                     Rank: 127,  Keep: False\n",
      "Feature: feature438                     Rank: 14,  Keep: False\n",
      "Feature: feature439                     Rank: 53,  Keep: False\n",
      "Feature: feature440                     Rank: 1,  Keep: True\n",
      "Feature: feature441                     Rank: 1,  Keep: True\n",
      "Feature: feature442                     Rank: 1,  Keep: True\n",
      "Feature: feature443                     Rank: 1,  Keep: True\n",
      "Feature: feature444                     Rank: 27,  Keep: False\n",
      "Feature: feature445                     Rank: 40,  Keep: False\n",
      "Feature: feature446                     Rank: 1,  Keep: True\n",
      "Feature: feature447                     Rank: 1,  Keep: True\n",
      "Feature: feature448                     Rank: 115,  Keep: False\n",
      "Feature: feature449                     Rank: 25,  Keep: False\n",
      "Feature: feature453                     Rank: 1,  Keep: True\n",
      "Feature: feature454                     Rank: 1,  Keep: True\n",
      "Feature: feature455                     Rank: 1,  Keep: True\n",
      "Feature: feature456                     Rank: 1,  Keep: True\n",
      "Feature: feature457                     Rank: 1,  Keep: True\n",
      "Feature: feature458                     Rank: 86,  Keep: False\n",
      "Feature: feature460                     Rank: 1,  Keep: True\n",
      "Feature: feature461                     Rank: 1,  Keep: True\n",
      "Feature: feature468                     Rank: 1,  Keep: True\n",
      "Feature: feature469                     Rank: 1,  Keep: True\n",
      "Feature: feature470                     Rank: 1,  Keep: True\n",
      "Feature: feature471                     Rank: 109,  Keep: False\n",
      "Feature: feature472                     Rank: 1,  Keep: True\n",
      "Feature: feature473                     Rank: 1,  Keep: True\n",
      "Feature: feature474                     Rank: 1,  Keep: True\n",
      "Feature: feature475                     Rank: 1,  Keep: True\n",
      "Feature: feature476                     Rank: 1,  Keep: True\n",
      "Feature: feature477                     Rank: 89,  Keep: False\n",
      "Feature: feature478                     Rank: 1,  Keep: True\n",
      "Feature: feature479                     Rank: 122,  Keep: False\n",
      "Feature: feature480                     Rank: 1,  Keep: True\n",
      "Feature: feature481                     Rank: 1,  Keep: True\n",
      "Feature: feature483                     Rank: 35,  Keep: False\n",
      "Feature: feature484                     Rank: 1,  Keep: True\n",
      "Feature: feature485                     Rank: 84,  Keep: False\n",
      "Feature: feature486                     Rank: 2,  Keep: False\n",
      "Feature: feature487                     Rank: 92,  Keep: False\n",
      "Feature: feature488                     Rank: 1,  Keep: True\n",
      "Feature: feature489                     Rank: 1,  Keep: True\n",
      "Feature: feature490                     Rank: 1,  Keep: True\n",
      "Feature: feature491                     Rank: 1,  Keep: True\n",
      "Feature: feature492                     Rank: 43,  Keep: False\n",
      "Feature: feature494                     Rank: 75,  Keep: False\n",
      "Feature: feature495                     Rank: 126,  Keep: False\n",
      "Feature: feature496                     Rank: 1,  Keep: True\n",
      "Feature: feature497                     Rank: 1,  Keep: True\n",
      "Feature: feature498                     Rank: 1,  Keep: True\n",
      "Feature: feature500                     Rank: 132,  Keep: False\n",
      "Feature: feature501                     Rank: 1,  Keep: True\n",
      "Feature: feature511                     Rank: 1,  Keep: True\n",
      "Feature: feature512                     Rank: 1,  Keep: True\n",
      "Feature: feature517                     Rank: 1,  Keep: True\n",
      "Feature: feature518                     Rank: 37,  Keep: False\n",
      "Feature: feature519                     Rank: 121,  Keep: False\n",
      "Feature: feature520                     Rank: 1,  Keep: True\n",
      "Feature: feature521                     Rank: 1,  Keep: True\n",
      "Feature: feature522                     Rank: 114,  Keep: False\n",
      "Feature: feature523                     Rank: 6,  Keep: False\n",
      "Feature: feature524                     Rank: 123,  Keep: False\n",
      "Feature: feature525                     Rank: 1,  Keep: True\n",
      "Feature: feature526                     Rank: 1,  Keep: True\n",
      "Feature: feature527                     Rank: 1,  Keep: True\n",
      "Feature: feature528                     Rank: 32,  Keep: False\n",
      "Feature: feature540                     Rank: 1,  Keep: True\n",
      "Feature: feature541                     Rank: 26,  Keep: False\n",
      "Feature: feature542                     Rank: 1,  Keep: True\n",
      "Feature: feature543                     Rank: 1,  Keep: True\n",
      "Feature: feature544                     Rank: 1,  Keep: True\n",
      "Feature: feature545                     Rank: 23,  Keep: False\n",
      "Feature: feature546                     Rank: 52,  Keep: False\n",
      "Feature: feature547                     Rank: 34,  Keep: False\n",
      "Feature: feature548                     Rank: 77,  Keep: False\n",
      "Feature: feature549                     Rank: 68,  Keep: False\n",
      "Feature: feature550                     Rank: 1,  Keep: True\n",
      "Feature: feature551                     Rank: 47,  Keep: False\n",
      "Feature: feature552                     Rank: 1,  Keep: True\n",
      "Feature: feature553                     Rank: 48,  Keep: False\n",
      "Feature: feature554                     Rank: 1,  Keep: True\n",
      "Feature: feature555                     Rank: 22,  Keep: False\n",
      "Feature: feature556                     Rank: 1,  Keep: True\n",
      "Feature: feature557                     Rank: 44,  Keep: False\n",
      "Feature: feature558                     Rank: 1,  Keep: True\n",
      "Feature: feature559                     Rank: 1,  Keep: True\n",
      "Feature: feature560                     Rank: 1,  Keep: True\n",
      "Feature: feature561                     Rank: 1,  Keep: True\n",
      "Feature: feature562                     Rank: 1,  Keep: True\n",
      "Feature: feature563                     Rank: 1,  Keep: True\n",
      "Feature: feature564                     Rank: 1,  Keep: True\n",
      "Feature: feature565                     Rank: 1,  Keep: True\n",
      "Feature: feature566                     Rank: 1,  Keep: True\n",
      "Feature: feature567                     Rank: 1,  Keep: True\n",
      "Feature: feature568                     Rank: 1,  Keep: True\n",
      "Feature: feature569                     Rank: 1,  Keep: True\n",
      "Feature: feature570                     Rank: 24,  Keep: False\n",
      "Feature: feature571                     Rank: 59,  Keep: False\n",
      "Feature: feature572                     Rank: 1,  Keep: True\n",
      "Feature: feature573                     Rank: 1,  Keep: True\n",
      "Feature: feature574                     Rank: 1,  Keep: True\n",
      "Feature: feature575                     Rank: 1,  Keep: True\n",
      "Feature: feature576                     Rank: 1,  Keep: True\n",
      "Feature: feature577                     Rank: 13,  Keep: False\n",
      "Feature: feature578                     Rank: 1,  Keep: True\n",
      "Feature: feature579                     Rank: 1,  Keep: True\n",
      "Feature: feature580                     Rank: 61,  Keep: False\n",
      "Feature: feature581                     Rank: 76,  Keep: False\n",
      "Feature: feature582                     Rank: 1,  Keep: True\n",
      "Feature: feature583                     Rank: 1,  Keep: True\n",
      "Feature: feature584                     Rank: 1,  Keep: True\n",
      "Feature: feature585                     Rank: 1,  Keep: True\n",
      "Feature: feature586                     Rank: 1,  Keep: True\n",
      "Feature: feature587                     Rank: 4,  Keep: False\n",
      "Feature: feature588                     Rank: 1,  Keep: True\n",
      "Feature: feature589                     Rank: 100,  Keep: False\n",
      "Feature: feature590                     Rank: 119,  Keep: False\n",
      "['feature1', 'feature4', 'feature5', 'feature7', 'feature8', 'feature9', 'feature10', 'feature11', 'feature12', 'feature13', 'feature15', 'feature16', 'feature17', 'feature18', 'feature19', 'feature20', 'feature22', 'feature23', 'feature25', 'feature26', 'feature27', 'feature29', 'feature31', 'feature32', 'feature33', 'feature34', 'feature35', 'feature36', 'feature38', 'feature39', 'feature40', 'feature41', 'feature42', 'feature45', 'feature46', 'feature47', 'feature48', 'feature49', 'feature51', 'feature52', 'feature54', 'feature55', 'feature56', 'feature57', 'feature59', 'feature60', 'feature63', 'feature64', 'feature65', 'feature66', 'feature67', 'feature68', 'feature69', 'feature71', 'feature72', 'feature73', 'feature77', 'feature78', 'feature79', 'feature80', 'feature81', 'feature82', 'feature83', 'feature84', 'feature88', 'feature90', 'feature91', 'feature92', 'feature93', 'feature97', 'feature99', 'feature100', 'feature103', 'feature104', 'feature105', 'feature106', 'feature107', 'feature108', 'feature109', 'feature110', 'feature111', 'feature112', 'feature113', 'feature114', 'feature116', 'feature117', 'feature118', 'feature120', 'feature121', 'feature122', 'feature123', 'feature124', 'feature125', 'feature126', 'feature127', 'feature128', 'feature130', 'feature131', 'feature132', 'feature133', 'feature134', 'feature135', 'feature136', 'feature138', 'feature140', 'feature141', 'feature144', 'feature145', 'feature146', 'feature147', 'feature148', 'feature149', 'feature151', 'feature153', 'feature154', 'feature155', 'feature157', 'feature160', 'feature161', 'feature162', 'feature163', 'feature164', 'feature166', 'feature167', 'feature170', 'feature171', 'feature174', 'feature175', 'feature176', 'feature177', 'feature178', 'feature182', 'feature183', 'feature184', 'feature185', 'feature186', 'feature188', 'feature189', 'feature196', 'feature197', 'feature198', 'feature199', 'feature201', 'feature202', 'feature203', 'feature204', 'feature205', 'feature206', 'feature208', 'feature209', 'feature211', 'feature212', 'feature213', 'feature214', 'feature215', 'feature216', 'feature217', 'feature218', 'feature219', 'feature220', 'feature222', 'feature224', 'feature228', 'feature229', 'feature239', 'feature240', 'feature245', 'feature247', 'feature248', 'feature251', 'feature253', 'feature254', 'feature255', 'feature268', 'feature271', 'feature273', 'feature274', 'feature280', 'feature282', 'feature283', 'feature286', 'feature288', 'feature289', 'feature291', 'feature292', 'feature295', 'feature296', 'feature297', 'feature298', 'feature299', 'feature300', 'feature301', 'feature302', 'feature303', 'feature304', 'feature307', 'feature308', 'feature310', 'feature311', 'feature313', 'feature317', 'feature318', 'feature319', 'feature320', 'feature324', 'feature325', 'feature332', 'feature333', 'feature334', 'feature335', 'feature336', 'feature337', 'feature339', 'feature340', 'feature341', 'feature342', 'feature345', 'feature347', 'feature349', 'feature350', 'feature353', 'feature355', 'feature357', 'feature358', 'feature360', 'feature361', 'feature363', 'feature364', 'feature367', 'feature377', 'feature378', 'feature383', 'feature384', 'feature385', 'feature386', 'feature391', 'feature392', 'feature393', 'feature406', 'feature407', 'feature409', 'feature410', 'feature411', 'feature413', 'feature414', 'feature417', 'feature418', 'feature421', 'feature424', 'feature425', 'feature426', 'feature427', 'feature428', 'feature429', 'feature431', 'feature432', 'feature433', 'feature434', 'feature435', 'feature436', 'feature440', 'feature441', 'feature442', 'feature443', 'feature446', 'feature447', 'feature453', 'feature454', 'feature455', 'feature456', 'feature457', 'feature460', 'feature461', 'feature468', 'feature469', 'feature470', 'feature472', 'feature473', 'feature474', 'feature475', 'feature476', 'feature478', 'feature480', 'feature481', 'feature484', 'feature488', 'feature489', 'feature490', 'feature491', 'feature496', 'feature497', 'feature498', 'feature501', 'feature511', 'feature512', 'feature517', 'feature520', 'feature521', 'feature525', 'feature526', 'feature527', 'feature540', 'feature542', 'feature543', 'feature544', 'feature550', 'feature552', 'feature554', 'feature556', 'feature558', 'feature559', 'feature560', 'feature561', 'feature562', 'feature563', 'feature564', 'feature565', 'feature566', 'feature567', 'feature568', 'feature569', 'feature572', 'feature573', 'feature574', 'feature575', 'feature576', 'feature578', 'feature579', 'feature582', 'feature583', 'feature584', 'feature585', 'feature586', 'feature588']\n"
     ]
    }
   ],
   "source": [
    "# apply RFE and store selected features in a variable\n",
    "X_train_rfeCV , final_features_rfeCV = RFECVFeatureSelection(imputed_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>feature12</th>\n",
       "      <th>feature13</th>\n",
       "      <th>...</th>\n",
       "      <th>feature575</th>\n",
       "      <th>feature576</th>\n",
       "      <th>feature578</th>\n",
       "      <th>feature579</th>\n",
       "      <th>feature582</th>\n",
       "      <th>feature583</th>\n",
       "      <th>feature584</th>\n",
       "      <th>feature585</th>\n",
       "      <th>feature586</th>\n",
       "      <th>feature588</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3079.77</td>\n",
       "      <td>1269.607800</td>\n",
       "      <td>1.7571</td>\n",
       "      <td>97.018900</td>\n",
       "      <td>0.1221</td>\n",
       "      <td>1.4607</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.9577</td>\n",
       "      <td>198.5381</td>\n",
       "      <td>...</td>\n",
       "      <td>60.9374</td>\n",
       "      <td>0.2519</td>\n",
       "      <td>24.5741</td>\n",
       "      <td>0.028200</td>\n",
       "      <td>68.74440</td>\n",
       "      <td>0.5001</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>2.1899</td>\n",
       "      <td>0.0194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3001.36</td>\n",
       "      <td>918.216100</td>\n",
       "      <td>1.2753</td>\n",
       "      <td>105.047800</td>\n",
       "      <td>0.1227</td>\n",
       "      <td>1.4206</td>\n",
       "      <td>-0.0052</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>203.8512</td>\n",
       "      <td>...</td>\n",
       "      <td>3.1887</td>\n",
       "      <td>0.0581</td>\n",
       "      <td>7.8563</td>\n",
       "      <td>0.035613</td>\n",
       "      <td>63.99824</td>\n",
       "      <td>0.4943</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>4.0318</td>\n",
       "      <td>0.0276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3042.78</td>\n",
       "      <td>1433.673200</td>\n",
       "      <td>1.0304</td>\n",
       "      <td>110.542200</td>\n",
       "      <td>0.1245</td>\n",
       "      <td>1.4964</td>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.0133</td>\n",
       "      <td>0.9486</td>\n",
       "      <td>197.4142</td>\n",
       "      <td>...</td>\n",
       "      <td>3.4013</td>\n",
       "      <td>0.0934</td>\n",
       "      <td>14.6788</td>\n",
       "      <td>0.018020</td>\n",
       "      <td>72.86980</td>\n",
       "      <td>0.4962</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>2.2877</td>\n",
       "      <td>0.0287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3018.64</td>\n",
       "      <td>1510.079700</td>\n",
       "      <td>1.5611</td>\n",
       "      <td>99.830000</td>\n",
       "      <td>0.1199</td>\n",
       "      <td>1.4428</td>\n",
       "      <td>-0.0110</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.9501</td>\n",
       "      <td>199.1920</td>\n",
       "      <td>...</td>\n",
       "      <td>3.6888</td>\n",
       "      <td>0.0892</td>\n",
       "      <td>12.0929</td>\n",
       "      <td>0.028400</td>\n",
       "      <td>49.74900</td>\n",
       "      <td>0.5047</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>1.9927</td>\n",
       "      <td>0.0141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3020.29</td>\n",
       "      <td>1744.777100</td>\n",
       "      <td>0.9618</td>\n",
       "      <td>100.178900</td>\n",
       "      <td>0.1218</td>\n",
       "      <td>1.4950</td>\n",
       "      <td>-0.0097</td>\n",
       "      <td>-0.0054</td>\n",
       "      <td>0.9679</td>\n",
       "      <td>201.6603</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4093</td>\n",
       "      <td>0.0788</td>\n",
       "      <td>13.1210</td>\n",
       "      <td>0.025480</td>\n",
       "      <td>69.47592</td>\n",
       "      <td>0.5010</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>2.9338</td>\n",
       "      <td>0.0114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>3057.31</td>\n",
       "      <td>1663.702400</td>\n",
       "      <td>1.0203</td>\n",
       "      <td>100.445600</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>1.4830</td>\n",
       "      <td>-0.0328</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.9663</td>\n",
       "      <td>197.7390</td>\n",
       "      <td>...</td>\n",
       "      <td>3.2513</td>\n",
       "      <td>0.0801</td>\n",
       "      <td>9.9246</td>\n",
       "      <td>0.026380</td>\n",
       "      <td>55.49078</td>\n",
       "      <td>0.5037</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>3.4736</td>\n",
       "      <td>0.0117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>3009.71</td>\n",
       "      <td>1308.647900</td>\n",
       "      <td>1.3907</td>\n",
       "      <td>101.133300</td>\n",
       "      <td>0.1208</td>\n",
       "      <td>1.4440</td>\n",
       "      <td>-0.0079</td>\n",
       "      <td>-0.0076</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>198.9233</td>\n",
       "      <td>...</td>\n",
       "      <td>3.4596</td>\n",
       "      <td>0.0944</td>\n",
       "      <td>14.8682</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>151.46970</td>\n",
       "      <td>0.4979</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>1.5724</td>\n",
       "      <td>0.0215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>3034.34</td>\n",
       "      <td>2028.220800</td>\n",
       "      <td>1.5552</td>\n",
       "      <td>95.425600</td>\n",
       "      <td>0.1234</td>\n",
       "      <td>1.4281</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.9452</td>\n",
       "      <td>204.2667</td>\n",
       "      <td>...</td>\n",
       "      <td>3.4068</td>\n",
       "      <td>0.0483</td>\n",
       "      <td>10.8388</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>84.81790</td>\n",
       "      <td>0.4968</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.5829</td>\n",
       "      <td>0.0116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>3025.21</td>\n",
       "      <td>2704.805249</td>\n",
       "      <td>1.4843</td>\n",
       "      <td>82.357569</td>\n",
       "      <td>0.1248</td>\n",
       "      <td>1.3687</td>\n",
       "      <td>-0.0070</td>\n",
       "      <td>-0.0033</td>\n",
       "      <td>0.9616</td>\n",
       "      <td>203.7470</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4650</td>\n",
       "      <td>0.0927</td>\n",
       "      <td>15.5905</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>46.10760</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>3.1428</td>\n",
       "      <td>0.0055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>2997.07</td>\n",
       "      <td>1226.221700</td>\n",
       "      <td>1.4656</td>\n",
       "      <td>106.312200</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>1.4779</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>-0.0013</td>\n",
       "      <td>0.9687</td>\n",
       "      <td>198.3858</td>\n",
       "      <td>...</td>\n",
       "      <td>36.6385</td>\n",
       "      <td>0.2560</td>\n",
       "      <td>45.2513</td>\n",
       "      <td>0.024780</td>\n",
       "      <td>82.73494</td>\n",
       "      <td>0.5014</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>2.3055</td>\n",
       "      <td>0.0220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1253 rows × 334 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature1     feature4  feature5    feature7  feature8  feature9  \\\n",
       "0      3079.77  1269.607800    1.7571   97.018900    0.1221    1.4607   \n",
       "1      3001.36   918.216100    1.2753  105.047800    0.1227    1.4206   \n",
       "2      3042.78  1433.673200    1.0304  110.542200    0.1245    1.4964   \n",
       "3      3018.64  1510.079700    1.5611   99.830000    0.1199    1.4428   \n",
       "4      3020.29  1744.777100    0.9618  100.178900    0.1218    1.4950   \n",
       "...        ...          ...       ...         ...       ...       ...   \n",
       "1248   3057.31  1663.702400    1.0203  100.445600    0.1247    1.4830   \n",
       "1249   3009.71  1308.647900    1.3907  101.133300    0.1208    1.4440   \n",
       "1250   3034.34  2028.220800    1.5552   95.425600    0.1234    1.4281   \n",
       "1251   3025.21  2704.805249    1.4843   82.357569    0.1248    1.3687   \n",
       "1252   2997.07  1226.221700    1.4656  106.312200    0.1209    1.4779   \n",
       "\n",
       "      feature10  feature11  feature12  feature13  ...  feature575  feature576  \\\n",
       "0        0.0155     0.0093     0.9577   198.5381  ...     60.9374      0.2519   \n",
       "1       -0.0052     0.0010     0.9649   203.8512  ...      3.1887      0.0581   \n",
       "2        0.0204     0.0133     0.9486   197.4142  ...      3.4013      0.0934   \n",
       "3       -0.0110     0.0101     0.9501   199.1920  ...      3.6888      0.0892   \n",
       "4       -0.0097    -0.0054     0.9679   201.6603  ...      2.4093      0.0788   \n",
       "...         ...        ...        ...        ...  ...         ...         ...   \n",
       "1248    -0.0328     0.0048     0.9663   197.7390  ...      3.2513      0.0801   \n",
       "1249    -0.0079    -0.0076     0.9673   198.9233  ...      3.4596      0.0944   \n",
       "1250     0.0049     0.0092     0.9452   204.2667  ...      3.4068      0.0483   \n",
       "1251    -0.0070    -0.0033     0.9616   203.7470  ...      4.4650      0.0927   \n",
       "1252     0.0052    -0.0013     0.9687   198.3858  ...     36.6385      0.2560   \n",
       "\n",
       "      feature578  feature579  feature582  feature583  feature584  feature585  \\\n",
       "0        24.5741    0.028200    68.74440      0.5001      0.0110      0.0034   \n",
       "1         7.8563    0.035613    63.99824      0.4943      0.0199      0.0042   \n",
       "2        14.6788    0.018020    72.86980      0.4962      0.0114      0.0034   \n",
       "3        12.0929    0.028400    49.74900      0.5047      0.0101      0.0031   \n",
       "4        13.1210    0.025480    69.47592      0.5010      0.0147      0.0036   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1248      9.9246    0.026380    55.49078      0.5037      0.0175      0.0039   \n",
       "1249     14.8682    0.017100   151.46970      0.4979      0.0078      0.0024   \n",
       "1250     10.8388    0.021000    84.81790      0.4968      0.0128      0.0035   \n",
       "1251     15.5905    0.012000    46.10760      0.5019      0.0158      0.0043   \n",
       "1252     45.2513    0.024780    82.73494      0.5014      0.0116      0.0031   \n",
       "\n",
       "      feature586  feature588  \n",
       "0         2.1899      0.0194  \n",
       "1         4.0318      0.0276  \n",
       "2         2.2877      0.0287  \n",
       "3         1.9927      0.0141  \n",
       "4         2.9338      0.0114  \n",
       "...          ...         ...  \n",
       "1248      3.4736      0.0117  \n",
       "1249      1.5724      0.0215  \n",
       "1250      2.5829      0.0116  \n",
       "1251      3.1428      0.0055  \n",
       "1252      2.3055      0.0220  \n",
       "\n",
       "[1253 rows x 334 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_rfeCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualization for RFE\n",
    "#from yellowbrick.model_selection import RFECV\n",
    "#cv = StratifiedKFold(5)\n",
    "#visualizer = RFECV(RandomForestClassifier(), cv=cv,scoring='f1_weighted')\n",
    "\n",
    "#visualizer.fit(retransformed_train, y_train)        # Fit the data to the visualizer\n",
    "#visualizer.show()           # Finalize and render the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names=np.array(imputed_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "                     ('scaler',MinMaxScaler()),\n",
    "                     ('model',Lasso())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GridSearchCV(pipeline,\n",
    "                      {'model__alpha':np.arange(0.1,10,0.1)},\n",
    "                      cv = 5, scoring=\"neg_mean_squared_error\",verbose=3\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 99 candidates, totalling 495 fits\n",
      "[CV 1/5] END .................model__alpha=0.1;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=0.1;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=0.1;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=0.1;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=0.1;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=0.2;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=0.2;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=0.2;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=0.2;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=0.2;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .model__alpha=0.30000000000000004;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .model__alpha=0.30000000000000004;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .model__alpha=0.30000000000000004;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .model__alpha=0.30000000000000004;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .model__alpha=0.30000000000000004;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=0.4;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=0.4;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=0.4;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=0.4;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=0.4;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=0.5;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=0.5;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=0.5;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=0.5;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=0.5;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=0.6;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=0.6;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=0.6;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=0.6;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=0.6;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END ..model__alpha=0.7000000000000001;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END ..model__alpha=0.7000000000000001;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END ..model__alpha=0.7000000000000001;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END ..model__alpha=0.7000000000000001;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END ..model__alpha=0.7000000000000001;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=0.8;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=0.8;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=0.8;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=0.8;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=0.8;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=0.9;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=0.9;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=0.9;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=0.9;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=0.9;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=1.0;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=1.0;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=1.0;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=1.0;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=1.0;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=1.1;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=1.1;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=1.1;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=1.1;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=1.1;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END ..model__alpha=1.2000000000000002;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END ..model__alpha=1.2000000000000002;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END ..model__alpha=1.2000000000000002;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END ..model__alpha=1.2000000000000002;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END ..model__alpha=1.2000000000000002;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END ..model__alpha=1.3000000000000003;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END ..model__alpha=1.3000000000000003;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END ..model__alpha=1.3000000000000003;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END ..model__alpha=1.3000000000000003;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END ..model__alpha=1.3000000000000003;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END ..model__alpha=1.4000000000000001;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END ..model__alpha=1.4000000000000001;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END ..model__alpha=1.4000000000000001;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END ..model__alpha=1.4000000000000001;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END ..model__alpha=1.4000000000000001;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END ..model__alpha=1.5000000000000002;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END ..model__alpha=1.5000000000000002;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END ..model__alpha=1.5000000000000002;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END ..model__alpha=1.5000000000000002;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END ..model__alpha=1.5000000000000002;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=1.6;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=1.6;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=1.6;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=1.6;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=1.6;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END ..model__alpha=1.7000000000000002;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END ..model__alpha=1.7000000000000002;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END ..model__alpha=1.7000000000000002;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END ..model__alpha=1.7000000000000002;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END ..model__alpha=1.7000000000000002;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END ..model__alpha=1.8000000000000003;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END ..model__alpha=1.8000000000000003;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END ..model__alpha=1.8000000000000003;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END ..model__alpha=1.8000000000000003;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END ..model__alpha=1.8000000000000003;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END ..model__alpha=1.9000000000000001;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END ..model__alpha=1.9000000000000001;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END ..model__alpha=1.9000000000000001;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END ..model__alpha=1.9000000000000001;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END ..model__alpha=1.9000000000000001;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=2.0;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=2.0;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=2.0;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=2.0;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=2.0;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=2.1;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=2.1;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=2.1;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=2.1;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=2.1;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=2.2;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=2.2;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=2.2;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=2.2;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=2.2;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END ..model__alpha=2.3000000000000003;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END ..model__alpha=2.3000000000000003;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END ..model__alpha=2.3000000000000003;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END ..model__alpha=2.3000000000000003;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END ..model__alpha=2.3000000000000003;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END ..model__alpha=2.4000000000000004;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END ..model__alpha=2.4000000000000004;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END ..model__alpha=2.4000000000000004;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END ..model__alpha=2.4000000000000004;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END ..model__alpha=2.4000000000000004;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END ..model__alpha=2.5000000000000004;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END ..model__alpha=2.5000000000000004;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END ..model__alpha=2.5000000000000004;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END ..model__alpha=2.5000000000000004;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END ..model__alpha=2.5000000000000004;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=2.6;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=2.6;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=2.6;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=2.6;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=2.6;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=2.7;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=2.7;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=2.7;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=2.7;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=2.7;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END ..model__alpha=2.8000000000000003;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END ..model__alpha=2.8000000000000003;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END ..model__alpha=2.8000000000000003;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END ..model__alpha=2.8000000000000003;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END ..model__alpha=2.8000000000000003;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END ..model__alpha=2.9000000000000004;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END ..model__alpha=2.9000000000000004;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END ..model__alpha=2.9000000000000004;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END ..model__alpha=2.9000000000000004;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END ..model__alpha=2.9000000000000004;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END ..model__alpha=3.0000000000000004;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END ..model__alpha=3.0000000000000004;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END ..model__alpha=3.0000000000000004;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END ..model__alpha=3.0000000000000004;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END ..model__alpha=3.0000000000000004;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=3.1;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=3.1;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=3.1;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=3.1;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=3.1;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=3.2;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=3.2;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=3.2;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=3.2;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=3.2;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END ..model__alpha=3.3000000000000003;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END ..model__alpha=3.3000000000000003;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END ..model__alpha=3.3000000000000003;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END ..model__alpha=3.3000000000000003;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END ..model__alpha=3.3000000000000003;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END ..model__alpha=3.4000000000000004;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END ..model__alpha=3.4000000000000004;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END ..model__alpha=3.4000000000000004;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END ..model__alpha=3.4000000000000004;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END ..model__alpha=3.4000000000000004;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END ..model__alpha=3.5000000000000004;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END ..model__alpha=3.5000000000000004;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END ..model__alpha=3.5000000000000004;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END ..model__alpha=3.5000000000000004;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END ..model__alpha=3.5000000000000004;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=3.6;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=3.6;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=3.6;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=3.6;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=3.6;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=3.7;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=3.7;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=3.7;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=3.7;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=3.7;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END ..model__alpha=3.8000000000000003;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END ..model__alpha=3.8000000000000003;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END ..model__alpha=3.8000000000000003;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END ..model__alpha=3.8000000000000003;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END ..model__alpha=3.8000000000000003;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END ..model__alpha=3.9000000000000004;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END ..model__alpha=3.9000000000000004;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END ..model__alpha=3.9000000000000004;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END ..model__alpha=3.9000000000000004;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END ..model__alpha=3.9000000000000004;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=4.0;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=4.0;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=4.0;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=4.0;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=4.0;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=4.1;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=4.1;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=4.1;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=4.1;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=4.1;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=4.2;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=4.2;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=4.2;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=4.2;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=4.2;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=4.3;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=4.3;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=4.3;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=4.3;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=4.3;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END ..model__alpha=4.3999999999999995;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END ..model__alpha=4.3999999999999995;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END ..model__alpha=4.3999999999999995;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END ..model__alpha=4.3999999999999995;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END ..model__alpha=4.3999999999999995;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=4.5;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=4.5;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=4.5;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=4.5;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=4.5;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=4.6;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=4.6;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=4.6;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=4.6;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=4.6;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=4.7;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=4.7;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=4.7;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=4.7;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=4.7;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=4.8;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=4.8;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=4.8;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=4.8;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=4.8;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=4.9;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=4.9;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=4.9;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=4.9;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=4.9;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=5.0;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=5.0;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=5.0;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=5.0;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=5.0;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=5.1;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=5.1;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=5.1;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=5.1;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=5.1;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=5.2;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=5.2;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=5.2;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=5.2;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=5.2;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=5.3;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=5.3;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=5.3;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=5.3;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=5.3;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=5.4;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=5.4;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=5.4;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=5.4;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=5.4;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=5.5;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=5.5;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=5.5;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=5.5;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=5.5;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=5.6;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=5.6;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=5.6;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=5.6;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=5.6;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=5.7;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=5.7;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=5.7;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=5.7;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=5.7;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=5.8;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=5.8;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=5.8;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=5.8;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=5.8;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=5.9;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=5.9;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=5.9;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=5.9;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=5.9;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=6.0;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=6.0;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=6.0;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=6.0;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=6.0;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=6.1;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=6.1;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=6.1;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=6.1;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=6.1;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=6.2;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=6.2;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=6.2;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=6.2;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=6.2;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=6.3;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=6.3;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=6.3;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=6.3;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=6.3;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=6.4;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=6.4;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=6.4;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=6.4;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=6.4;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=6.5;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=6.5;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=6.5;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=6.5;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=6.5;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=6.6;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=6.6;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=6.6;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=6.6;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=6.6;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=6.7;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=6.7;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=6.7;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=6.7;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=6.7;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=6.8;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=6.8;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=6.8;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=6.8;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=6.8;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=6.9;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=6.9;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=6.9;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=6.9;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=6.9;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=7.0;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=7.0;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=7.0;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=7.0;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=7.0;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=7.1;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=7.1;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=7.1;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=7.1;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=7.1;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=7.2;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=7.2;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=7.2;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=7.2;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=7.2;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=7.3;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=7.3;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=7.3;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=7.3;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=7.3;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=7.4;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=7.4;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=7.4;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=7.4;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=7.4;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=7.5;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=7.5;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=7.5;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=7.5;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=7.5;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=7.6;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=7.6;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=7.6;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=7.6;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=7.6;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=7.7;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=7.7;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=7.7;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=7.7;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=7.7;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=7.8;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=7.8;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=7.8;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=7.8;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=7.8;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=7.9;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=7.9;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=7.9;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=7.9;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=7.9;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=8.0;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=8.0;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=8.0;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=8.0;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=8.0;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=8.1;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=8.1;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=8.1;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=8.1;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=8.1;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=8.2;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=8.2;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=8.2;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=8.2;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=8.2;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=8.3;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=8.3;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=8.3;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=8.3;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=8.3;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=8.4;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=8.4;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=8.4;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=8.4;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=8.4;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=8.5;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=8.5;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=8.5;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=8.5;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=8.5;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=8.6;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=8.6;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=8.6;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=8.6;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=8.6;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=8.7;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=8.7;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=8.7;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=8.7;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=8.7;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=8.8;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=8.8;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=8.8;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=8.8;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=8.8;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=8.9;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=8.9;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=8.9;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=8.9;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=8.9;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=9.0;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=9.0;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=9.0;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=9.0;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=9.0;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=9.1;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=9.1;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=9.1;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=9.1;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=9.1;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=9.2;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=9.2;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=9.2;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=9.2;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=9.2;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=9.3;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=9.3;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=9.3;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=9.3;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=9.3;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=9.4;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=9.4;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=9.4;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=9.4;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=9.4;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=9.5;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=9.5;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=9.5;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=9.5;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=9.5;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=9.6;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=9.6;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=9.6;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=9.6;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=9.6;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END ...model__alpha=9.700000000000001;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END ...model__alpha=9.700000000000001;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END ...model__alpha=9.700000000000001;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END ...model__alpha=9.700000000000001;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END ...model__alpha=9.700000000000001;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=9.8;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=9.8;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=9.8;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=9.8;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=9.8;, score=-0.145 total time=   0.0s\n",
      "[CV 1/5] END .................model__alpha=9.9;, score=-0.309 total time=   0.0s\n",
      "[CV 2/5] END .................model__alpha=9.9;, score=-0.253 total time=   0.0s\n",
      "[CV 3/5] END .................model__alpha=9.9;, score=-0.253 total time=   0.0s\n",
      "[CV 4/5] END .................model__alpha=9.9;, score=-0.281 total time=   0.0s\n",
      "[CV 5/5] END .................model__alpha=9.9;, score=-0.145 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                                       ('model', Lasso())]),\n",
       "             param_grid={'model__alpha': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. , 1.1, 1.2, 1.3,\n",
       "       1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2. , 2.1, 2.2, 2.3, 2.4, 2.5, 2.6,\n",
       "       2.7, 2.8, 2.9, 3. , 3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 3.9,\n",
       "       4. , 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9, 5. , 5.1, 5.2,\n",
       "       5.3, 5.4, 5.5, 5.6, 5.7, 5.8, 5.9, 6. , 6.1, 6.2, 6.3, 6.4, 6.5,\n",
       "       6.6, 6.7, 6.8, 6.9, 7. , 7.1, 7.2, 7.3, 7.4, 7.5, 7.6, 7.7, 7.8,\n",
       "       7.9, 8. , 8.1, 8.2, 8.3, 8.4, 8.5, 8.6, 8.7, 8.8, 8.9, 9. , 9.1,\n",
       "       9.2, 9.3, 9.4, 9.5, 9.6, 9.7, 9.8, 9.9])},\n",
       "             scoring='neg_mean_squared_error', verbose=3)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(imputed_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_\n",
    "coefficients = search.best_estimator_.named_steps['model'].coef_\n",
    "importance = np.abs(coefficients)\n",
    "importance\n",
    "np.array(feature_names)[importance > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sampling(x_train, y_train, sampler):\n",
    "    \n",
    "    #SMOTE\n",
    "    if sampler == 'SMOTE':\n",
    "        sampler = SMOTE(random_state=100)    \n",
    "    \n",
    "    #ROSE\n",
    "    if sampler == 'ROSE':\n",
    "        sampler = RandomOverSampler(random_state=100, shrinkage=1)\n",
    "\n",
    "    #ADASYN\n",
    "    if sampler == 'ADASYN':\n",
    "        sampler = ADASYN(random_state=100)\n",
    "    \n",
    "\n",
    "    #SMOTTEENN\n",
    "    if sampler == 'SMOTEENN' :\n",
    "        sampler = SMOTEENN(random_state=100)\n",
    "        \n",
    "        \n",
    "    #Random under Sampling\n",
    "    if sampler == \"randomunder\":\n",
    "        sampler = RandomUnderSampler(random_state=100)\n",
    "\n",
    "    X_resampled, y_resampled = sampler.fit_resample(x_train, y_train)\n",
    "    counter = Counter(y_resampled)\n",
    "    print(counter)\n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({-1: 1170, 1: 1170})\n"
     ]
    }
   ],
   "source": [
    "# Imbalance treatment\n",
    "X_resampled, y_resampled = Sampling(X_train, y_train,'SMOTE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      -1\n",
       "1      -1\n",
       "2      -1\n",
       "3      -1\n",
       "4      -1\n",
       "       ..\n",
       "2335    1\n",
       "2336    1\n",
       "2337    1\n",
       "2338    1\n",
       "2339    1\n",
       "Name: status, Length: 2340, dtype: int64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#descriptive analysis\n",
    "def eda(df,output):\n",
    "    #output={}\n",
    "    for col in df.columns:\n",
    "        mean=df[col].mean()\n",
    "        std= df[col].std()\n",
    "        percent_null= pd.isnull(df[col]).sum()/len(df[col])*100\n",
    "        unique=len(pd.unique(df[col]))\n",
    "        outlier_df3= df[(np.abs(stats.zscore(df[col])) > 3)]\n",
    "        outlier_df2= df[(np.abs(stats.zscore(df[col])) > 2)]\n",
    "        count_3s_perc=len(outlier_df3)*100/len(df)\n",
    "        count_2s_perc=(len(outlier_df2)-len(outlier_df3))*100/len(df)\n",
    "        min= df[col].min()\n",
    "        q25=df[col].quantile(0.25)\n",
    "        q50=df[col].quantile(0.5)\n",
    "        q75=df[col].quantile(0.75)\n",
    "        max= df[col].max()\n",
    "        skewness=df[col].skew()\n",
    "        kurtosis=df[col].kurtosis()\n",
    "        list = []\n",
    "        list.append(mean)\n",
    "        list.append(std)\n",
    "        list.append(percent_null)\n",
    "        list.append(unique)\n",
    "        list.append(count_3s_perc)\n",
    "        list.append(count_2s_perc)\n",
    "        list.append(min)\n",
    "        list.append(q25)\n",
    "        list.append(q50)\n",
    "        list.append(q75)\n",
    "        list.append(max)\n",
    "        list.append(skewness)\n",
    "        list.append(kurtosis)\n",
    "        output[col] = list\n",
    "    return output;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing_Records</th>\n",
       "      <th>Percentage (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feature294</th>\n",
       "      <td>285</td>\n",
       "      <td>90.764331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature293</th>\n",
       "      <td>285</td>\n",
       "      <td>90.764331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature159</th>\n",
       "      <td>285</td>\n",
       "      <td>90.764331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature158</th>\n",
       "      <td>285</td>\n",
       "      <td>90.764331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature493</th>\n",
       "      <td>269</td>\n",
       "      <td>85.668790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature283</th>\n",
       "      <td>1</td>\n",
       "      <td>0.318471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature284</th>\n",
       "      <td>1</td>\n",
       "      <td>0.318471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature285</th>\n",
       "      <td>1</td>\n",
       "      <td>0.318471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.318471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature286</th>\n",
       "      <td>1</td>\n",
       "      <td>0.318471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>446 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Missing_Records  Percentage (%)\n",
       "feature294              285       90.764331\n",
       "feature293              285       90.764331\n",
       "feature159              285       90.764331\n",
       "feature158              285       90.764331\n",
       "feature493              269       85.668790\n",
       "...                     ...             ...\n",
       "feature283                1        0.318471\n",
       "feature284                1        0.318471\n",
       "feature285                1        0.318471\n",
       "feature2                  1        0.318471\n",
       "feature286                1        0.318471\n",
       "\n",
       "[446 rows x 2 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_na = null_values(x_test)\n",
    "x_test_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing_Records</th>\n",
       "      <th>Percentage (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feature294</th>\n",
       "      <td>285</td>\n",
       "      <td>90.764331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature293</th>\n",
       "      <td>285</td>\n",
       "      <td>90.764331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature159</th>\n",
       "      <td>285</td>\n",
       "      <td>90.764331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature158</th>\n",
       "      <td>285</td>\n",
       "      <td>90.764331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature493</th>\n",
       "      <td>269</td>\n",
       "      <td>85.668790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature359</th>\n",
       "      <td>269</td>\n",
       "      <td>85.668790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature221</th>\n",
       "      <td>269</td>\n",
       "      <td>85.668790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature86</th>\n",
       "      <td>269</td>\n",
       "      <td>85.668790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Missing_Records  Percentage (%)\n",
       "feature294              285       90.764331\n",
       "feature293              285       90.764331\n",
       "feature159              285       90.764331\n",
       "feature158              285       90.764331\n",
       "feature493              269       85.668790\n",
       "feature359              269       85.668790\n",
       "feature221              269       85.668790\n",
       "feature86               269       85.668790"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_na= x_test_na[x_test_na[\"Percentage (%)\"] > 80]\n",
    "x_test_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(314, 582)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_new = x_test.drop(axis=1, columns=x_test_na.index)\n",
    "x_test_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>percent_null</th>\n",
       "      <th>unique</th>\n",
       "      <th>count_3s</th>\n",
       "      <th>count_2s</th>\n",
       "      <th>min</th>\n",
       "      <th>q25</th>\n",
       "      <th>q50</th>\n",
       "      <th>q75</th>\n",
       "      <th>max</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feature1</th>\n",
       "      <td>3015.805399</td>\n",
       "      <td>72.695332</td>\n",
       "      <td>0.318471</td>\n",
       "      <td>314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2787.4900</td>\n",
       "      <td>2968.330000</td>\n",
       "      <td>3011.84000</td>\n",
       "      <td>3057.56000</td>\n",
       "      <td>3266.5500</td>\n",
       "      <td>0.392153</td>\n",
       "      <td>1.009080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature2</th>\n",
       "      <td>2493.657604</td>\n",
       "      <td>85.188422</td>\n",
       "      <td>0.318471</td>\n",
       "      <td>310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2158.7500</td>\n",
       "      <td>2452.280000</td>\n",
       "      <td>2492.81000</td>\n",
       "      <td>2535.71000</td>\n",
       "      <td>2809.7900</td>\n",
       "      <td>-0.007244</td>\n",
       "      <td>2.102846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature3</th>\n",
       "      <td>2201.873688</td>\n",
       "      <td>27.746567</td>\n",
       "      <td>1.273885</td>\n",
       "      <td>228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2117.5889</td>\n",
       "      <td>2183.449975</td>\n",
       "      <td>2201.35000</td>\n",
       "      <td>2218.42775</td>\n",
       "      <td>2315.2667</td>\n",
       "      <td>0.161078</td>\n",
       "      <td>0.825308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature4</th>\n",
       "      <td>1402.265403</td>\n",
       "      <td>462.104127</td>\n",
       "      <td>1.273885</td>\n",
       "      <td>228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>847.7976</td>\n",
       "      <td>1079.924825</td>\n",
       "      <td>1287.88445</td>\n",
       "      <td>1586.94760</td>\n",
       "      <td>3619.7397</td>\n",
       "      <td>2.058669</td>\n",
       "      <td>6.184798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature5</th>\n",
       "      <td>4.912465</td>\n",
       "      <td>63.092033</td>\n",
       "      <td>1.273885</td>\n",
       "      <td>227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.7217</td>\n",
       "      <td>1.020325</td>\n",
       "      <td>1.30010</td>\n",
       "      <td>1.52960</td>\n",
       "      <td>1112.1600</td>\n",
       "      <td>17.605908</td>\n",
       "      <td>309.978581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature586</th>\n",
       "      <td>3.001342</td>\n",
       "      <td>1.035471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>314</td>\n",
       "      <td>2.229299</td>\n",
       "      <td>0.955414</td>\n",
       "      <td>1.4716</td>\n",
       "      <td>2.323425</td>\n",
       "      <td>2.79330</td>\n",
       "      <td>3.43675</td>\n",
       "      <td>8.8160</td>\n",
       "      <td>2.166765</td>\n",
       "      <td>7.755072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature587</th>\n",
       "      <td>0.021208</td>\n",
       "      <td>0.012121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>177</td>\n",
       "      <td>0.955414</td>\n",
       "      <td>4.458599</td>\n",
       "      <td>-0.0169</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.01995</td>\n",
       "      <td>0.02750</td>\n",
       "      <td>0.0831</td>\n",
       "      <td>0.863569</td>\n",
       "      <td>3.426609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature588</th>\n",
       "      <td>0.016996</td>\n",
       "      <td>0.009225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>153</td>\n",
       "      <td>1.273885</td>\n",
       "      <td>2.866242</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.01500</td>\n",
       "      <td>0.02120</td>\n",
       "      <td>0.0651</td>\n",
       "      <td>1.485789</td>\n",
       "      <td>3.590882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature589</th>\n",
       "      <td>0.005425</td>\n",
       "      <td>0.002935</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>87</td>\n",
       "      <td>1.592357</td>\n",
       "      <td>3.184713</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>0.00675</td>\n",
       "      <td>0.0212</td>\n",
       "      <td>1.639023</td>\n",
       "      <td>4.481107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature590</th>\n",
       "      <td>103.871311</td>\n",
       "      <td>99.739517</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>231</td>\n",
       "      <td>2.866242</td>\n",
       "      <td>2.866242</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>44.135650</td>\n",
       "      <td>74.56785</td>\n",
       "      <td>116.10880</td>\n",
       "      <td>579.1817</td>\n",
       "      <td>2.405960</td>\n",
       "      <td>6.309187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>582 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   mean         std  percent_null  unique  count_3s  count_2s  \\\n",
       "feature1    3015.805399   72.695332      0.318471     314  0.000000  0.000000   \n",
       "feature2    2493.657604   85.188422      0.318471     310  0.000000  0.000000   \n",
       "feature3    2201.873688   27.746567      1.273885     228  0.000000  0.000000   \n",
       "feature4    1402.265403  462.104127      1.273885     228  0.000000  0.000000   \n",
       "feature5       4.912465   63.092033      1.273885     227  0.000000  0.000000   \n",
       "...                 ...         ...           ...     ...       ...       ...   \n",
       "feature586     3.001342    1.035471      0.000000     314  2.229299  0.955414   \n",
       "feature587     0.021208    0.012121      0.000000     177  0.955414  4.458599   \n",
       "feature588     0.016996    0.009225      0.000000     153  1.273885  2.866242   \n",
       "feature589     0.005425    0.002935      0.000000      87  1.592357  3.184713   \n",
       "feature590   103.871311   99.739517      0.000000     231  2.866242  2.866242   \n",
       "\n",
       "                  min          q25         q50         q75        max  \\\n",
       "feature1    2787.4900  2968.330000  3011.84000  3057.56000  3266.5500   \n",
       "feature2    2158.7500  2452.280000  2492.81000  2535.71000  2809.7900   \n",
       "feature3    2117.5889  2183.449975  2201.35000  2218.42775  2315.2667   \n",
       "feature4     847.7976  1079.924825  1287.88445  1586.94760  3619.7397   \n",
       "feature5       0.7217     1.020325     1.30010     1.52960  1112.1600   \n",
       "...               ...          ...         ...         ...        ...   \n",
       "feature586     1.4716     2.323425     2.79330     3.43675     8.8160   \n",
       "feature587    -0.0169     0.014000     0.01995     0.02750     0.0831   \n",
       "feature588     0.0032     0.010400     0.01500     0.02120     0.0651   \n",
       "feature589     0.0010     0.003300     0.00485     0.00675     0.0212   \n",
       "feature590     0.0000    44.135650    74.56785   116.10880   579.1817   \n",
       "\n",
       "             skewness    kurtosis  \n",
       "feature1     0.392153    1.009080  \n",
       "feature2    -0.007244    2.102846  \n",
       "feature3     0.161078    0.825308  \n",
       "feature4     2.058669    6.184798  \n",
       "feature5    17.605908  309.978581  \n",
       "...               ...         ...  \n",
       "feature586   2.166765    7.755072  \n",
       "feature587   0.863569    3.426609  \n",
       "feature588   1.485789    3.590882  \n",
       "feature589   1.639023    4.481107  \n",
       "feature590   2.405960    6.309187  \n",
       "\n",
       "[582 rows x 13 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_new\n",
    "##proceeding with only training data \n",
    "#analysis of volatility and null values of training data \n",
    "#xtrain_desc = x_train.describe()\n",
    "x_test_new_eda={}\n",
    "x_test_new_eda=eda(x_test_new,x_test_new_eda)\n",
    "x_test_new_eda1=pd.DataFrame.from_dict(x_test_new_eda,orient='index')\n",
    "x_test_new_eda1.columns=['mean','std', 'percent_null', 'unique', 'count_3s', 'count_2s', 'min', 'q25', 'q50', 'q75', 'max','skewness','kurtosis']\n",
    "#Percent_null of features before split \n",
    "#sns.histplot(data=result1, x='percent_null',bins=20, kde=True)\n",
    "x_test_new_eda1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>percent_null</th>\n",
       "      <th>unique</th>\n",
       "      <th>count_3s</th>\n",
       "      <th>count_2s</th>\n",
       "      <th>min</th>\n",
       "      <th>q25</th>\n",
       "      <th>q50</th>\n",
       "      <th>q75</th>\n",
       "      <th>max</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feature6</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.273885</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.318471</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature43</th>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.318471</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature50</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.318471</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature53</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.318471</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature535</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.955414</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature536</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.955414</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature537</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.955414</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature538</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.955414</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature539</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.955414</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             mean  std  percent_null  unique  count_3s  count_2s    min  \\\n",
       "feature6    100.0  0.0      1.273885       2       0.0       0.0  100.0   \n",
       "feature14     0.0  0.0      0.318471       2       0.0       0.0    0.0   \n",
       "feature43    70.0  0.0      0.318471       2       0.0       0.0   70.0   \n",
       "feature50     1.0  0.0      0.318471       2       0.0       0.0    1.0   \n",
       "feature53     0.0  0.0      0.318471       2       0.0       0.0    0.0   \n",
       "...           ...  ...           ...     ...       ...       ...    ...   \n",
       "feature535    0.0  0.0      0.955414       2       0.0       0.0    0.0   \n",
       "feature536    0.0  0.0      0.955414       2       0.0       0.0    0.0   \n",
       "feature537    0.0  0.0      0.955414       2       0.0       0.0    0.0   \n",
       "feature538    0.0  0.0      0.955414       2       0.0       0.0    0.0   \n",
       "feature539    0.0  0.0      0.955414       2       0.0       0.0    0.0   \n",
       "\n",
       "              q25    q50    q75    max  skewness  kurtosis  \n",
       "feature6    100.0  100.0  100.0  100.0       0.0       0.0  \n",
       "feature14     0.0    0.0    0.0    0.0       0.0       0.0  \n",
       "feature43    70.0   70.0   70.0   70.0       0.0       0.0  \n",
       "feature50     1.0    1.0    1.0    1.0       0.0       0.0  \n",
       "feature53     0.0    0.0    0.0    0.0       0.0       0.0  \n",
       "...           ...    ...    ...    ...       ...       ...  \n",
       "feature535    0.0    0.0    0.0    0.0       0.0       0.0  \n",
       "feature536    0.0    0.0    0.0    0.0       0.0       0.0  \n",
       "feature537    0.0    0.0    0.0    0.0       0.0       0.0  \n",
       "feature538    0.0    0.0    0.0    0.0       0.0       0.0  \n",
       "feature539    0.0    0.0    0.0    0.0       0.0       0.0  \n",
       "\n",
       "[122 rows x 13 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_new_eda1[x_test_new_eda1['std']==0]\n",
    "x_test_new_std= x_test_new_eda1[x_test_new_eda1[\"std\"] == 0]\n",
    "x_test_new_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(314, 460)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_new_2 = x_test_new.drop(axis=1, columns=x_test_new_std.index)\n",
    "x_test_new_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_3s=x_test_new_2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "zscore(x_test_3s,x_test_3s.columns,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 460 features, but KNNImputer is expecting 466 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15180/3324883694.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimputed_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_3s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_test_3s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\impute\\_knn.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    243\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m             \u001b[0mforce_all_finite\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"allow-nan\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m         X = self._validate_data(\n\u001b[0m\u001b[0;32m    246\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ensure_2d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    401\u001b[0m                 \u001b[1;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m                 \u001b[1;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X has 460 features, but KNNImputer is expecting 466 features as input."
     ]
    }
   ],
   "source": [
    "imputed_test = pd.DataFrame(knn.transform(x_test_3s), columns = x_test_3s.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(X, y,X_test,y_test):\n",
    "    rf_boruta = RandomForestClassifier(random_state=1, n_estimators=1000, max_depth=5)\n",
    "    rf_boruta.fit(X,y)\n",
    "    y_predicted_test= rf_boruta.predict(X_test)\n",
    "    score1= accuracy_score(y_test, y_predicted_test)\n",
    "    return score1\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

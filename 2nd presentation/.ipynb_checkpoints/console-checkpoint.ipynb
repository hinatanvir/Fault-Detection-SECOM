{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READ ME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook is implemeted in a repository in github with input and output folders.\n",
    "#### It has 2 parts:\n",
    "##### > Part 1: Pre-defined funtions for each technique.\n",
    "##### > Part 2: Execution of model pipelines, here users can modify which combination of techniques they want to run. The scores will be printed as a csv in output folders. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1: FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #importing libraries\n",
    "# import csv\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.impute import KNNImputer\n",
    "# from sklearn.experimental import enable_iterative_imputer\n",
    "# from sklearn.impute import IterativeImputer\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# from boruta import BorutaPy\n",
    "# from BorutaShap import BorutaShap\n",
    "# from sklearn.feature_selection import RFE\n",
    "\n",
    "# from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "# from imblearn.combine import SMOTEENN\n",
    "\n",
    "# from collections import Counter\n",
    "# from sklearn.svm import SVC\n",
    "\n",
    "# from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, f1_score, precision_score, recall_score, roc_auc_score, log_loss, cohen_kappa_score\n",
    "\n",
    "# import keras\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.utils import to_categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function is to read, transform and join 2 data frame\n",
    "\n",
    "def read_features():\n",
    "    path = 'input/secom.data'\n",
    "    df = pd.read_csv(path, delimiter=' ', header=None, na_values=['NaN'])\n",
    "    df.columns = ['feature_'+str(x+1) for x in range(len(df.columns))]\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def read_target():\n",
    "    path = 'input/secom_labels.data'\n",
    "    df = pd.read_csv(path, delimiter=' ', header=None, na_values=['NaN'])\n",
    "    df.columns = ['status','timestamp']\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'],dayfirst=True)\n",
    "    return df\n",
    "\n",
    "#for the testing purporse, trim to remain first 100 rows only\n",
    "X = read_features()\n",
    "y = read_target().iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove duplicated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the duplicated features (columns)\n",
    "def remove_duplicated_columns(df):\n",
    "    dict_duplicate_pair = {}\n",
    "    dict_duplicate_matches = {}\n",
    "    list_duplicate = []\n",
    "    to_remove = []\n",
    "    for i in range(0, len(df.columns)):\n",
    "        l = []\n",
    "        for j in range(i+1,len(df.columns)):\n",
    "            dict_duplicate_pair[str(i+1)+';'+str(j+1)] = df.iloc[:,i].equals(df.iloc[:,j])\n",
    "            if df.iloc[:,i].equals(df.iloc[:,j]) == True:\n",
    "                if j not in list_duplicate:\n",
    "                    l.append(j)\n",
    "                    to_remove.append('feature_'+str(j+1))\n",
    "                list_duplicate.append(i)\n",
    "                list_duplicate.append(j)\n",
    "        if len(l)!=0:\n",
    "            dict_duplicate_matches[i] = l\n",
    "\n",
    "\n",
    "    df_duplicate_pair = pd.DataFrame.from_dict(dict_duplicate_pair, orient='index')\n",
    "    df_duplicate_pair.columns=['duplicate']\n",
    "\n",
    "    df_duplicate_matches = pd.DataFrame.from_dict(dict_duplicate_matches, orient='index')\n",
    "\n",
    "    \n",
    "    df = df.drop(columns=to_remove, axis = 1)\n",
    "\n",
    "    return df\n",
    "\n",
    "# X = remove_duplicated_columns(X)\n",
    "# X.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove columns with Constant volatility (std=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_constant_volatility(df):\n",
    "    df_EDA= df.describe().T\n",
    "    df_EDA= df_EDA[df_EDA[\"std\"] == 0]\n",
    "    df = df.drop(axis=1, columns=df_EDA.index)\n",
    "    return df\n",
    "\n",
    "# X = remove_constant_volatility(X)\n",
    "# X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove columns with high %Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_cols_with_high_pct_null(df, null_threshold):\n",
    "    list_column_with_pct_null = pd.concat([df.isnull().sum(), df.isnull().sum()/df.shape[0]],axis=1).rename(columns={0:'Missing_Records', 1:'Percentage (%)'})\n",
    "    list_column_with_pct_null= list_column_with_pct_null[list_column_with_pct_null[\"Percentage (%)\"] >= null_threshold]\n",
    "    df = df.drop(axis=1, columns=list_column_with_pct_null.index)\n",
    "    return df\n",
    "\n",
    "# X = remove_cols_with_high_pct_null(X, 0.8)\n",
    "# X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how = ['NaN', '3s' ,'nothing']\n",
    "def replace_outlier(df, how):\n",
    "    for col in df:\n",
    "        ll_col = df[col].mean() - 3 * df[col].std()\n",
    "        ul_col = df[col].mean() + 3 * df[col].std()\n",
    "        if how == 'NaN':\n",
    "            df[col] = np.where(df[col]>ul_col,np.NaN,np.where(df[col]<ll_col,np.NaN,df[col]))\n",
    "        elif how == '3s':\n",
    "            df[col] = np.where(df[col]>ul_col,ul_col,np.where(df[col]<ll_col,ll_col,df[col]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing value Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#which_weights = ['distance','uniform']\n",
    "\n",
    "def impute_null_with_knn(X_train, X_test, which_weights):\n",
    "    #First scale the data \n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = pd.DataFrame(scaler.fit_transform(X_train), columns= X_train.columns)\n",
    "    X_test = pd.DataFrame(scaler.transform(X_test), columns= X_test.columns)\n",
    "\n",
    "    knn = KNNImputer(n_neighbors=5, weights=which_weights) #check this neighbors = 5\n",
    "\n",
    "    X_train = pd.DataFrame(knn.fit_transform(X_train), columns=X_train.columns)\n",
    "    X_test = pd.DataFrame(knn.transform(X_test), columns=X_test.columns)\n",
    "    \n",
    "    X_train = pd.DataFrame(scaler.inverse_transform(X_train), columns= X_train.columns)\n",
    "    X_test = pd.DataFrame(scaler.inverse_transform(X_test), columns= X_test.columns)\n",
    "    return X_train, X_test\n",
    "\n",
    "#X_train = impute_null_with_knn(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_null_with_mice(X_train, X_test): \n",
    "    imp = IterativeImputer(max_iter=5, verbose=0, imputation_order='roman', random_state=0)\n",
    "    X_train = pd.DataFrame(imp.fit_transform(X_train), columns=X_train.columns)\n",
    "    X_test = pd.DataFrame(imp.transform(X_test), columns=X_test.columns)\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is BorutaShap with TENTATIVE features\n",
    "\n",
    "#list_method=['shap','gini']\n",
    "\n",
    "def BorutaShap_FS (X, y,method_option) :\n",
    "    #modelshap = RandomForestClassifier(n_jobs=-1,n_estimators=100, class_weight='balanced_subsample', max_depth=5, random_state=100)\n",
    "    modelshap = RandomForestClassifier(n_jobs=-1,n_estimators=100, max_depth=5, random_state=100)\n",
    "\n",
    "    # define model for resp. classifier\n",
    "    modelshap.fit(X,y)\n",
    "    feature_names = np.array(X.columns)\n",
    "    # define Boruta Sahp feature selection method\n",
    "    feature_selector = BorutaShap(model=modelshap,\n",
    "                              importance_measure=method_option,\n",
    "                              classification=True)  # find all relevant features\n",
    "    feature_selector.fit(X,y,n_trials=100,sample = False, verbose = False,random_state=100)  \n",
    "    #feature_selector.plot(which_features='accepted',figsize=(20,10))\n",
    "    tentative=X.loc[:,feature_selector.tentative]\n",
    "    selected=feature_selector.Subset()\n",
    "    selten=pd.concat([selected,tentative],axis=1)\n",
    "    # call transform() on X to filter it down to selected features\n",
    "    return  selten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFE\n",
    "\n",
    "#classifier = ['RF', 'SVM']\n",
    "\n",
    "def RFE_FS (X, y,classify) :\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled= pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "    feature_names = np.array(X_scaled.columns)\n",
    "    if classify == 'RF':\n",
    "    # define random forest classifier\n",
    "        model = RandomForestClassifier(n_jobs=-1, class_weight='balanced_subsample', max_depth=5, random_state=100)\n",
    "       \n",
    "    if classify== 'SVM':\n",
    "        model = SVC(kernel='linear',C=5)\n",
    "        #rfe = RFECV(estimator = model,scoring='accuracy')\n",
    "    # find all relevant features\n",
    "    model.fit(X_scaled, y)\n",
    "    rfe = RFE(estimator = model,n_features_to_select = 30)\n",
    "    rfe.fit(X_scaled,y)\n",
    "\n",
    "     # zip feature names, ranks, and decisions \n",
    "    feature_ranks = list(zip(feature_names, \n",
    "                             rfe.ranking_, \n",
    "                             rfe.support_))\n",
    "\n",
    "    final_features_rfe = list()\n",
    "    indexes = np.where(rfe.ranking_ <= 2)\n",
    "    for x in np.nditer(indexes):\n",
    "        final_features_rfe.append(feature_names[x])\n",
    "    \n",
    "    \n",
    "    # unscale the data before return\n",
    "    X_unscaled=pd.DataFrame(scaler.inverse_transform(X_scaled), columns=X_scaled.columns)\n",
    "    ff_rfe=pd.DataFrame(X_unscaled.filter(final_features_rfe))\n",
    "    \n",
    "\n",
    " # call transform() on X to filter it down to selected features\n",
    "    return  ff_rfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boruta function with random forest\n",
    "\n",
    "def BorutaPy_FS (X, y) :\n",
    "    feature_names = np.array(X.columns)\n",
    "\n",
    "    # define random forest classifier\n",
    "    model = RandomForestClassifier(n_jobs=-1, class_weight='balanced_subsample', max_depth=5, random_state=100)\n",
    "    model.fit(X, y)\n",
    "    # define Boruta feature selection method\n",
    "    \n",
    "    feature_selector = BorutaPy(model, n_estimators='auto', verbose=0, random_state=100, max_iter=140)\n",
    "\n",
    "    # find all relevant features\n",
    "    feature_selector.fit(X.to_numpy(),y)\n",
    "\n",
    "    # check selected features\n",
    "    ##--feature_selector.support_\n",
    "\n",
    "    # check ranking of features\n",
    "    ##--feature_ranking=feature_selector.ranking_\n",
    "\n",
    "    # zip feature names, ranks, and decisions \n",
    "    # feature_ranks = list(zip(feature_names, \n",
    "    #                          feature_selector.ranking_, \n",
    "    #                          feature_selector.support_))\n",
    "\n",
    "    # print the results\n",
    "    ##--for feat in feature_ranks:\n",
    "    ##--    print('Feature: {:<30} Rank: {},  Keep: {}'.format(feat[0], feat[1], feat[2]))\n",
    "        \n",
    "    final_features = list()\n",
    "    indexes = np.where(feature_selector.ranking_ <= 2) #change to 2\n",
    "    for x in np.nditer(indexes):\n",
    "        final_features.append(feature_names[x])\n",
    "    ##--print(final_features)\n",
    "    \n",
    " # call transform() on X to filter it down to selected features\n",
    "    return pd.DataFrame(X.filter(final_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multicolinearity treatement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the highly collinear features from data\n",
    "def remove_collinear_features(x, threshold):\n",
    "    '''\n",
    "    Objective:\n",
    "        Remove collinear features in a dataframe with a correlation coefficient\n",
    "        greater than the threshold. Removing collinear features can help a model \n",
    "        to generalize and improves the interpretability of the model.\n",
    "\n",
    "    Inputs: \n",
    "        x: features dataframe\n",
    "        threshold: features with correlations greater than this value are removed\n",
    "\n",
    "    Output: \n",
    "        dataframe that contains only the non-highly-collinear features\n",
    "    '''\n",
    "\n",
    "    # Calculate the correlation matrix\n",
    "    corr_matrix = x.corr()\n",
    "    iters = range(len(corr_matrix.columns) - 1)\n",
    "    drop_cols = []\n",
    "\n",
    "    # Iterate through the correlation matrix and compare correlations\n",
    "    for i in iters:\n",
    "        for j in range(i+1):\n",
    "            item = corr_matrix.iloc[j:(j+1), (i+1):(i+2)]\n",
    "            col = item.columns\n",
    "            row = item.index\n",
    "            val = abs(item.values)\n",
    "\n",
    "            # If correlation exceeds the threshold\n",
    "            if val >= threshold:\n",
    "                #Print the correlated features and the correlation value\n",
    "                #print(col.values[0], \"|\", row.values[0], \"|\", round(val[0][0], 2))\n",
    "                drop_cols.append(col.values[0])\n",
    "\n",
    "    # Drop one of each pair of correlated columns\n",
    "    drops = set(drop_cols)\n",
    "    x = x.drop(columns=drops)\n",
    "\n",
    "    return x\n",
    "\n",
    "#remove_collinear_features(X, 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(X_train, y_train, sampler):\n",
    "    \n",
    "    #SMOTE\n",
    "    if sampler == 'SMOTE':\n",
    "        sampler = SMOTE(random_state=100)    \n",
    "    \n",
    "    #ROSE\n",
    "    if sampler == 'ROSE':\n",
    "        sampler = RandomOverSampler(random_state=100, shrinkage=1)\n",
    "\n",
    "    #ADASYN\n",
    "    if sampler == 'ADASYN':\n",
    "        sampler = ADASYN(random_state=100)\n",
    "    \n",
    "\n",
    "    #SMOTTEENN\n",
    "    if sampler == 'SMOTEENN' :\n",
    "        sampler = SMOTEENN(random_state=100)\n",
    "        \n",
    "        \n",
    "    #Random under Sampling\n",
    "    if sampler == \"randomunder\":\n",
    "        sampler = RandomUnderSampler(random_state=100)\n",
    "\n",
    "    X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)\n",
    "    #counter = Counter(y_resampled)\n",
    "    #print(counter)\n",
    "    \n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "# X_train, y_train = sampling(X_train, y_train,'SMOTE')\n",
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model: Random Forest & Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_model = ['RF', 'LR']\n",
    "\n",
    "def run_model(X_train, y_train, X_test, y_test, which_model):\n",
    "\n",
    "    if which_model == 'RF':\n",
    "    # building model before balancing data\n",
    "        model = RandomForestClassifier(random_state=1, n_estimators=1000, max_depth=5) ###############\n",
    "    elif which_model == 'LR':\n",
    "        model = LogisticRegression(random_state=1)\n",
    "    \n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "    #For TEST SPLIT\n",
    "    y_pred= model.predict(X_test)\n",
    "    cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    accuracy= accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred) ##\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    sensitivity = cf_matrix[1][1] / ( cf_matrix[1][1] + cf_matrix[1][0] )\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    type_1_error_FP = cf_matrix[1][0]\n",
    "    type_2_error_FN = cf_matrix[0][1]\n",
    "    log_loss_ = log_loss(y_test, y_pred)\n",
    "    cohen_kappa_score_ = cohen_kappa_score(y_test, y_pred)\n",
    "    #Note by default 1 is the positive label. Therefore, -1 is negative\n",
    "    #bad waffe -> 2 line of matrix -> POSITIVE -> data = -1\n",
    "\n",
    "    #For TRAIN SPLIT\n",
    "    y_pred_train= model.predict(X_train)\n",
    "    cf_matrix_train = confusion_matrix(y_train, y_pred_train)\n",
    "    accuracy_train= accuracy_score(y_train, y_pred_train)\n",
    "    f1_train = f1_score(y_train, y_pred_train) ##\n",
    "    precision_train = precision_score(y_train, y_pred_train)\n",
    "    recall_train = recall_score(y_train, y_pred_train)\n",
    "    sensitivity_train = cf_matrix_train[1][1] / ( cf_matrix_train[1][1] + cf_matrix_train[1][0] )\n",
    "    auc_train = roc_auc_score(y_train, y_pred_train)\n",
    "    type_1_error_FP_train = cf_matrix_train[1][0]\n",
    "    type_2_error_FN_train = cf_matrix_train[0][1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return cf_matrix, accuracy, f1, precision, recall, sensitivity, type_1_error_FP, type_2_error_FN, auc,log_loss_,cohen_kappa_score_, cf_matrix_train, accuracy_train, f1_train, precision_train, recall_train, sensitivity_train, type_1_error_FP_train, type_2_error_FN_train, auc_train\n",
    "\n",
    "#run_model(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model: Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NN\n",
    "\n",
    "\n",
    "def run_model_NN(X_train, y_train, X_test, y_test):\n",
    "    y_train = y_train.replace(-1, 0) #to_cat cannot work with negative numbers\n",
    "    y_test = y_test.replace(-1, 0)\n",
    "\n",
    "    input_dim = X_train.shape[1]\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dense(35, activation='relu'))\n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(5, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    # one hot encode outputs\n",
    "    y_train_c = to_categorical(y_train)\n",
    "    y_test_c = to_categorical(y_test)\n",
    "\n",
    "\n",
    "    model.fit(X_train, y_train_c, epochs=10, batch_size=50, verbose=2)\n",
    "\n",
    "\n",
    "    #For TEST SPLIT\n",
    "    y_pred = model.predict(X_test)\n",
    "    #Converting predictions to label\n",
    "    pred = list()\n",
    "    for i in range(len(y_pred)):\n",
    "        pred.append(np.argmax(y_pred[i]))\n",
    "\n",
    "    #Converting one hot encoded test label to label\n",
    "    test = list()\n",
    "    for i in range(len(y_test_c)):\n",
    "        test.append(np.argmax(y_test_c[i]))\n",
    "\n",
    "\n",
    "    cf_matrix = confusion_matrix(test, pred)\n",
    "    accuracy= accuracy_score(test, pred)\n",
    "    f1 = f1_score(test, pred) ##\n",
    "    precision = precision_score(test, pred)\n",
    "    recall = recall_score(test, pred)\n",
    "    sensitivity = cf_matrix[1][1] / ( cf_matrix[1][1] + cf_matrix[1][0] ) #change from specificity -> sensitivity\n",
    "    auc = roc_auc_score(test, pred)\n",
    "    type_1_error_FP = cf_matrix[1][0]\n",
    "    type_2_error_FN = cf_matrix[0][1]\n",
    "    log_loss_ = log_loss(test, pred)\n",
    "    cohen_kappa_score_ = cohen_kappa_score(test, pred)\n",
    "    #Note by default 1 is the positive label. Therefore, -1 is negative\n",
    "    #bad waffe -> 2 line of matrix -> POSITIVE -> data = -1\n",
    "\n",
    "\n",
    "    #For TRAIN SPLIT\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    #Converting predictions to label\n",
    "    pred_train = list()\n",
    "    for i in range(len(y_pred_train)): \n",
    "        pred_train.append(np.argmax(y_pred_train[i]))\n",
    "\n",
    "    #Converting one hot encoded test label to label\n",
    "    train_ = list()\n",
    "    for i in range(len(y_train_c)):\n",
    "        train_.append(np.argmax(y_train_c[i]))\n",
    "\n",
    "    y_pred_train= model.predict(X_train)\n",
    "    cf_matrix_train = confusion_matrix(train_, pred_train)\n",
    "    accuracy_train= accuracy_score(train_, pred_train)\n",
    "    f1_train = f1_score(train_, pred_train) ##\n",
    "    precision_train = precision_score(train_, pred_train)\n",
    "    recall_train = recall_score(train_, pred_train)\n",
    "    sensitivity_train = cf_matrix_train[1][1] / ( cf_matrix_train[1][1] + cf_matrix_train[1][0] )\n",
    "    auc_train = roc_auc_score(train_, pred_train)\n",
    "    type_1_error_FP_train = cf_matrix_train[1][0]\n",
    "    type_2_error_FN_train = cf_matrix_train[0][1]\n",
    "\n",
    "\n",
    "    return cf_matrix, accuracy, f1, precision, recall, sensitivity, type_1_error_FP, type_2_error_FN, auc,log_loss_,cohen_kappa_score_, cf_matrix_train, accuracy_train, f1_train, precision_train, recall_train, sensitivity_train, type_1_error_FP_train, type_2_error_FN_train, auc_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2: EXECUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(466,)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fast_track_cols = X_test.columns\n",
    "# fast_track_cols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:17<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_cols BEFORE multicolinearity treatement 12\n",
      "n_cols AFTER multicolinearity treatement 10\n",
      "Epoch 1/10\n",
      "35/35 - 1s - loss: 17.7861 - accuracy: 0.4246 - 668ms/epoch - 19ms/step\n",
      "Epoch 2/10\n",
      "35/35 - 0s - loss: 1.1715 - accuracy: 0.4246 - 45ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "35/35 - 0s - loss: 0.7834 - accuracy: 0.4246 - 46ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "35/35 - 0s - loss: 0.6976 - accuracy: 0.4509 - 47ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "35/35 - 0s - loss: 0.6704 - accuracy: 0.6005 - 43ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "35/35 - 0s - loss: 0.6635 - accuracy: 0.6688 - 43ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "35/35 - 0s - loss: 0.6615 - accuracy: 0.6525 - 47ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "35/35 - 0s - loss: 0.6248 - accuracy: 0.7132 - 85ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "35/35 - 0s - loss: 0.5941 - accuracy: 0.7085 - 74ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "35/35 - 0s - loss: 0.5613 - accuracy: 0.7021 - 72ms/epoch - 2ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "54/54 [==============================] - 0s 1ms/step\n",
      "54/54 [==============================] - 0s 1ms/step\n",
      "attemp no.:  1 NaN & knn__uniform & BoS__shap & SMOTEENN & NN  acc:  0.8630573248407644  accuracy_train:  0.7167056074766355  f1:  0.3384615384615385  f1_train:  0.6974422956955708  sensitivity:  0.5238095238095238  :auc  0.7055907687307004  cfm:  \n",
      " [[260  33]\n",
      " [ 10  11]] \n",
      " n_cols 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:16<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_cols BEFORE multicolinearity treatement 12\n",
      "n_cols AFTER multicolinearity treatement 11\n",
      "Epoch 1/10\n",
      "47/47 - 1s - loss: 0.9406 - accuracy: 0.4972 - 629ms/epoch - 13ms/step\n",
      "Epoch 2/10\n",
      "47/47 - 0s - loss: 0.6946 - accuracy: 0.4972 - 76ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "47/47 - 0s - loss: 0.6905 - accuracy: 0.5333 - 73ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "47/47 - 0s - loss: 0.6883 - accuracy: 0.6029 - 69ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "47/47 - 0s - loss: 0.6850 - accuracy: 0.5930 - 68ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "47/47 - 0s - loss: 0.6733 - accuracy: 0.6115 - 88ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "47/47 - 0s - loss: 0.6553 - accuracy: 0.6180 - 138ms/epoch - 3ms/step\n",
      "Epoch 8/10\n",
      "47/47 - 0s - loss: 0.6527 - accuracy: 0.6235 - 76ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "47/47 - 0s - loss: 0.6462 - accuracy: 0.6296 - 68ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "47/47 - 0s - loss: 0.6442 - accuracy: 0.6291 - 68ms/epoch - 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "73/73 [==============================] - 0s 925us/step\n",
      "73/73 [==============================] - 0s 967us/step\n",
      "attemp no.:  2 NaN & knn__uniform & BoS__shap & ADASYN & NN  acc:  0.7420382165605095  accuracy_train:  0.6377309840996992  f1:  0.24299065420560745  f1_train:  0.5901798736023336  sensitivity:  0.6190476190476191  :auc  0.6849504306842191  cfm:  \n",
      " [[220  73]\n",
      " [  8  13]] \n",
      " n_cols 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:22<00:00,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_cols BEFORE multicolinearity treatement 7\n",
      "n_cols AFTER multicolinearity treatement 6\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 - 1s - loss: 0.7055 - accuracy: 0.5855 - 639ms/epoch - 14ms/step\n",
      "Epoch 2/10\n",
      "47/47 - 0s - loss: 0.6447 - accuracy: 0.6325 - 77ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "47/47 - 0s - loss: 0.6390 - accuracy: 0.6256 - 57ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "47/47 - 0s - loss: 0.6353 - accuracy: 0.6274 - 59ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "47/47 - 0s - loss: 0.6324 - accuracy: 0.6333 - 60ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "47/47 - 0s - loss: 0.6288 - accuracy: 0.6231 - 69ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "47/47 - 0s - loss: 0.6287 - accuracy: 0.6321 - 55ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "47/47 - 0s - loss: 0.6255 - accuracy: 0.6248 - 72ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "47/47 - 0s - loss: 0.6207 - accuracy: 0.6291 - 60ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "47/47 - 0s - loss: 0.6156 - accuracy: 0.6295 - 72ms/epoch - 2ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "74/74 [==============================] - 0s 978us/step\n",
      "74/74 [==============================] - 0s 917us/step\n",
      "attemp no.:  3 NaN & knn__uniform & BoS__shap & SMOTE & NN  acc:  0.8439490445859873  accuracy_train:  0.6222222222222222  f1:  0.28985507246376807  f1_train:  0.5126791620727674  sensitivity:  0.47619047619047616  :auc  0.6732488217129856  cfm:  \n",
      " [[255  38]\n",
      " [ 11  10]] \n",
      " n_cols 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:21<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_cols BEFORE multicolinearity treatement 10\n",
      "n_cols AFTER multicolinearity treatement 8\n",
      "Epoch 1/10\n",
      "47/47 - 1s - loss: 11.0913 - accuracy: 0.5205 - 652ms/epoch - 14ms/step\n",
      "Epoch 2/10\n",
      "47/47 - 0s - loss: 0.8134 - accuracy: 0.4966 - 59ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "47/47 - 0s - loss: 0.7260 - accuracy: 0.5094 - 56ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "47/47 - 0s - loss: 0.7232 - accuracy: 0.5201 - 67ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "47/47 - 0s - loss: 0.7474 - accuracy: 0.5299 - 73ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "47/47 - 0s - loss: 0.6815 - accuracy: 0.5538 - 64ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "47/47 - 0s - loss: 0.7190 - accuracy: 0.5615 - 65ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "47/47 - 0s - loss: 0.7254 - accuracy: 0.5500 - 82ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "47/47 - 0s - loss: 0.7315 - accuracy: 0.5803 - 58ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "47/47 - 0s - loss: 0.7814 - accuracy: 0.5534 - 58ms/epoch - 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "74/74 [==============================] - 0s 1ms/step\n",
      "74/74 [==============================] - 0s 1ms/step\n",
      "attemp no.:  4 NaN & knn__uniform & BoS__shap & ROSE & NN  acc:  0.1910828025477707  accuracy_train:  0.5192307692307693  f1:  0.13013698630136986  f1_train:  0.6515949210281822  sensitivity:  0.9047619047619048  :auc  0.5223468226881196  cfm:  \n",
      " [[ 41 252]\n",
      " [  2  19]] \n",
      " n_cols 8\n",
      "n_cols BEFORE multicolinearity treatement 31\n",
      "n_cols AFTER multicolinearity treatement 25\n",
      "Epoch 1/10\n",
      "37/37 - 1s - loss: 12.7800 - accuracy: 0.4853 - 734ms/epoch - 20ms/step\n",
      "Epoch 2/10\n",
      "37/37 - 0s - loss: 2.6908 - accuracy: 0.4918 - 60ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "37/37 - 0s - loss: 1.7916 - accuracy: 0.5420 - 66ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "37/37 - 0s - loss: 1.2717 - accuracy: 0.5632 - 61ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "37/37 - 0s - loss: 1.2137 - accuracy: 0.5605 - 56ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "37/37 - 0s - loss: 1.7908 - accuracy: 0.5491 - 53ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "37/37 - 0s - loss: 2.1018 - accuracy: 0.5147 - 56ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "37/37 - 0s - loss: 2.9128 - accuracy: 0.5463 - 51ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "37/37 - 0s - loss: 2.7438 - accuracy: 0.5540 - 52ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "37/37 - 0s - loss: 1.2033 - accuracy: 0.5921 - 50ms/epoch - 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "58/58 [==============================] - 0s 1ms/step\n",
      "58/58 [==============================] - 0s 2ms/step\n",
      "attemp no.:  5 NaN & knn__uniform & RFE__RF & SMOTEENN & NN  acc:  0.910828025477707  accuracy_train:  0.47546346782988  f1:  0.17647058823529413  f1_train:  0.21661237785016288  sensitivity:  0.14285714285714285  :auc  0.5543637250121891  cfm:  \n",
      " [[283  10]\n",
      " [ 18   3]] \n",
      " n_cols 25\n",
      "n_cols BEFORE multicolinearity treatement 31\n",
      "n_cols AFTER multicolinearity treatement 23\n",
      "Epoch 1/10\n",
      "47/47 - 1s - loss: 25.5784 - accuracy: 0.5097 - 592ms/epoch - 13ms/step\n",
      "Epoch 2/10\n",
      "47/47 - 0s - loss: 4.3659 - accuracy: 0.5282 - 75ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "47/47 - 0s - loss: 4.1239 - accuracy: 0.5235 - 67ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "47/47 - 0s - loss: 1.6544 - accuracy: 0.5606 - 71ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "47/47 - 0s - loss: 1.3246 - accuracy: 0.5640 - 64ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "47/47 - 0s - loss: 1.7775 - accuracy: 0.5464 - 60ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "47/47 - 0s - loss: 1.4557 - accuracy: 0.5649 - 83ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "47/47 - 0s - loss: 1.0613 - accuracy: 0.5787 - 73ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "47/47 - 0s - loss: 1.1416 - accuracy: 0.5533 - 75ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "47/47 - 0s - loss: 1.2302 - accuracy: 0.5640 - 66ms/epoch - 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "73/73 [==============================] - 0s 951us/step\n",
      "73/73 [==============================] - 0s 1ms/step\n",
      "attemp no.:  6 NaN & knn__uniform & RFE__RF & ADASYN & NN  acc:  0.8343949044585988  accuracy_train:  0.6127641224665804  f1:  0.2571428571428572  f1_train:  0.4596871239470517  sensitivity:  0.42857142857142855  :auc  0.6460263286201853  cfm:  \n",
      " [[253  40]\n",
      " [ 12   9]] \n",
      " n_cols 23\n",
      "n_cols BEFORE multicolinearity treatement 31\n",
      "n_cols AFTER multicolinearity treatement 25\n",
      "Epoch 1/10\n",
      "47/47 - 1s - loss: 29.0365 - accuracy: 0.4816 - 622ms/epoch - 13ms/step\n",
      "Epoch 2/10\n",
      "47/47 - 0s - loss: 1.3763 - accuracy: 0.5085 - 78ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "47/47 - 0s - loss: 1.7133 - accuracy: 0.5098 - 76ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "47/47 - 0s - loss: 1.6921 - accuracy: 0.5085 - 83ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "47/47 - 0s - loss: 1.1155 - accuracy: 0.5171 - 131ms/epoch - 3ms/step\n",
      "Epoch 6/10\n",
      "47/47 - 0s - loss: 1.0300 - accuracy: 0.5256 - 108ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "47/47 - 0s - loss: 0.9537 - accuracy: 0.5346 - 89ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "47/47 - 0s - loss: 1.0835 - accuracy: 0.5372 - 101ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "47/47 - 0s - loss: 0.9204 - accuracy: 0.5432 - 85ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "47/47 - 0s - loss: 0.9197 - accuracy: 0.5543 - 88ms/epoch - 2ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "74/74 [==============================] - 0s 3ms/step\n",
      "74/74 [==============================] - 0s 1ms/step\n",
      "attemp no.:  7 NaN & knn__uniform & RFE__RF & SMOTE & NN  acc:  0.39171974522292996  accuracy_train:  0.6205128205128205  f1:  0.15859030837004406  f1_train:  0.6925207756232687  sensitivity:  0.8571428571428571  :auc  0.6077523159434421  cfm:  \n",
      " [[105 188]\n",
      " [  3  18]] \n",
      " n_cols 25\n",
      "n_cols BEFORE multicolinearity treatement 31\n",
      "n_cols AFTER multicolinearity treatement 25\n",
      "Epoch 1/10\n",
      "47/47 - 1s - loss: 6.9907 - accuracy: 0.4983 - 784ms/epoch - 17ms/step\n",
      "Epoch 2/10\n",
      "47/47 - 0s - loss: 0.9081 - accuracy: 0.5504 - 74ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "47/47 - 0s - loss: 0.7822 - accuracy: 0.5650 - 66ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "47/47 - 0s - loss: 0.9065 - accuracy: 0.5547 - 65ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "47/47 - 0s - loss: 0.9333 - accuracy: 0.5628 - 60ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "47/47 - 0s - loss: 0.8107 - accuracy: 0.5842 - 62ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "47/47 - 0s - loss: 0.8104 - accuracy: 0.5684 - 90ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "47/47 - 0s - loss: 0.6853 - accuracy: 0.6197 - 87ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "47/47 - 0s - loss: 0.8913 - accuracy: 0.5598 - 87ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "47/47 - 0s - loss: 0.7005 - accuracy: 0.6094 - 83ms/epoch - 2ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "74/74 [==============================] - 0s 1ms/step\n",
      "74/74 [==============================] - 0s 1ms/step\n",
      "attemp no.:  8 NaN & knn__uniform & RFE__RF & ROSE & NN  acc:  0.07006369426751592  accuracy_train:  0.5017094017094017  f1:  0.12574850299401197  f1_train:  0.6651349798966111  sensitivity:  1.0  :auc  0.5017064846416383  cfm:  \n",
      " [[  1 292]\n",
      " [  0  21]] \n",
      " n_cols 25\n",
      "n_cols BEFORE multicolinearity treatement 466\n",
      "n_cols AFTER multicolinearity treatement 240\n",
      "Epoch 1/10\n",
      "35/35 - 1s - loss: 56.2460 - accuracy: 0.5955 - 620ms/epoch - 18ms/step\n",
      "Epoch 2/10\n",
      "35/35 - 0s - loss: 5.2331 - accuracy: 0.6493 - 77ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "35/35 - 0s - loss: 3.6912 - accuracy: 0.6672 - 64ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "35/35 - 0s - loss: 2.7348 - accuracy: 0.6927 - 65ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "35/35 - 0s - loss: 2.3154 - accuracy: 0.6962 - 64ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "35/35 - 0s - loss: 1.9615 - accuracy: 0.7176 - 63ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "35/35 - 0s - loss: 1.4824 - accuracy: 0.7413 - 53ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "35/35 - 0s - loss: 1.3989 - accuracy: 0.7575 - 53ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "35/35 - 0s - loss: 1.3588 - accuracy: 0.7425 - 61ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "35/35 - 0s - loss: 1.3129 - accuracy: 0.7824 - 67ms/epoch - 2ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "54/54 [==============================] - 0s 1ms/step\n",
      "attemp no.:  9 NaN & knn__uniform & nothing & SMOTEENN & NN  acc:  0.6687898089171974  accuracy_train:  0.6452546296296297  f1:  0.11864406779661016  f1_train:  0.6832041343669251  sensitivity:  0.3333333333333333  :auc  0.5130830489192264  cfm:  \n",
      " [[203  90]\n",
      " [ 14   7]] \n",
      " n_cols 240\n",
      "n_cols BEFORE multicolinearity treatement 466\n",
      "n_cols AFTER multicolinearity treatement 240\n",
      "Epoch 1/10\n",
      "48/48 - 1s - loss: 2.1588 - accuracy: 0.5225 - 564ms/epoch - 12ms/step\n",
      "Epoch 2/10\n",
      "48/48 - 0s - loss: 0.6931 - accuracy: 0.5042 - 78ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "48/48 - 0s - loss: 0.6932 - accuracy: 0.5042 - 66ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "48/48 - 0s - loss: 0.6931 - accuracy: 0.5042 - 66ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "48/48 - 0s - loss: 0.6932 - accuracy: 0.5042 - 71ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "48/48 - 0s - loss: 0.6931 - accuracy: 0.5042 - 67ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "48/48 - 0s - loss: 0.6931 - accuracy: 0.5042 - 77ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "48/48 - 0s - loss: 0.6932 - accuracy: 0.5042 - 80ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "48/48 - 0s - loss: 0.6932 - accuracy: 0.5042 - 71ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "48/48 - 0s - loss: 0.6931 - accuracy: 0.5042 - 67ms/epoch - 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "74/74 [==============================] - 0s 988us/step\n",
      "74/74 [==============================] - 0s 937us/step\n",
      "attemp no.:  10 NaN & knn__uniform & nothing & ADASYN & NN  acc:  0.06687898089171974  accuracy_train:  0.5042372881355932  f1:  0.1253731343283582  f1_train:  0.6704225352112676  sensitivity:  1.0  :auc  0.5  cfm:  \n",
      " [[  0 293]\n",
      " [  0  21]] \n",
      " n_cols 240\n",
      "n_cols BEFORE multicolinearity treatement 466\n",
      "n_cols AFTER multicolinearity treatement 240\n",
      "Epoch 1/10\n",
      "47/47 - 1s - loss: 26.0844 - accuracy: 0.5167 - 557ms/epoch - 12ms/step\n",
      "Epoch 2/10\n",
      "47/47 - 0s - loss: 0.6902 - accuracy: 0.5047 - 77ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "47/47 - 0s - loss: 0.6890 - accuracy: 0.5060 - 67ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "47/47 - 0s - loss: 0.7014 - accuracy: 0.5043 - 64ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "47/47 - 0s - loss: 0.6932 - accuracy: 0.5000 - 68ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "47/47 - 0s - loss: 0.6932 - accuracy: 0.5000 - 78ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "47/47 - 0s - loss: 0.6932 - accuracy: 0.5000 - 74ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "47/47 - 0s - loss: 0.6932 - accuracy: 0.5000 - 89ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "47/47 - 0s - loss: 0.6932 - accuracy: 0.5000 - 68ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "47/47 - 0s - loss: 0.6932 - accuracy: 0.5000 - 72ms/epoch - 2ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "74/74 [==============================] - 0s 944us/step\n",
      "74/74 [==============================] - 0s 927us/step\n",
      "attemp no.:  11 NaN & knn__uniform & nothing & SMOTE & NN  acc:  0.06687898089171974  accuracy_train:  0.5  f1:  0.1253731343283582  f1_train:  0.6666666666666666  sensitivity:  1.0  :auc  0.5  cfm:  \n",
      " [[  0 293]\n",
      " [  0  21]] \n",
      " n_cols 240\n",
      "n_cols BEFORE multicolinearity treatement 466\n",
      "n_cols AFTER multicolinearity treatement 240\n",
      "Epoch 1/10\n",
      "47/47 - 1s - loss: 14.4006 - accuracy: 0.5620 - 610ms/epoch - 13ms/step\n",
      "Epoch 2/10\n",
      "47/47 - 0s - loss: 3.7165 - accuracy: 0.6278 - 77ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "47/47 - 0s - loss: 2.6414 - accuracy: 0.6581 - 89ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "47/47 - 0s - loss: 1.8607 - accuracy: 0.6974 - 72ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "47/47 - 0s - loss: 1.6470 - accuracy: 0.6966 - 69ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "47/47 - 0s - loss: 1.1860 - accuracy: 0.7291 - 68ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "47/47 - 0s - loss: 1.0214 - accuracy: 0.7470 - 79ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "47/47 - 0s - loss: 0.9497 - accuracy: 0.7479 - 79ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "47/47 - 0s - loss: 0.8535 - accuracy: 0.7615 - 80ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "47/47 - 0s - loss: 0.7042 - accuracy: 0.7675 - 82ms/epoch - 2ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "74/74 [==============================] - 0s 1ms/step\n",
      "74/74 [==============================] - 0s 1ms/step\n",
      "attemp no.:  12 NaN & knn__uniform & nothing & ROSE & NN  acc:  0.6592356687898089  accuracy_train:  0.7811965811965812  f1:  0.11570247933884298  f1_train:  0.7903357903357904  sensitivity:  0.3333333333333333  :auc  0.5079635949943117  cfm:  \n",
      " [[200  93]\n",
      " [ 14   7]] \n",
      " n_cols 240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:18<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_cols BEFORE multicolinearity treatement 7\n",
      "n_cols AFTER multicolinearity treatement 5\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 - 1s - loss: 0.7079 - accuracy: 0.5802 - 583ms/epoch - 16ms/step\n",
      "Epoch 2/10\n",
      "36/36 - 0s - loss: 0.6460 - accuracy: 0.5802 - 51ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "36/36 - 0s - loss: 0.6436 - accuracy: 0.5950 - 51ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "36/36 - 0s - loss: 0.6395 - accuracy: 0.5762 - 45ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "36/36 - 0s - loss: 0.6387 - accuracy: 0.5853 - 47ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "36/36 - 0s - loss: 0.6312 - accuracy: 0.5865 - 55ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "36/36 - 0s - loss: 0.6322 - accuracy: 0.6030 - 50ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "36/36 - 0s - loss: 0.6305 - accuracy: 0.6013 - 52ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "36/36 - 0s - loss: 0.6434 - accuracy: 0.5796 - 49ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "36/36 - 0s - loss: 0.6361 - accuracy: 0.6092 - 50ms/epoch - 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "55/55 [==============================] - 0s 1ms/step\n",
      "55/55 [==============================] - 0s 1ms/step\n",
      "attemp no.:  13 nothing & knn__uniform & BoS__shap & SMOTEENN & NN  acc:  0.06687898089171974  accuracy_train:  0.5813424345847554  f1:  0.1253731343283582  f1_train:  0.7348703170028819  sensitivity:  1.0  :auc  0.5  cfm:  \n",
      " [[  0 293]\n",
      " [  0  21]] \n",
      " n_cols 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:18<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_cols BEFORE multicolinearity treatement 7\n",
      "n_cols AFTER multicolinearity treatement 5\n",
      "Epoch 1/10\n",
      "48/48 - 1s - loss: 0.6939 - accuracy: 0.5110 - 561ms/epoch - 12ms/step\n",
      "Epoch 2/10\n",
      "48/48 - 0s - loss: 0.6863 - accuracy: 0.5363 - 66ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "48/48 - 0s - loss: 0.6853 - accuracy: 0.5465 - 63ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "48/48 - 0s - loss: 0.6803 - accuracy: 0.5562 - 60ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "48/48 - 0s - loss: 0.6826 - accuracy: 0.5410 - 63ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "48/48 - 0s - loss: 0.6797 - accuracy: 0.5465 - 74ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "48/48 - 0s - loss: 0.6788 - accuracy: 0.5435 - 142ms/epoch - 3ms/step\n",
      "Epoch 8/10\n",
      "48/48 - 0s - loss: 0.6809 - accuracy: 0.5427 - 69ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "48/48 - 0s - loss: 0.6776 - accuracy: 0.5406 - 70ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "48/48 - 0s - loss: 0.6737 - accuracy: 0.5490 - 71ms/epoch - 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "74/74 [==============================] - 0s 1ms/step\n",
      "74/74 [==============================] - 0s 892us/step\n",
      "attemp no.:  14 nothing & knn__uniform & BoS__shap & ADASYN & NN  acc:  0.856687898089172  accuracy_train:  0.5494505494505495  f1:  0.2105263157894737  f1_train:  0.31225806451612903  sensitivity:  0.2857142857142857  :auc  0.591662603607996  cfm:  \n",
      " [[263  30]\n",
      " [ 15   6]] \n",
      " n_cols 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:19<00:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_cols BEFORE multicolinearity treatement 7\n",
      "n_cols AFTER multicolinearity treatement 5\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 - 1s - loss: 0.7079 - accuracy: 0.5026 - 579ms/epoch - 12ms/step\n",
      "Epoch 2/10\n",
      "47/47 - 0s - loss: 0.6823 - accuracy: 0.5551 - 95ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "47/47 - 0s - loss: 0.6797 - accuracy: 0.5628 - 66ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "47/47 - 0s - loss: 0.6755 - accuracy: 0.5714 - 64ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "47/47 - 0s - loss: 0.6736 - accuracy: 0.5530 - 68ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "47/47 - 0s - loss: 0.6746 - accuracy: 0.5585 - 65ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "47/47 - 0s - loss: 0.6720 - accuracy: 0.5679 - 60ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "47/47 - 0s - loss: 0.6765 - accuracy: 0.5483 - 69ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "47/47 - 0s - loss: 0.6713 - accuracy: 0.5714 - 61ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "47/47 - 0s - loss: 0.6713 - accuracy: 0.5551 - 66ms/epoch - 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "74/74 [==============================] - 0s 988us/step\n",
      "74/74 [==============================] - 0s 958us/step\n",
      "attemp no.:  15 nothing & knn__uniform & BoS__shap & SMOTE & NN  acc:  0.8057324840764332  accuracy_train:  0.5547008547008547  f1:  0.1643835616438356  f1_train:  0.37753882915173237  sensitivity:  0.2857142857142857  :auc  0.5643588493417844  cfm:  \n",
      " [[247  46]\n",
      " [ 15   6]] \n",
      " n_cols 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:19<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_cols BEFORE multicolinearity treatement 7\n",
      "n_cols AFTER multicolinearity treatement 5\n",
      "Epoch 1/10\n",
      "47/47 - 1s - loss: 0.6885 - accuracy: 0.5526 - 682ms/epoch - 15ms/step\n",
      "Epoch 2/10\n",
      "47/47 - 0s - loss: 0.6787 - accuracy: 0.5594 - 76ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "47/47 - 0s - loss: 0.6758 - accuracy: 0.5568 - 83ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "47/47 - 0s - loss: 0.6737 - accuracy: 0.5692 - 82ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "47/47 - 0s - loss: 0.6730 - accuracy: 0.5735 - 78ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "47/47 - 0s - loss: 0.6706 - accuracy: 0.5697 - 74ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "47/47 - 0s - loss: 0.6653 - accuracy: 0.5876 - 67ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "47/47 - 0s - loss: 0.6652 - accuracy: 0.5769 - 63ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "47/47 - 0s - loss: 0.6631 - accuracy: 0.5850 - 60ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "47/47 - 0s - loss: 0.6578 - accuracy: 0.5949 - 65ms/epoch - 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "74/74 [==============================] - 0s 1ms/step\n",
      "74/74 [==============================] - 0s 2ms/step\n",
      "attemp no.:  16 nothing & knn__uniform & BoS__shap & ROSE & NN  acc:  0.8375796178343949  accuracy_train:  0.614957264957265  f1:  0.19047619047619047  f1_train:  0.47093364650616565  sensitivity:  0.2857142857142857  :auc  0.5814236957581667  cfm:  \n",
      " [[257  36]\n",
      " [ 15   6]] \n",
      " n_cols 5\n",
      "n_cols BEFORE multicolinearity treatement 31\n",
      "n_cols AFTER multicolinearity treatement 27\n",
      "Epoch 1/10\n",
      "33/33 - 1s - loss: 301.7317 - accuracy: 0.5291 - 575ms/epoch - 17ms/step\n",
      "Epoch 2/10\n",
      "33/33 - 0s - loss: 0.6974 - accuracy: 0.4114 - 47ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "33/33 - 0s - loss: 0.6951 - accuracy: 0.4114 - 45ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "33/33 - 0s - loss: 0.6926 - accuracy: 0.5291 - 51ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "33/33 - 0s - loss: 0.6901 - accuracy: 0.5886 - 55ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "33/33 - 0s - loss: 0.6879 - accuracy: 0.5886 - 53ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "33/33 - 0s - loss: 0.6859 - accuracy: 0.5886 - 48ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "33/33 - 0s - loss: 0.6843 - accuracy: 0.5886 - 52ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "33/33 - 0s - loss: 0.6829 - accuracy: 0.5886 - 54ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "33/33 - 0s - loss: 0.6817 - accuracy: 0.5886 - 59ms/epoch - 2ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "52/52 [==============================] - 0s 959us/step\n",
      "52/52 [==============================] - 0s 967us/step\n",
      "attemp no.:  17 nothing & knn__uniform & RFE__RF & SMOTEENN & NN  acc:  0.06687898089171974  accuracy_train:  0.5885922330097088  f1:  0.1253731343283582  f1_train:  0.7410236822001528  sensitivity:  1.0  :auc  0.5  cfm:  \n",
      " [[  0 293]\n",
      " [  0  21]] \n",
      " n_cols 27\n",
      "n_cols BEFORE multicolinearity treatement 31\n",
      "n_cols AFTER multicolinearity treatement 27\n",
      "Epoch 1/10\n",
      "47/47 - 1s - loss: 63.0853 - accuracy: 0.4772 - 640ms/epoch - 14ms/step\n",
      "Epoch 2/10\n",
      "47/47 - 0s - loss: 1.9935 - accuracy: 0.4674 - 61ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "47/47 - 0s - loss: 0.8784 - accuracy: 0.4897 - 64ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "47/47 - 0s - loss: 0.8054 - accuracy: 0.5198 - 70ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "47/47 - 0s - loss: 0.7953 - accuracy: 0.5077 - 60ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "47/47 - 0s - loss: 0.7446 - accuracy: 0.5275 - 62ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "47/47 - 0s - loss: 0.7479 - accuracy: 0.5309 - 82ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "47/47 - 0s - loss: 0.7833 - accuracy: 0.5107 - 61ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "47/47 - 0s - loss: 0.7561 - accuracy: 0.5253 - 58ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "47/47 - 0s - loss: 0.7358 - accuracy: 0.5318 - 65ms/epoch - 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "73/73 [==============================] - 0s 1ms/step\n",
      "73/73 [==============================] - 0s 910us/step\n",
      "attemp no.:  18 nothing & knn__uniform & RFE__RF & ADASYN & NN  acc:  0.07643312101910828  accuracy_train:  0.5055841924398625  f1:  0.12650602409638556  f1_train:  0.6680126910873954  sensitivity:  1.0  :auc  0.5051194539249146  cfm:  \n",
      " [[  3 290]\n",
      " [  0  21]] \n",
      " n_cols 27\n",
      "n_cols BEFORE multicolinearity treatement 31\n",
      "n_cols AFTER multicolinearity treatement 27\n",
      "Epoch 1/10\n",
      "47/47 - 1s - loss: 98.2581 - accuracy: 0.4944 - 655ms/epoch - 14ms/step\n",
      "Epoch 2/10\n",
      "47/47 - 0s - loss: 2.4093 - accuracy: 0.5175 - 63ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "47/47 - 0s - loss: 1.9695 - accuracy: 0.5299 - 58ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "47/47 - 0s - loss: 1.8393 - accuracy: 0.5030 - 71ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "47/47 - 0s - loss: 1.5233 - accuracy: 0.5158 - 69ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "47/47 - 0s - loss: 1.2324 - accuracy: 0.5205 - 80ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "47/47 - 0s - loss: 1.1850 - accuracy: 0.5214 - 73ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "47/47 - 0s - loss: 1.1317 - accuracy: 0.5338 - 64ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "47/47 - 0s - loss: 1.1924 - accuracy: 0.5432 - 72ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "47/47 - 0s - loss: 1.0871 - accuracy: 0.5406 - 142ms/epoch - 3ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "74/74 [==============================] - 0s 2ms/step\n",
      "74/74 [==============================] - 0s 1ms/step\n",
      "attemp no.:  19 nothing & knn__uniform & RFE__RF & SMOTE & NN  acc:  0.5  accuracy_train:  0.520940170940171  f1:  0.1513513513513514  f1_train:  0.5350476980506014  sensitivity:  0.6666666666666666  :auc  0.5773606370875995  cfm:  \n",
      " [[143 150]\n",
      " [  7  14]] \n",
      " n_cols 27\n",
      "n_cols BEFORE multicolinearity treatement 31\n",
      "n_cols AFTER multicolinearity treatement 27\n",
      "Epoch 1/10\n",
      "47/47 - 1s - loss: 57.1569 - accuracy: 0.5034 - 593ms/epoch - 13ms/step\n",
      "Epoch 2/10\n",
      "47/47 - 0s - loss: 0.8566 - accuracy: 0.5120 - 69ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "47/47 - 0s - loss: 0.8329 - accuracy: 0.4979 - 68ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "47/47 - 0s - loss: 0.8198 - accuracy: 0.5222 - 68ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "47/47 - 0s - loss: 0.8920 - accuracy: 0.5154 - 70ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "47/47 - 0s - loss: 0.8977 - accuracy: 0.5350 - 70ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "47/47 - 0s - loss: 0.8620 - accuracy: 0.5137 - 215ms/epoch - 5ms/step\n",
      "Epoch 8/10\n",
      "47/47 - 0s - loss: 0.7777 - accuracy: 0.5491 - 105ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "47/47 - 0s - loss: 0.7588 - accuracy: 0.5274 - 97ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "47/47 - 0s - loss: 0.8469 - accuracy: 0.5385 - 82ms/epoch - 2ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "74/74 [==============================] - 0s 1ms/step\n",
      "74/74 [==============================] - 0s 1ms/step\n",
      "attemp no.:  20 nothing & knn__uniform & RFE__RF & ROSE & NN  acc:  0.06687898089171974  accuracy_train:  0.5  f1:  0.1253731343283582  f1_train:  0.6666666666666666  sensitivity:  1.0  :auc  0.5  cfm:  \n",
      " [[  0 293]\n",
      " [  0  21]] \n",
      " n_cols 27\n",
      "n_cols BEFORE multicolinearity treatement 466\n",
      "n_cols AFTER multicolinearity treatement 240\n",
      "Epoch 1/10\n",
      "35/35 - 1s - loss: 6.4773 - accuracy: 0.5660 - 567ms/epoch - 16ms/step\n",
      "Epoch 2/10\n",
      "35/35 - 0s - loss: 0.7894 - accuracy: 0.6897 - 59ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "35/35 - 0s - loss: 0.6596 - accuracy: 0.6927 - 59ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "35/35 - 0s - loss: 0.6454 - accuracy: 0.6938 - 59ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "35/35 - 0s - loss: 0.6358 - accuracy: 0.6944 - 58ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "35/35 - 0s - loss: 0.6279 - accuracy: 0.6956 - 59ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "35/35 - 0s - loss: 0.6224 - accuracy: 0.6962 - 59ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "35/35 - 0s - loss: 0.6177 - accuracy: 0.6968 - 59ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "35/35 - 0s - loss: 0.6196 - accuracy: 0.6915 - 73ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "35/35 - 0s - loss: 0.6150 - accuracy: 0.6944 - 83ms/epoch - 2ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "54/54 [==============================] - 0s 1ms/step\n",
      "54/54 [==============================] - 0s 1ms/step\n",
      "attemp no.:  21 nothing & knn__uniform & nothing & SMOTEENN & NN  acc:  0.11146496815286625  accuracy_train:  0.6956011730205278  f1:  0.13084112149532712  f1_train:  0.8166725538678912  sensitivity:  1.0  :auc  0.5238907849829352  cfm:  \n",
      " [[ 14 279]\n",
      " [  0  21]] \n",
      " n_cols 240\n",
      "n_cols BEFORE multicolinearity treatement 466\n",
      "n_cols AFTER multicolinearity treatement 240\n",
      "Epoch 1/10\n",
      "48/48 - 1s - loss: 2.2895 - accuracy: 0.4981 - 627ms/epoch - 13ms/step\n",
      "Epoch 2/10\n",
      "48/48 - 0s - loss: 0.6934 - accuracy: 0.4951 - 76ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "48/48 - 0s - loss: 0.6933 - accuracy: 0.4951 - 86ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "48/48 - 0s - loss: 0.6932 - accuracy: 0.4846 - 79ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "48/48 - 0s - loss: 0.6932 - accuracy: 0.5049 - 78ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "48/48 - 0s - loss: 0.6932 - accuracy: 0.4837 - 76ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "48/48 - 0s - loss: 0.6932 - accuracy: 0.5049 - 76ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "48/48 - 0s - loss: 0.6931 - accuracy: 0.5049 - 76ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "48/48 - 0s - loss: 0.6932 - accuracy: 0.5049 - 75ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "48/48 - 0s - loss: 0.6931 - accuracy: 0.5049 - 78ms/epoch - 2ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "74/74 [==============================] - 0s 1ms/step\n",
      "74/74 [==============================] - 0s 1ms/step\n",
      "attemp no.:  22 nothing & knn__uniform & nothing & ADASYN & NN  acc:  0.06687898089171974  accuracy_train:  0.5048666948793906  f1:  0.1253731343283582  f1_train:  0.670978627671541  sensitivity:  1.0  :auc  0.5  cfm:  \n",
      " [[  0 293]\n",
      " [  0  21]] \n",
      " n_cols 240\n",
      "n_cols BEFORE multicolinearity treatement 466\n",
      "n_cols AFTER multicolinearity treatement 240\n",
      "Epoch 1/10\n",
      "47/47 - 1s - loss: 2.6800 - accuracy: 0.4996 - 663ms/epoch - 14ms/step\n",
      "Epoch 2/10\n",
      "47/47 - 0s - loss: 0.7446 - accuracy: 0.4885 - 80ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "47/47 - 0s - loss: 0.7355 - accuracy: 0.4974 - 84ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "47/47 - 0s - loss: 0.6928 - accuracy: 0.5107 - 78ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "47/47 - 0s - loss: 0.6979 - accuracy: 0.5197 - 79ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "47/47 - 0s - loss: 0.7117 - accuracy: 0.5128 - 74ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "47/47 - 0s - loss: 0.7003 - accuracy: 0.5235 - 75ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "47/47 - 0s - loss: 0.7028 - accuracy: 0.5222 - 78ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "47/47 - 0s - loss: 0.7080 - accuracy: 0.5081 - 80ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "47/47 - 0s - loss: 0.7018 - accuracy: 0.4944 - 82ms/epoch - 2ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "74/74 [==============================] - 0s 1ms/step\n",
      "74/74 [==============================] - 0s 1ms/step\n",
      "attemp no.:  23 nothing & knn__uniform & nothing & SMOTE & NN  acc:  0.9331210191082803  accuracy_train:  0.5  f1:  0.0  f1_train:  0.0  sensitivity:  0.0  :auc  0.5  cfm:  \n",
      " [[293   0]\n",
      " [ 21   0]] \n",
      " n_cols 240\n",
      "n_cols BEFORE multicolinearity treatement 466\n",
      "n_cols AFTER multicolinearity treatement 240\n",
      "Epoch 1/10\n",
      "47/47 - 1s - loss: 5.5484 - accuracy: 0.5051 - 673ms/epoch - 14ms/step\n",
      "Epoch 2/10\n",
      "47/47 - 0s - loss: 0.6936 - accuracy: 0.5043 - 93ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "47/47 - 0s - loss: 0.6936 - accuracy: 0.5004 - 91ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "47/47 - 0s - loss: 0.6929 - accuracy: 0.5004 - 95ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "47/47 - 0s - loss: 0.6928 - accuracy: 0.5004 - 100ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "47/47 - 0s - loss: 0.6928 - accuracy: 0.5004 - 105ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "47/47 - 0s - loss: 0.6928 - accuracy: 0.4872 - 96ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "47/47 - 0s - loss: 0.6928 - accuracy: 0.4944 - 101ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "47/47 - 0s - loss: 0.6928 - accuracy: 0.5026 - 100ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "47/47 - 0s - loss: 0.6958 - accuracy: 0.5004 - 100ms/epoch - 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "74/74 [==============================] - 0s 2ms/step\n",
      "74/74 [==============================] - 0s 2ms/step\n",
      "attemp no.:  24 nothing & knn__uniform & nothing & ROSE & NN  acc:  0.9331210191082803  accuracy_train:  0.5  f1:  0.0  f1_train:  0.0  sensitivity:  0.0  :auc  0.5  cfm:  \n",
      " [[293   0]\n",
      " [ 21   0]] \n",
      " n_cols 240\n"
     ]
    }
   ],
   "source": [
    "X = read_features()\n",
    "y = read_target().iloc[:,0]\n",
    "\n",
    "result = []\n",
    "i = 1\n",
    "\n",
    "\n",
    "\n",
    "#step 1:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1, stratify=y)\n",
    "#change random state??\n",
    "\n",
    "#-----------\n",
    "\n",
    "step 2:\n",
    "X_train = remove_duplicated_columns(X_train)\n",
    "#step 3:\n",
    "X_train = remove_constant_volatility(X_train)\n",
    "#step 4:\n",
    "X_train = remove_cols_with_high_pct_null(X_train, 0.8) #this can be in the loop too, may be later\n",
    "#step 5: remove the same columns from step 2-4 TRAIN_TEST split\n",
    "X_test = X_test.loc[:,X_train.columns]\n",
    "\n",
    "#------------\n",
    "\n",
    "# X_train = X_train.loc[:, fast_track_cols]\n",
    "# X_test = X_test.loc[:, fast_track_cols]\n",
    "\n",
    "#------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#step 6-9\n",
    "replace_outlier_options = ['NaN','nothing'] #nothing at all\n",
    "#replace_outlier_options = ['3s','NaN','nothing']\n",
    "impute_null_options = ['knn__uniform']\n",
    "#impute_null_options = ['knn__distance', 'MICE', 'knn__uniform']\n",
    "FS_options = ['BoS__shap', 'RFE__RF','nothing']\n",
    "#FS_options = ['BoP','BoS__shap', 'BoS__gini', 'RFE__RF', 'RFE__SVM', 'nothing]\n",
    "sampling_options = ['SMOTEENN','ADASYN','SMOTE','ROSE'] #TRY OTHER SAMPLING\n",
    "#sampling_options = ['SMOTE','ROSE','ADASYN','SMOTEENN']\n",
    "model_options = ['NN']\n",
    "#model_options = ['LR', 'RF', 'NN']\n",
    "#try RF=10depth\n",
    "\n",
    "#next: TRY KNN DISTANCE\n",
    "\n",
    "for replace_with in replace_outlier_options:\n",
    "    for knn_weight in impute_null_options:\n",
    "        for classifier_model in FS_options:\n",
    "            for sampling_technique in sampling_options:\n",
    "                for Model in model_options:\n",
    "                    X_train_temp = X_train\n",
    "                    X_test_temp = X_test\n",
    "                    y_train_temp = y_train\n",
    "                    y_test_temp = y_test\n",
    "\n",
    "                    combined_technique = replace_with +' & '+ knn_weight +' & '+ classifier_model +' & '+ sampling_technique +' & '+ Model\n",
    "\n",
    "                    #step 6: oulier treatement (on both TRAIN & TEST split)\n",
    "                    if replace_with != 'nothing':\n",
    "                        X_train_temp = replace_outlier(X_train_temp, replace_with)\n",
    "                        X_test_temp = replace_outlier(X_test_temp, replace_with)\n",
    "                    \n",
    "                    #step 7: missing value imputation (on both TRAIN & TEST split)\n",
    "                    if knn_weight == 'knn__distance' or knn_weight == 'knn__uniform':\n",
    "                        X_train_temp, X_test_temp = impute_null_with_knn(X_train_temp, X_test_temp, knn_weight[-(len(knn_weight)-5):])\n",
    "                    elif knn_weight == 'MICE':\n",
    "                        X_train_temp, X_test_temp = impute_null_with_mice(X_train_temp, X_test_temp)\n",
    "\n",
    "                    #step 8: feature selection (on both TRAIN & TEST split)\n",
    "                    if classifier_model !='nothing':\n",
    "                        if classifier_model == 'BoS__shap' or classifier_model == 'BoS__gini':\n",
    "                            X_train_temp = BorutaShap_FS(X_train_temp, y_train_temp, classifier_model[-(len(classifier_model)-5):])\n",
    "                        elif classifier_model == 'RFE__RF' or classifier_model == 'RFE__SVM':\n",
    "                            X_train_temp = RFE_FS(X_train_temp, y_train_temp, classifier_model[-(len(classifier_model)-5):])\n",
    "                        elif classifier_model == 'BoP':\n",
    "                            X_train_temp = BorutaPy_FS(X_train_temp, y_train_temp)\n",
    "                    \n",
    "                    #step 9: remove multilinear features\n",
    "                    print('n_cols BEFORE multicolinearity treatement', X_train_temp.shape[1])\n",
    "                    X_train_temp = remove_collinear_features(X_train_temp, 0.7)\n",
    "                    print('n_cols AFTER multicolinearity treatement', X_train_temp.shape[1])\n",
    "\n",
    "                    #apply the same result for TEST\n",
    "                    X_test_temp = X_test_temp.loc[:,X_train_temp.columns]\n",
    "\n",
    "                    #print out datasets for backup\n",
    "                    X_train_temp.to_csv('sampling_visualization/X_train_temp_BEFORESAMPLING_'+str(i)+combined_technique+'.csv')\n",
    "                    X_test_temp.to_csv('sampling_visualization/X_test_temp_BEFORESAMPLING_'+str(i)+combined_technique+'.csv')\n",
    "                    y_train_temp.to_csv('sampling_visualization/y_train_temp_BEFORESAMPLING_'+str(i)+combined_technique+'.csv')\n",
    "                    y_test_temp.to_csv('sampling_visualization/y_test_temp_BEFORESAMPLING_'+str(i)+combined_technique+'.csv')\n",
    "\n",
    "                    #step 10: balancing only on TRAIN split\n",
    "                    X_train_temp, y_train_temp = sampling(X_train_temp, y_train_temp, sampling_technique)\n",
    "\n",
    "                    #print out datasets for backup\n",
    "                    X_train_temp.to_csv('sampling_visualization/X_train_temp_AFTERSAMPLING_'+str(i)+combined_technique+'.csv')\n",
    "                    X_test_temp.to_csv('sampling_visualization/X_test_temp_AFTERSAMPLING_'+str(i)+combined_technique+'.csv')\n",
    "                    y_train_temp.to_csv('sampling_visualization/y_train_temp_AFTERSAMPLING_'+str(i)+combined_technique+'.csv')\n",
    "                    y_test_temp.to_csv('sampling_visualization/y_test_temp_AFTERSAMPLING_'+str(i)+combined_technique+'.csv')\n",
    "\n",
    "\n",
    "                    #step 11: train model, predict, and print scores\n",
    "                    if Model != 'NN':\n",
    "                        try:\n",
    "                            cf_matrix, accuracy, f1, precision, recall, sensitivity, type_1_error_FP, type_2_error_FN, auc, log_loss_,cohen_kappa_score_, cf_matrix_train, accuracy_train, f1_train, precision_train, recall_train, sensitivity_train, type_1_error_FP_train, type_2_error_FN_train, auc_train = run_model(X_train_temp, y_train_temp, X_test_temp, y_test_temp, Model)\n",
    "                        except Exception:\n",
    "                            cf_matrix = accuracy = f1 = precision = recall = sensitivity = type_1_error_FP = type_2_error_FN = auc = log_loss_ =cohen_kappa_score_ = cf_matrix_train = accuracy_train = f1_train = precision_train = recall_train = sensitivity_train = type_1_error_FP_train = type_2_error_FN_train = auc_train = 0\n",
    "                    elif Model == 'NN':\n",
    "                        try:\n",
    "                            cf_matrix, accuracy, f1, precision, recall, sensitivity, type_1_error_FP, type_2_error_FN, auc, log_loss_,cohen_kappa_score_, cf_matrix_train, accuracy_train, f1_train, precision_train, recall_train, sensitivity_train, type_1_error_FP_train, type_2_error_FN_train, auc_train = run_model_NN(X_train_temp, y_train_temp, X_test_temp, y_test_temp)\n",
    "                        except Exception:\n",
    "                            cf_matrix = accuracy = f1 = precision = recall = sensitivity = type_1_error_FP = type_2_error_FN = auc = log_loss_ =cohen_kappa_score_ = cf_matrix_train = accuracy_train = f1_train = precision_train = recall_train = sensitivity_train = type_1_error_FP_train = type_2_error_FN_train = auc_train = 0\n",
    "\n",
    "                    result.append((i, combined_technique, X_train_temp.shape[1], replace_with, knn_weight, classifier_model, sampling_technique, Model, X_train_temp.columns, cf_matrix, accuracy, f1, precision, recall, sensitivity, type_1_error_FP, type_2_error_FN, auc, log_loss_, cohen_kappa_score_, cf_matrix_train, accuracy_train, f1_train, precision_train, recall_train, sensitivity_train, type_1_error_FP_train, type_2_error_FN_train, auc_train))\n",
    "                    \n",
    "                    print('attemp no.: ',i, combined_technique,' acc: ', accuracy,' accuracy_train: ',accuracy_train, ' f1: ', f1,' f1_train: ',f1_train, ' sensitivity: ', sensitivity, ' :auc ', auc, ' cfm: ', '\\n', cf_matrix, '\\n n_cols', X_train_temp.shape[1])\n",
    "                    \n",
    "\n",
    "                    if i%5==0: \n",
    "                        df_result = pd.DataFrame(result, columns = ['No.','combination','n_cols','outlier_replace_with', 'imputation_knn_weight', 'FS_classifier_model', 'balancing_sampling_technique', 'Model','cols','cf_matrix', 'accuracy', 'f1', 'precision', 'recall', 'sensitivity', 'type_1_error_FP', 'type_2_error_FN', 'auc', 'log_loss_','cohen_kappa_score_','cf_matrix_train', 'accuracy_train', 'f1_train', 'precision_train', 'recall_train', 'sensitivity_train', 'type_1_error_FP_train', 'type_2_error_FN_train', 'auc_train'])\n",
    "                        df_result.to_csv('tracker/result'+str(i)+'.csv')\n",
    "                    \n",
    "\n",
    "                    i+=1\n",
    "\n",
    "\n",
    "\n",
    "df_result = pd.DataFrame(result, columns = ['No.','combination','n_cols','outlier_replace_with', 'imputation_knn_weight', 'FS_classifier_model', 'balancing_sampling_technique', 'Model','cols','cf_matrix', 'accuracy', 'f1', 'precision', 'recall', 'sensitivity', 'type_1_error_FP', 'type_2_error_FN', 'auc', 'log_loss_','cohen_kappa_score_','cf_matrix_train', 'accuracy_train', 'f1_train', 'precision_train', 'recall_train', 'sensitivity_train', 'type_1_error_FP_train', 'type_2_error_FN_train', 'auc_train'])\n",
    "df_result.to_csv('tracker/result.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3aeb15c8c31224d9ef37a76c0046f703a279f439b6efd04fb2681e5f2715bf2f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
